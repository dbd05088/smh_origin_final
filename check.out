Remove the tensorboard dir
[INFO] main.py:222 > Set the device (cuda)
[INFO] main.py:267 > Using train-transforms Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=4)
    ToTensor()
    Normalize(mean=(0.4914, 0.482158, 0.4465231), std=(0.247032, 0.243485, 0.2615877))
)
[INFO] augment.py:18 > cifar10: autoaugmentation is applied
[INFO] main.py:290 > Using train-transforms [AutoAugment CIFAR10 Policy]
[INFO] main.py:300 > [1] Select a CIL method (rm)
[INFO] method_manager.py:48 > CIL Scenario: 
n_tasks: 5
n_init_cls: 2
n_cls_a_task: 2
total cls: 10
[INFO] main.py:306 > [2] Incrementally training 5 tasks

##################################################
# Task 0 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 30  current step :  0
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.23s. Batch: 1.92s. S_Loss: 2.5301. T_Loss: 2.4255. Mask: 0.0000. :   0%|          | 0/10 [00:01<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.23s. Batch: 1.92s. S_Loss: 2.5301. T_Loss: 2.4255. Mask: 0.0000. :  10%|█         | 1/10 [00:01<00:17,  1.92s/it]Train Iter:   2/ 30. LR: 0.0000. Data: 0.13s. Batch: 1.41s. S_Loss: 2.4803. T_Loss: 2.5526. Mask: 0.0000. :  10%|█         | 1/10 [00:02<00:17,  1.92s/it]Train Iter:   2/ 30. LR: 0.0000. Data: 0.13s. Batch: 1.41s. S_Loss: 2.4803. T_Loss: 2.5526. Mask: 0.0000. :  20%|██        | 2/10 [00:02<00:10,  1.32s/it]Train Iter:   3/ 30. LR: 0.0000. Data: 0.08s. Batch: 1.04s. S_Loss: 2.5303. T_Loss: 2.5536. Mask: 0.0000. :  20%|██        | 2/10 [00:03<00:10,  1.32s/it]Train Iter:   3/ 30. LR: 0.0000. Data: 0.08s. Batch: 1.04s. S_Loss: 2.5303. T_Loss: 2.5536. Mask: 0.0000. :  30%|███       | 3/10 [00:03<00:05,  1.17it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.06s. Batch: 0.80s. S_Loss: 2.5301. T_Loss: 2.5380. Mask: 0.0078. :  30%|███       | 3/10 [00:03<00:05,  1.17it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.66s. S_Loss: 2.5338. T_Loss: 2.5314. Mask: 0.0063. :  40%|████      | 4/10 [00:03<00:05,  1.17it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.66s. S_Loss: 2.5338. T_Loss: 2.5314. Mask: 0.0063. :  50%|█████     | 5/10 [00:03<00:02,  2.37it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.56s. S_Loss: 2.5137. T_Loss: 2.5459. Mask: 0.0052. :  50%|█████     | 5/10 [00:03<00:02,  2.37it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.50s. S_Loss: 2.4850. T_Loss: 2.5145. Mask: 0.0045. :  60%|██████    | 6/10 [00:03<00:01,  2.37it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.50s. S_Loss: 2.4850. T_Loss: 2.5145. Mask: 0.0045. :  70%|███████   | 7/10 [00:03<00:00,  3.65it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.46s. S_Loss: 2.4675. T_Loss: 2.5149. Mask: 0.0039. :  70%|███████   | 7/10 [00:03<00:00,  3.65it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.46s. S_Loss: 2.4675. T_Loss: 2.5149. Mask: 0.0039. :  80%|████████  | 8/10 [00:03<00:00,  3.77it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.43s. S_Loss: 2.4620. T_Loss: 2.5310. Mask: 0.0035. :  80%|████████  | 8/10 [00:03<00:00,  3.77it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.43s. S_Loss: 2.4620. T_Loss: 2.5310. Mask: 0.0035. :  90%|█████████ | 9/10 [00:03<00:00,  4.40it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.39s. S_Loss: 2.4624. T_Loss: 2.5100. Mask: 0.0031. :  90%|█████████ | 9/10 [00:03<00:00,  4.40it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.39s. S_Loss: 2.4624. T_Loss: 2.5100. Mask: 0.0031. : 100%|██████████| 10/10 [00:03<00:00,  5.06it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.39s. S_Loss: 2.4624. T_Loss: 2.5100. Mask: 0.0031. : 100%|██████████| 10/10 [00:03<00:00,  2.53it/s]
total : 30  current step :  1
total : 30  current step :  2
total : 30  current step :  3
total : 30  current step :  4
total : 30  current step :  5
total : 30  current step :  6
total : 30  current step :  7
total : 30  current step :  8
total : 30  current step :  9
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 12.0405. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.55s. Loss: 12.0405. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.78s. Loss: 11.8978. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.52s. Loss: 11.8553. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 12.0705. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 11.9202. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 11.7726. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 11.6145. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 11.5020. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 11.2862. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 11.2297. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:35,  1.55s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 11.2297. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 11.1644. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 11.1643. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 11.1758. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 11.2603. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 11.1770. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 11.1304. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 11.1880. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.17it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 11.1880. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 11.1471. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 11.1098. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 11.1546. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 11.1316. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 11.1589. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 11.1187. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 11.0639. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 11.0652. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 11.0864. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 11.0888. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 11.1087. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.1442. top1: 0.00. top5: 100.00. :  27%|██▋       | 17/63 [00:01<00:03, 14.71it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.1442. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.1543. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.1632. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.3422. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.4993. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 11.6392. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.7315. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.8218. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.9633. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.0874. top1: 0.00. top5: 100.00. :  46%|████▌     | 29/63 [00:01<00:01, 28.39it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.0874. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:01<00:00, 37.81it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.1976. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:01<00:00, 37.81it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.3444. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:01<00:00, 37.81it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4930. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.6173. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.7154. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.7881. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.9083. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.9883. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.0589. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.1545. top1: 0.00. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 37.81it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.1545. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.2467. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.3298. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.4074. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.4970. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.5796. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.6354. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.6888. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.7303. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.7524. top1: 0.00. top5: 100.00. :  76%|███████▌  | 48/63 [00:02<00:00, 48.95it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.7524. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.7811. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.8138. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.8892. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.9416. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.9633. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.9871. top1: 0.00. top5: 100.00. :  90%|█████████ | 57/63 [00:02<00:00, 56.15it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.9871. top1: 0.00. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 26.05it/s]
total : 30  current step :  10
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.4610. T_Loss: 2.3600. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.4610. T_Loss: 2.3600. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  7.52it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.3572. T_Loss: 2.2891. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  7.52it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.3572. T_Loss: 2.2891. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  6.98it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.18s. S_Loss: 2.3565. T_Loss: 2.3100. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  6.98it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.18s. S_Loss: 2.3565. T_Loss: 2.3100. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.23it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.16s. S_Loss: 2.3929. T_Loss: 2.2489. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.23it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.16s. S_Loss: 2.3929. T_Loss: 2.2489. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.20it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.3861. T_Loss: 2.2409. Mask: 0.0063. :  40%|████      | 4/10 [00:00<00:00,  6.20it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.3861. T_Loss: 2.2409. Mask: 0.0063. :  50%|█████     | 5/10 [00:00<00:00,  6.96it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.3999. T_Loss: 2.2130. Mask: 0.0052. :  50%|█████     | 5/10 [00:00<00:00,  6.96it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.3999. T_Loss: 2.2130. Mask: 0.0052. :  60%|██████    | 6/10 [00:00<00:00,  6.56it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.4058. T_Loss: 2.1864. Mask: 0.0045. :  60%|██████    | 6/10 [00:01<00:00,  6.56it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.4058. T_Loss: 2.1864. Mask: 0.0045. :  70%|███████   | 7/10 [00:01<00:00,  7.14it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.4243. T_Loss: 2.1716. Mask: 0.0039. :  70%|███████   | 7/10 [00:01<00:00,  7.14it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.4243. T_Loss: 2.1716. Mask: 0.0039. :  80%|████████  | 8/10 [00:01<00:00,  7.46it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.16s. S_Loss: 2.4345. T_Loss: 2.1268. Mask: 0.0035. :  80%|████████  | 8/10 [00:01<00:00,  7.46it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.16s. S_Loss: 2.4345. T_Loss: 2.1268. Mask: 0.0035. :  90%|█████████ | 9/10 [00:01<00:00,  5.93it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.4437. T_Loss: 2.0830. Mask: 0.0031. :  90%|█████████ | 9/10 [00:01<00:00,  5.93it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.4437. T_Loss: 2.0830. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  6.49it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.15s. S_Loss: 2.4437. T_Loss: 2.0830. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  6.53it/s]
total : 30  current step :  11
total : 30  current step :  12
total : 30  current step :  13
total : 30  current step :  14
total : 30  current step :  15
total : 30  current step :  16
total : 30  current step :  17
total : 30  current step :  18
total : 30  current step :  19
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.43s. Loss: 9.1745. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.43s. Loss: 9.1745. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.73s. Loss: 9.0685. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.49s. Loss: 9.0219. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.37s. Loss: 9.2015. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.30s. Loss: 9.0812. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.25s. Loss: 8.9648. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.21s. Loss: 8.8464. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.19s. Loss: 8.7561. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.17s. Loss: 8.5893. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 8.5420. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.14s. Loss: 8.4939. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 8.4941. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:28,  1.44s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 8.4941. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 8.5010. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 8.5631. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.12s. Loss: 8.4987. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 8.4613. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 8.5058. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 8.4756. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 8.4488. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 8.4860. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 8.4677. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 8.4891. top1: 0.00. top5: 100.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.73it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 8.4891. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 8.4580. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 8.4148. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 8.4159. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4318. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4348. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4494. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4769. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4843. top1: 0.00. top5: 100.00. :  35%|███▍      | 22/63 [00:01<00:02, 17.40it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 8.4843. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:01<00:01, 24.91it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.4909. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:01<00:01, 24.91it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.6259. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:01<00:01, 24.91it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.7395. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.8417. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.9071. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.9744. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 9.0792. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.1718. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.2525. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.3614. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.4713. top1: 0.00. top5: 100.00. :  48%|████▊     | 30/63 [00:02<00:01, 24.91it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.4713. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.5643. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.6375. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.6905. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.7799. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.8382. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.8902. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.9619. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.0308. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.0924. top1: 0.00. top5: 100.00. :  65%|██████▌   | 41/63 [00:02<00:00, 36.75it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.0924. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.1513. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.2189. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.2789. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.3202. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.3604. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.3897. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.4053. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.4250. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.4494. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5062. top1: 0.00. top5: 100.00. :  79%|███████▉  | 50/63 [00:02<00:00, 45.54it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5062. top1: 0.00. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 55.82it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5451. top1: 0.00. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 55.82it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5609. top1: 0.00. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 55.82it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5787. top1: 0.00. top5: 100.00. :  95%|█████████▌| 60/63 [00:02<00:00, 55.82it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5787. top1: 0.00. top5: 100.00. : 100%|██████████| 63/63 [00:02<00:00, 25.44it/s]
total : 30  current step :  20
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.4341. T_Loss: 1.7736. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.4341. T_Loss: 1.7736. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  8.16it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5394. T_Loss: 1.7294. Mask: 0.0156. :  10%|█         | 1/10 [00:00<00:01,  8.16it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5394. T_Loss: 1.7294. Mask: 0.0156. :  20%|██        | 2/10 [00:00<00:00,  8.08it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5412. T_Loss: 1.6849. Mask: 0.0312. :  20%|██        | 2/10 [00:00<00:00,  8.08it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5412. T_Loss: 1.6849. Mask: 0.0312. :  30%|███       | 3/10 [00:00<00:00,  8.18it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5225. T_Loss: 1.7136. Mask: 0.0469. :  30%|███       | 3/10 [00:00<00:00,  8.18it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5225. T_Loss: 1.7136. Mask: 0.0469. :  40%|████      | 4/10 [00:00<00:00,  8.18it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5382. T_Loss: 1.7004. Mask: 0.0563. :  40%|████      | 4/10 [00:00<00:00,  8.18it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5382. T_Loss: 1.7004. Mask: 0.0563. :  50%|█████     | 5/10 [00:00<00:00,  8.14it/s]total : 30  current step :  21
total : 30  current step :  22
total : 30  current step :  23
total : 30  current step :  24
total : 30  current step :  25
Train Iter:  26/ 30. LR: 0.0000. Data: 0.27s. Batch: 0.39s. S_Loss: 2.5284. T_Loss: 1.6933. Mask: 0.0938. :  50%|█████     | 5/10 [00:02<00:00,  8.14it/s]Train Iter:  26/ 30. LR: 0.0000. Data: 0.27s. Batch: 0.39s. S_Loss: 2.5284. T_Loss: 1.6933. Mask: 0.0938. :  60%|██████    | 6/10 [00:02<00:02,  1.50it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.23s. Batch: 0.35s. S_Loss: 2.5315. T_Loss: 1.7059. Mask: 0.1339. :  60%|██████    | 6/10 [00:02<00:02,  1.50it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.23s. Batch: 0.35s. S_Loss: 2.5315. T_Loss: 1.7059. Mask: 0.1339. :  70%|███████   | 7/10 [00:02<00:01,  2.06it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.20s. Batch: 0.32s. S_Loss: 2.5228. T_Loss: 1.6997. Mask: 0.1680. :  70%|███████   | 7/10 [00:02<00:01,  2.06it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.20s. Batch: 0.32s. S_Loss: 2.5228. T_Loss: 1.6997. Mask: 0.1680. :  80%|████████  | 8/10 [00:02<00:00,  2.72it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.18s. Batch: 0.31s. S_Loss: 2.5159. T_Loss: 1.7244. Mask: 0.2118. :  80%|████████  | 8/10 [00:02<00:00,  2.72it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.18s. Batch: 0.31s. S_Loss: 2.5159. T_Loss: 1.7244. Mask: 0.2118. :  90%|█████████ | 9/10 [00:02<00:00,  3.07it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.16s. Batch: 0.29s. S_Loss: 2.5134. T_Loss: 1.7221. Mask: 0.2500. :  90%|█████████ | 9/10 [00:02<00:00,  3.07it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.16s. Batch: 0.29s. S_Loss: 2.5134. T_Loss: 1.7221. Mask: 0.2500. : 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.16s. Batch: 0.29s. S_Loss: 2.5134. T_Loss: 1.7221. Mask: 0.2500. : 100%|██████████| 10/10 [00:02<00:00,  3.44it/s]
total : 30  current step :  26
total : 30  current step :  27
total : 30  current step :  28
total : 30  current step :  29
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.39s. Loss: 7.1683. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.39s. Loss: 7.1683. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.71s. Loss: 7.0890. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.48s. Loss: 7.0472. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.36s. Loss: 7.1978. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.29s. Loss: 7.1005. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.24s. Loss: 7.0069. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.21s. Loss: 6.9148. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.18s. Loss: 6.8406. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.16s. Loss: 6.7109. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 6.6715. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.39s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 6.6715. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.14s. Loss: 6.6355. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.13s. Loss: 6.6365. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.12s. Loss: 6.6415. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.11s. Loss: 6.6875. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 6.6379. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.10s. Loss: 6.6068. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 6.6424. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.6196. top1: 0.00. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:06,  8.77it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.6196. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.5996. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6302. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6158. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6326. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6079. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.5729. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.5738. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.5866. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.5894. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6006. top1: 0.00. top5: 100.00. :  29%|██▊       | 18/63 [00:01<00:02, 16.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6006. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6219. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6275. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6327. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.7388. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.8256. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.9046. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.9538. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.0076. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.0892. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.1618. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.2245. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.3091. top1: 0.00. top5: 100.00. :  44%|████▍     | 28/63 [00:01<00:01, 28.30it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.3091. top1: 0.00. top5: 100.00. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.3944. top1: 0.00. top5: 100.00. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.4673. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s] Test Iter:  43/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.5248. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.5660. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.6351. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.6801. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.7209. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.7774. top1: 0.00. top5: 99.93. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.8315. top1: 0.00. top5: 99.94. :  63%|██████▎   | 40/63 [00:01<00:00, 42.74it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.8315. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.8795. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.9263. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.9795. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.0252. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.0574. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:01<00:00, 50.96it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.0892. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:02<00:00, 50.96it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.1115. top1: 0.00. top5: 99.94. :  78%|███████▊  | 49/63 [00:02<00:00, 50.96it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.1237. top1: 0.00. top5: 99.95. :  78%|███████▊  | 49/63 [00:02<00:00, 50.96it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.1383. top1: 0.00. top5: 99.95. :  78%|███████▊  | 49/63 [00:02<00:00, 50.96it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.1577. top1: 0.00. top5: 99.95. :  78%|███████▊  | 49/63 [00:02<00:00, 50.96it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.1577. top1: 0.00. top5: 99.95. :  94%|█████████▎| 59/63 [00:02<00:00, 60.94it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.2023. top1: 0.00. top5: 99.95. :  94%|█████████▎| 59/63 [00:02<00:00, 60.94it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.2329. top1: 0.00. top5: 99.95. :  94%|█████████▎| 59/63 [00:02<00:00, 60.94it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.2454. top1: 0.00. top5: 99.95. :  94%|█████████▎| 59/63 [00:02<00:00, 60.94it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.2593. top1: 0.00. top5: 99.95. :  94%|█████████▎| 59/63 [00:02<00:00, 60.94it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 8.2593. top1: 0.00. top5: 99.95. : 100%|██████████| 63/63 [00:02<00:00, 27.63it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.46s. Batch: 1.59s. Loss: 2.5595. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.46s. Batch: 1.59s. Loss: 2.5595. :   4%|▍         | 1/25 [00:01<00:38,  1.59s/it]Finetune Epoch:  1/ 5. Data: 1.54s. Batch: 1.63s. Loss: 2.5543. :   4%|▍         | 1/25 [00:01<00:38,  1.59s/it]Finetune Epoch:  1/ 5. Data: 1.58s. Batch: 1.66s. Loss: 2.5702. :   4%|▍         | 1/25 [00:01<00:38,  1.59s/it]Finetune Epoch:  1/ 5. Data: 1.58s. Batch: 1.66s. Loss: 2.5702. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  1/ 5. Data: 1.62s. Batch: 1.69s. Loss: 2.5556. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  1/ 5. Data: 1.65s. Batch: 1.71s. Loss: 2.5482. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  1/ 5. Data: 1.67s. Batch: 1.74s. Loss: 2.5428. :  12%|█▏        | 3/25 [00:01<00:10,  2.17it/s]Finetune Epoch:  1/ 5. Data: 1.67s. Batch: 1.74s. Loss: 2.5428. :  24%|██▍       | 6/25 [00:01<00:03,  4.83it/s]Finetune Epoch:  1/ 5. Data: 1.70s. Batch: 1.76s. Loss: 2.5401. :  24%|██▍       | 6/25 [00:01<00:03,  4.83it/s]Finetune Epoch:  1/ 5. Data: 1.73s. Batch: 1.79s. Loss: 2.5440. :  24%|██▍       | 6/25 [00:01<00:03,  4.83it/s]Finetune Epoch:  1/ 5. Data: 1.73s. Batch: 1.79s. Loss: 2.5440. :  32%|███▏      | 8/25 [00:01<00:02,  6.69it/s]Finetune Epoch:  1/ 5. Data: 1.76s. Batch: 1.81s. Loss: 2.5397. :  32%|███▏      | 8/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  1/ 5. Data: 1.78s. Batch: 1.84s. Loss: 2.5420. :  32%|███▏      | 8/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.5375. :  32%|███▏      | 8/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.5375. :  44%|████▍     | 11/25 [00:02<00:01,  9.72it/s]Finetune Epoch:  1/ 5. Data: 1.83s. Batch: 1.88s. Loss: 2.5370. :  44%|████▍     | 11/25 [00:02<00:01,  9.72it/s]Finetune Epoch:  1/ 5. Data: 1.85s. Batch: 1.91s. Loss: 2.5359. :  44%|████▍     | 11/25 [00:02<00:01,  9.72it/s]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.5363. :  44%|████▍     | 11/25 [00:02<00:01,  9.72it/s]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.5363. :  56%|█████▌    | 14/25 [00:02<00:00, 12.09it/s]Finetune Epoch:  1/ 5. Data: 1.90s. Batch: 1.96s. Loss: 2.5384. :  56%|█████▌    | 14/25 [00:02<00:00, 12.09it/s]Finetune Epoch:  1/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.5342. :  56%|█████▌    | 14/25 [00:02<00:00, 12.09it/s]Finetune Epoch:  1/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.5342. :  64%|██████▍   | 16/25 [00:02<00:00, 13.43it/s]Finetune Epoch:  1/ 5. Data: 1.95s. Batch: 2.01s. Loss: 2.5351. :  64%|██████▍   | 16/25 [00:02<00:00, 13.43it/s]Finetune Epoch:  1/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.5367. :  64%|██████▍   | 16/25 [00:02<00:00, 13.43it/s]Finetune Epoch:  1/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.5367. :  72%|███████▏  | 18/25 [00:02<00:00, 14.39it/s]Finetune Epoch:  1/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.5368. :  72%|███████▏  | 18/25 [00:02<00:00, 14.39it/s]Finetune Epoch:  1/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.5342. :  72%|███████▏  | 18/25 [00:02<00:00, 14.39it/s]Finetune Epoch:  1/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.5338. :  72%|███████▏  | 18/25 [00:02<00:00, 14.39it/s]Finetune Epoch:  1/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.5338. :  84%|████████▍ | 21/25 [00:02<00:00, 16.07it/s]Finetune Epoch:  1/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.5322. :  84%|████████▍ | 21/25 [00:02<00:00, 16.07it/s]Finetune Epoch:  1/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.5302. :  84%|████████▍ | 21/25 [00:02<00:00, 16.07it/s]Finetune Epoch:  1/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.5289. :  84%|████████▍ | 21/25 [00:02<00:00, 16.07it/s]Finetune Epoch:  1/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.5289. :  96%|█████████▌| 24/25 [00:02<00:00, 17.22it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.5285. :  96%|█████████▌| 24/25 [00:02<00:00, 17.22it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.5285. : 100%|██████████| 25/25 [00:02<00:00,  8.35it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.40s. Loss: 2.7786. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.40s. Loss: 2.7786. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.71s. Loss: 2.7249. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.48s. Loss: 2.7120. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.36s. Loss: 2.7377. top1: 0.00. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.30s. Loss: 2.7181. top1: 0.00. top5: 98.75. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.6875. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.22s. Loss: 2.6742. top1: 0.00. top5: 99.11. :   2%|▏         | 1/63 [00:01<01:26,  1.40s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.22s. Loss: 2.6742. top1: 0.00. top5: 99.11. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.6570. top1: 0.00. top5: 99.22. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.6330. top1: 0.00. top5: 99.31. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.6233. top1: 0.00. top5: 99.38. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.6197. top1: 0.00. top5: 99.43. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.6231. top1: 0.00. top5: 99.48. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.6271. top1: 0.00. top5: 99.28. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.6311. top1: 0.00. top5: 99.33. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.6272. top1: 0.00. top5: 99.38. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.6191. top1: 0.00. top5: 99.22. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.6247. top1: 0.00. top5: 99.26. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.6208. top1: 0.00. top5: 99.31. :  11%|█         | 7/63 [00:01<00:09,  6.15it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.6208. top1: 0.00. top5: 99.31. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.6195. top1: 0.00. top5: 99.34. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.6275. top1: 0.00. top5: 99.38. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.6243. top1: 0.00. top5: 99.40. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.6274. top1: 0.00. top5: 99.43. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6220. top1: 0.00. top5: 99.46. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6137. top1: 0.00. top5: 99.48. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6148. top1: 0.00. top5: 99.25. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6184. top1: 0.00. top5: 99.28. :  29%|██▊       | 18/63 [00:01<00:02, 18.19it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6184. top1: 0.00. top5: 99.28. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6195. top1: 0.00. top5: 99.31. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6222. top1: 0.00. top5: 99.33. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6228. top1: 0.00. top5: 99.35. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6245. top1: 0.00. top5: 99.27. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6261. top1: 0.00. top5: 99.29. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6487. top1: 0.00. top5: 99.32. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6634. top1: 0.00. top5: 99.34. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6790. top1: 0.00. top5: 99.26. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6856. top1: 0.00. top5: 99.29. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7009. top1: 0.00. top5: 99.31. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7168. top1: 0.00. top5: 99.32. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7315. top1: 0.00. top5: 99.34. :  41%|████▏     | 26/63 [00:01<00:01, 26.95it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7315. top1: 0.00. top5: 99.34. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7450. top1: 0.00. top5: 99.36. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7618. top1: 0.00. top5: 99.38. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7784. top1: 0.00. top5: 99.39. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.7938. top1: 0.00. top5: 99.33. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8069. top1: 0.00. top5: 99.35. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8149. top1: 0.00. top5: 99.36. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8268. top1: 0.00. top5: 99.38. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8360. top1: 0.00. top5: 99.39. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8450. top1: 0.00. top5: 99.40. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8564. top1: 0.00. top5: 99.41. :  60%|██████    | 38/63 [00:01<00:00, 42.10it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8564. top1: 0.00. top5: 99.41. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8685. top1: 0.00. top5: 99.43. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8787. top1: 0.00. top5: 99.44. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.8909. top1: 0.00. top5: 99.45. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9023. top1: 0.00. top5: 99.40. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9103. top1: 0.00. top5: 99.41. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9165. top1: 0.00. top5: 99.42. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9245. top1: 0.00. top5: 99.43. :  76%|███████▌  | 48/63 [00:01<00:00, 53.04it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9289. top1: 0.00. top5: 99.44. :  76%|███████▌  | 48/63 [00:02<00:00, 53.04it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9320. top1: 0.00. top5: 99.40. :  76%|███████▌  | 48/63 [00:02<00:00, 53.04it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9338. top1: 0.00. top5: 99.41. :  76%|███████▌  | 48/63 [00:02<00:00, 53.04it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9338. top1: 0.00. top5: 99.41. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9388. top1: 0.00. top5: 99.42. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9479. top1: 0.00. top5: 99.43. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9545. top1: 0.00. top5: 99.44. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9578. top1: 0.00. top5: 99.40. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9610. top1: 0.00. top5: 99.40. :  92%|█████████▏| 58/63 [00:02<00:00, 62.76it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.9610. top1: 0.00. top5: 99.40. : 100%|██████████| 63/63 [00:02<00:00, 27.95it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.5319. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.5319. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  2/ 5. Data: 1.47s. Batch: 1.52s. Loss: 2.5271. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  2/ 5. Data: 1.50s. Batch: 1.55s. Loss: 2.5086. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  2/ 5. Data: 1.50s. Batch: 1.55s. Loss: 2.5086. :  12%|█▏        | 3/25 [00:01<00:09,  2.34it/s]Finetune Epoch:  2/ 5. Data: 1.52s. Batch: 1.57s. Loss: 2.5090. :  12%|█▏        | 3/25 [00:01<00:09,  2.34it/s]Finetune Epoch:  2/ 5. Data: 1.55s. Batch: 1.60s. Loss: 2.5045. :  12%|█▏        | 3/25 [00:01<00:09,  2.34it/s]Finetune Epoch:  2/ 5. Data: 1.57s. Batch: 1.62s. Loss: 2.5039. :  12%|█▏        | 3/25 [00:01<00:09,  2.34it/s]Finetune Epoch:  2/ 5. Data: 1.57s. Batch: 1.62s. Loss: 2.5039. :  24%|██▍       | 6/25 [00:01<00:03,  5.15it/s]Finetune Epoch:  2/ 5. Data: 1.60s. Batch: 1.65s. Loss: 2.5063. :  24%|██▍       | 6/25 [00:01<00:03,  5.15it/s]Finetune Epoch:  2/ 5. Data: 1.62s. Batch: 1.67s. Loss: 2.5061. :  24%|██▍       | 6/25 [00:01<00:03,  5.15it/s]Finetune Epoch:  2/ 5. Data: 1.65s. Batch: 1.70s. Loss: 2.5073. :  24%|██▍       | 6/25 [00:01<00:03,  5.15it/s]Finetune Epoch:  2/ 5. Data: 1.65s. Batch: 1.70s. Loss: 2.5073. :  36%|███▌      | 9/25 [00:01<00:02,  7.88it/s]Finetune Epoch:  2/ 5. Data: 1.67s. Batch: 1.72s. Loss: 2.5055. :  36%|███▌      | 9/25 [00:01<00:02,  7.88it/s]Finetune Epoch:  2/ 5. Data: 1.70s. Batch: 1.74s. Loss: 2.5015. :  36%|███▌      | 9/25 [00:01<00:02,  7.88it/s]Finetune Epoch:  2/ 5. Data: 1.72s. Batch: 1.77s. Loss: 2.4969. :  36%|███▌      | 9/25 [00:02<00:02,  7.88it/s]Finetune Epoch:  2/ 5. Data: 1.72s. Batch: 1.77s. Loss: 2.4969. :  48%|████▊     | 12/25 [00:02<00:01, 10.49it/s]Finetune Epoch:  2/ 5. Data: 1.75s. Batch: 1.79s. Loss: 2.4931. :  48%|████▊     | 12/25 [00:02<00:01, 10.49it/s]Finetune Epoch:  2/ 5. Data: 1.77s. Batch: 1.82s. Loss: 2.4891. :  48%|████▊     | 12/25 [00:02<00:01, 10.49it/s]Finetune Epoch:  2/ 5. Data: 1.77s. Batch: 1.82s. Loss: 2.4891. :  56%|█████▌    | 14/25 [00:02<00:00, 11.62it/s]Finetune Epoch:  2/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.4873. :  56%|█████▌    | 14/25 [00:02<00:00, 11.62it/s]Finetune Epoch:  2/ 5. Data: 1.82s. Batch: 1.87s. Loss: 2.4878. :  56%|█████▌    | 14/25 [00:02<00:00, 11.62it/s]Finetune Epoch:  2/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.4866. :  56%|█████▌    | 14/25 [00:02<00:00, 11.62it/s]Finetune Epoch:  2/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.4866. :  68%|██████▊   | 17/25 [00:02<00:00, 13.88it/s]Finetune Epoch:  2/ 5. Data: 1.87s. Batch: 1.92s. Loss: 2.4865. :  68%|██████▊   | 17/25 [00:02<00:00, 13.88it/s]Finetune Epoch:  2/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.4846. :  68%|██████▊   | 17/25 [00:02<00:00, 13.88it/s]Finetune Epoch:  2/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.4846. :  76%|███████▌  | 19/25 [00:02<00:00, 14.89it/s]Finetune Epoch:  2/ 5. Data: 1.93s. Batch: 1.97s. Loss: 2.4825. :  76%|███████▌  | 19/25 [00:02<00:00, 14.89it/s]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.4807. :  76%|███████▌  | 19/25 [00:02<00:00, 14.89it/s]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.4807. :  84%|████████▍ | 21/25 [00:02<00:00, 15.99it/s]Finetune Epoch:  2/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.4807. :  84%|████████▍ | 21/25 [00:02<00:00, 15.99it/s]Finetune Epoch:  2/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.4801. :  84%|████████▍ | 21/25 [00:02<00:00, 15.99it/s]Finetune Epoch:  2/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.4801. :  92%|█████████▏| 23/25 [00:02<00:00, 16.81it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.4791. :  92%|█████████▏| 23/25 [00:02<00:00, 16.81it/s]Finetune Epoch:  2/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.4785. :  92%|█████████▏| 23/25 [00:02<00:00, 16.81it/s]Finetune Epoch:  2/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.4785. : 100%|██████████| 25/25 [00:02<00:00, 17.57it/s]Finetune Epoch:  2/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.4785. : 100%|██████████| 25/25 [00:02<00:00,  8.67it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.53s. Loss: 2.5159. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.53s. Loss: 2.5159. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.78s. Loss: 2.4665. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.52s. Loss: 2.4565. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 2.4689. top1: 0.00. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 2.4566. top1: 0.00. top5: 99.38. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 2.4340. top1: 0.00. top5: 99.48. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.4279. top1: 0.00. top5: 99.55. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 2.4167. top1: 0.00. top5: 99.61. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.4009. top1: 0.00. top5: 99.65. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.3949. top1: 0.00. top5: 99.69. :   2%|▏         | 1/63 [00:01<01:34,  1.53s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.3949. top1: 0.00. top5: 99.69. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.3932. top1: 0.00. top5: 99.72. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.3970. top1: 0.00. top5: 99.74. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4004. top1: 0.00. top5: 99.52. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.4011. top1: 0.00. top5: 99.55. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.3998. top1: 0.00. top5: 99.58. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.3945. top1: 0.00. top5: 99.41. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.3974. top1: 0.00. top5: 99.45. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.3953. top1: 0.00. top5: 99.48. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.3955. top1: 0.00. top5: 99.51. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4012. top1: 0.00. top5: 99.53. :  16%|█▌        | 10/63 [00:01<00:06,  8.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4012. top1: 0.00. top5: 99.53. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.3995. top1: 0.00. top5: 99.55. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4011. top1: 0.00. top5: 99.57. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.3976. top1: 0.00. top5: 99.59. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.3922. top1: 0.00. top5: 99.61. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.3930. top1: 0.00. top5: 99.38. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.3959. top1: 0.00. top5: 99.40. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.3967. top1: 0.00. top5: 99.42. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3985. top1: 0.00. top5: 99.44. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3978. top1: 0.00. top5: 99.46. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3992. top1: 0.00. top5: 99.38. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4005. top1: 0.00. top5: 99.40. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4134. top1: 0.00. top5: 99.41. :  32%|███▏      | 20/63 [00:01<00:02, 18.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4134. top1: 0.00. top5: 99.41. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4203. top1: 0.00. top5: 99.43. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4287. top1: 0.00. top5: 99.45. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4309. top1: 0.00. top5: 99.46. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4406. top1: 0.00. top5: 99.48. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4491. top1: 0.00. top5: 99.49. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4572. top1: 0.00. top5: 99.51. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4647. top1: 0.00. top5: 99.52. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4736. top1: 0.00. top5: 99.53. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4827. top1: 0.00. top5: 99.54. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4914. top1: 0.00. top5: 99.48. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4991. top1: 0.00. top5: 99.49. :  51%|█████     | 32/63 [00:01<00:00, 31.55it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4991. top1: 0.00. top5: 99.49. :  68%|██████▊   | 43/63 [00:01<00:00, 43.65it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5031. top1: 0.00. top5: 99.50. :  68%|██████▊   | 43/63 [00:01<00:00, 43.65it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5089. top1: 0.00. top5: 99.51. :  68%|██████▊   | 43/63 [00:01<00:00, 43.65it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5137. top1: 0.00. top5: 99.52. :  68%|██████▊   | 43/63 [00:01<00:00, 43.65it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5190. top1: 0.00. top5: 99.53. :  68%|██████▊   | 43/63 [00:01<00:00, 43.65it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5256. top1: 0.00. top5: 99.54. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5331. top1: 0.00. top5: 99.55. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5387. top1: 0.00. top5: 99.56. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5466. top1: 0.00. top5: 99.57. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5534. top1: 0.00. top5: 99.58. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5573. top1: 0.00. top5: 99.59. :  68%|██████▊   | 43/63 [00:02<00:00, 43.65it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5573. top1: 0.00. top5: 99.59. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5605. top1: 0.00. top5: 99.59. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5654. top1: 0.06. top5: 99.60. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5677. top1: 0.06. top5: 99.61. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5696. top1: 0.11. top5: 99.56. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5700. top1: 0.11. top5: 99.57. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5732. top1: 0.11. top5: 99.58. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5784. top1: 0.10. top5: 99.58. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5822. top1: 0.10. top5: 99.59. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.5843. top1: 0.10. top5: 99.55. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.5862. top1: 0.10. top5: 99.55. :  84%|████████▍ | 53/63 [00:02<00:00, 51.78it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.5862. top1: 0.10. top5: 99.55. : 100%|██████████| 63/63 [00:02<00:00, 26.86it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.4322. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.4322. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  3/ 5. Data: 1.47s. Batch: 1.52s. Loss: 2.4413. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  3/ 5. Data: 1.50s. Batch: 1.54s. Loss: 2.4461. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  3/ 5. Data: 1.52s. Batch: 1.56s. Loss: 2.4423. :   4%|▍         | 1/25 [00:01<00:35,  1.49s/it]Finetune Epoch:  3/ 5. Data: 1.52s. Batch: 1.56s. Loss: 2.4423. :  16%|█▌        | 4/25 [00:01<00:06,  3.14it/s]Finetune Epoch:  3/ 5. Data: 1.54s. Batch: 1.58s. Loss: 2.4413. :  16%|█▌        | 4/25 [00:01<00:06,  3.14it/s]Finetune Epoch:  3/ 5. Data: 1.56s. Batch: 1.61s. Loss: 2.4476. :  16%|█▌        | 4/25 [00:01<00:06,  3.14it/s]Finetune Epoch:  3/ 5. Data: 1.59s. Batch: 1.63s. Loss: 2.4473. :  16%|█▌        | 4/25 [00:01<00:06,  3.14it/s]Finetune Epoch:  3/ 5. Data: 1.59s. Batch: 1.63s. Loss: 2.4473. :  28%|██▊       | 7/25 [00:01<00:03,  5.73it/s]Finetune Epoch:  3/ 5. Data: 1.61s. Batch: 1.65s. Loss: 2.4495. :  28%|██▊       | 7/25 [00:01<00:03,  5.73it/s]Finetune Epoch:  3/ 5. Data: 1.63s. Batch: 1.68s. Loss: 2.4483. :  28%|██▊       | 7/25 [00:01<00:03,  5.73it/s]Finetune Epoch:  3/ 5. Data: 1.66s. Batch: 1.70s. Loss: 2.4512. :  28%|██▊       | 7/25 [00:01<00:03,  5.73it/s]Finetune Epoch:  3/ 5. Data: 1.66s. Batch: 1.70s. Loss: 2.4512. :  40%|████      | 10/25 [00:01<00:01,  8.39it/s]Finetune Epoch:  3/ 5. Data: 1.68s. Batch: 1.73s. Loss: 2.4509. :  40%|████      | 10/25 [00:01<00:01,  8.39it/s]Finetune Epoch:  3/ 5. Data: 1.70s. Batch: 1.75s. Loss: 2.4498. :  40%|████      | 10/25 [00:02<00:01,  8.39it/s]Finetune Epoch:  3/ 5. Data: 1.70s. Batch: 1.75s. Loss: 2.4498. :  48%|████▊     | 12/25 [00:02<00:01, 10.02it/s]Finetune Epoch:  3/ 5. Data: 1.73s. Batch: 1.77s. Loss: 2.4484. :  48%|████▊     | 12/25 [00:02<00:01, 10.02it/s]Finetune Epoch:  3/ 5. Data: 1.75s. Batch: 1.80s. Loss: 2.4484. :  48%|████▊     | 12/25 [00:02<00:01, 10.02it/s]Finetune Epoch:  3/ 5. Data: 1.78s. Batch: 1.82s. Loss: 2.4474. :  48%|████▊     | 12/25 [00:02<00:01, 10.02it/s]Finetune Epoch:  3/ 5. Data: 1.78s. Batch: 1.82s. Loss: 2.4474. :  60%|██████    | 15/25 [00:02<00:00, 12.53it/s]Finetune Epoch:  3/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.4461. :  60%|██████    | 15/25 [00:02<00:00, 12.53it/s]Finetune Epoch:  3/ 5. Data: 1.83s. Batch: 1.88s. Loss: 2.4431. :  60%|██████    | 15/25 [00:02<00:00, 12.53it/s]Finetune Epoch:  3/ 5. Data: 1.83s. Batch: 1.88s. Loss: 2.4431. :  68%|██████▊   | 17/25 [00:02<00:00, 13.31it/s]Finetune Epoch:  3/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.4408. :  68%|██████▊   | 17/25 [00:02<00:00, 13.31it/s]Finetune Epoch:  3/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.4398. :  68%|██████▊   | 17/25 [00:02<00:00, 13.31it/s]Finetune Epoch:  3/ 5. Data: 1.91s. Batch: 1.95s. Loss: 2.4397. :  68%|██████▊   | 17/25 [00:02<00:00, 13.31it/s]Finetune Epoch:  3/ 5. Data: 1.91s. Batch: 1.95s. Loss: 2.4397. :  80%|████████  | 20/25 [00:02<00:00, 15.08it/s]Finetune Epoch:  3/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.4367. :  80%|████████  | 20/25 [00:02<00:00, 15.08it/s]Finetune Epoch:  3/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.4368. :  80%|████████  | 20/25 [00:02<00:00, 15.08it/s]Finetune Epoch:  3/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.4356. :  80%|████████  | 20/25 [00:02<00:00, 15.08it/s]Finetune Epoch:  3/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.4356. :  92%|█████████▏| 23/25 [00:02<00:00, 16.67it/s]Finetune Epoch:  3/ 5. Data: 2.01s. Batch: 2.05s. Loss: 2.4346. :  92%|█████████▏| 23/25 [00:02<00:00, 16.67it/s]Finetune Epoch:  3/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.4333. :  92%|█████████▏| 23/25 [00:02<00:00, 16.67it/s]Finetune Epoch:  3/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.4333. : 100%|██████████| 25/25 [00:02<00:00,  8.77it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.52s. Loss: 2.3533. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.52s. Loss: 2.3533. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.77s. Loss: 2.3080. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.51s. Loss: 2.3010. top1: 0.00. top5: 97.92. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.39s. Loss: 2.3053. top1: 0.00. top5: 98.44. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.31s. Loss: 2.2986. top1: 0.00. top5: 98.75. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.26s. Loss: 2.2819. top1: 0.00. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.2804. top1: 0.00. top5: 99.11. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 2.2737. top1: 0.00. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.2630. top1: 0.00. top5: 99.31. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.2597. top1: 0.00. top5: 99.38. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.2590. top1: 0.00. top5: 99.43. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.2627. top1: 0.00. top5: 99.48. :   2%|▏         | 1/63 [00:01<01:34,  1.52s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.2627. top1: 0.00. top5: 99.48. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.2655. top1: 0.00. top5: 99.52. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.2640. top1: 0.00. top5: 99.55. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.2639. top1: 0.00. top5: 99.58. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.2608. top1: 0.00. top5: 99.41. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.2618. top1: 0.00. top5: 99.45. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.2607. top1: 0.00. top5: 99.48. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.2618. top1: 0.00. top5: 99.51. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.2659. top1: 0.00. top5: 99.53. :  19%|█▉        | 12/63 [00:01<00:05, 10.04it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.2659. top1: 0.00. top5: 99.53. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.2650. top1: 0.00. top5: 99.55. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.2656. top1: 0.00. top5: 99.57. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.2635. top1: 0.00. top5: 99.59. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2604. top1: 0.00. top5: 99.61. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2608. top1: 0.00. top5: 99.38. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2632. top1: 0.00. top5: 99.40. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2638. top1: 0.00. top5: 99.42. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2649. top1: 0.00. top5: 99.44. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2635. top1: 0.00. top5: 99.46. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2647. top1: 0.00. top5: 99.38. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2658. top1: 0.00. top5: 99.40. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2715. top1: 0.00. top5: 99.41. :  32%|███▏      | 20/63 [00:01<00:02, 17.51it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2715. top1: 0.00. top5: 99.41. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2724. top1: 0.00. top5: 99.43. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2752. top1: 0.00. top5: 99.45. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2739. top1: 0.00. top5: 99.46. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2791. top1: 0.00. top5: 99.48. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2819. top1: 0.00. top5: 99.49. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2852. top1: 0.00. top5: 99.51. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2879. top1: 0.00. top5: 99.52. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2911. top1: 0.00. top5: 99.53. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2946. top1: 0.00. top5: 99.54. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2981. top1: 0.00. top5: 99.48. :  51%|█████     | 32/63 [00:01<00:01, 30.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2981. top1: 0.00. top5: 99.48. :  67%|██████▋   | 42/63 [00:01<00:00, 41.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3017. top1: 0.00. top5: 99.49. :  67%|██████▋   | 42/63 [00:01<00:00, 41.98it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3025. top1: 0.07. top5: 99.50. :  67%|██████▋   | 42/63 [00:01<00:00, 41.98it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3038. top1: 0.07. top5: 99.51. :  67%|██████▋   | 42/63 [00:01<00:00, 41.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3052. top1: 0.07. top5: 99.52. :  67%|██████▋   | 42/63 [00:01<00:00, 41.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3076. top1: 0.07. top5: 99.53. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3106. top1: 0.07. top5: 99.54. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3144. top1: 0.06. top5: 99.55. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3167. top1: 0.06. top5: 99.56. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3212. top1: 0.06. top5: 99.57. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3244. top1: 0.06. top5: 99.58. :  67%|██████▋   | 42/63 [00:02<00:00, 41.98it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3244. top1: 0.06. top5: 99.58. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3254. top1: 0.06. top5: 99.59. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3261. top1: 0.06. top5: 99.59. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3287. top1: 0.11. top5: 99.60. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3292. top1: 0.11. top5: 99.61. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3300. top1: 0.16. top5: 99.56. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3293. top1: 0.16. top5: 99.57. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3311. top1: 0.16. top5: 99.58. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3333. top1: 0.16. top5: 99.58. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.3350. top1: 0.15. top5: 99.59. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.3360. top1: 0.15. top5: 99.60. :  83%|████████▎ | 52/63 [00:02<00:00, 50.95it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.3360. top1: 0.15. top5: 99.60. :  98%|█████████▊| 62/63 [00:02<00:00, 60.48it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.3370. top1: 0.15. top5: 99.60. :  98%|█████████▊| 62/63 [00:02<00:00, 60.48it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.3370. top1: 0.15. top5: 99.60. : 100%|██████████| 63/63 [00:02<00:00, 27.11it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.37s. Batch: 1.43s. Loss: 2.3955. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.37s. Batch: 1.43s. Loss: 2.3955. :   4%|▍         | 1/25 [00:01<00:34,  1.43s/it]Finetune Epoch:  4/ 5. Data: 1.40s. Batch: 1.45s. Loss: 2.4215. :   4%|▍         | 1/25 [00:01<00:34,  1.43s/it]Finetune Epoch:  4/ 5. Data: 1.42s. Batch: 1.47s. Loss: 2.4231. :   4%|▍         | 1/25 [00:01<00:34,  1.43s/it]Finetune Epoch:  4/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.4163. :   4%|▍         | 1/25 [00:01<00:34,  1.43s/it]Finetune Epoch:  4/ 5. Data: 1.44s. Batch: 1.49s. Loss: 2.4163. :  16%|█▌        | 4/25 [00:01<00:06,  3.27it/s]Finetune Epoch:  4/ 5. Data: 1.47s. Batch: 1.51s. Loss: 2.4085. :  16%|█▌        | 4/25 [00:01<00:06,  3.27it/s]Finetune Epoch:  4/ 5. Data: 1.49s. Batch: 1.54s. Loss: 2.4036. :  16%|█▌        | 4/25 [00:01<00:06,  3.27it/s]Finetune Epoch:  4/ 5. Data: 1.51s. Batch: 1.56s. Loss: 2.4053. :  16%|█▌        | 4/25 [00:01<00:06,  3.27it/s]Finetune Epoch:  4/ 5. Data: 1.51s. Batch: 1.56s. Loss: 2.4053. :  28%|██▊       | 7/25 [00:01<00:02,  6.07it/s]Finetune Epoch:  4/ 5. Data: 1.54s. Batch: 1.58s. Loss: 2.4063. :  28%|██▊       | 7/25 [00:01<00:02,  6.07it/s]Finetune Epoch:  4/ 5. Data: 1.56s. Batch: 1.61s. Loss: 2.4035. :  28%|██▊       | 7/25 [00:01<00:02,  6.07it/s]Finetune Epoch:  4/ 5. Data: 1.56s. Batch: 1.61s. Loss: 2.4035. :  36%|███▌      | 9/25 [00:01<00:02,  7.90it/s]Finetune Epoch:  4/ 5. Data: 1.58s. Batch: 1.63s. Loss: 2.4046. :  36%|███▌      | 9/25 [00:01<00:02,  7.90it/s]Finetune Epoch:  4/ 5. Data: 1.61s. Batch: 1.65s. Loss: 2.4028. :  36%|███▌      | 9/25 [00:01<00:02,  7.90it/s]Finetune Epoch:  4/ 5. Data: 1.63s. Batch: 1.68s. Loss: 2.3994. :  36%|███▌      | 9/25 [00:01<00:02,  7.90it/s]Finetune Epoch:  4/ 5. Data: 1.63s. Batch: 1.68s. Loss: 2.3994. :  48%|████▊     | 12/25 [00:01<00:01, 10.60it/s]Finetune Epoch:  4/ 5. Data: 1.65s. Batch: 1.70s. Loss: 2.3980. :  48%|████▊     | 12/25 [00:01<00:01, 10.60it/s]Finetune Epoch:  4/ 5. Data: 1.68s. Batch: 1.73s. Loss: 2.3953. :  48%|████▊     | 12/25 [00:02<00:01, 10.60it/s]Finetune Epoch:  4/ 5. Data: 1.68s. Batch: 1.73s. Loss: 2.3953. :  56%|█████▌    | 14/25 [00:02<00:00, 12.17it/s]Finetune Epoch:  4/ 5. Data: 1.70s. Batch: 1.75s. Loss: 2.3937. :  56%|█████▌    | 14/25 [00:02<00:00, 12.17it/s]Finetune Epoch:  4/ 5. Data: 1.73s. Batch: 1.78s. Loss: 2.3930. :  56%|█████▌    | 14/25 [00:02<00:00, 12.17it/s]Finetune Epoch:  4/ 5. Data: 1.73s. Batch: 1.78s. Loss: 2.3930. :  64%|██████▍   | 16/25 [00:02<00:00, 13.45it/s]Finetune Epoch:  4/ 5. Data: 1.75s. Batch: 1.80s. Loss: 2.3919. :  64%|██████▍   | 16/25 [00:02<00:00, 13.45it/s]Finetune Epoch:  4/ 5. Data: 1.78s. Batch: 1.83s. Loss: 2.3910. :  64%|██████▍   | 16/25 [00:02<00:00, 13.45it/s]Finetune Epoch:  4/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.3912. :  64%|██████▍   | 16/25 [00:02<00:00, 13.45it/s]Finetune Epoch:  4/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.3912. :  76%|███████▌  | 19/25 [00:02<00:00, 15.35it/s]Finetune Epoch:  4/ 5. Data: 1.83s. Batch: 1.88s. Loss: 2.3879. :  76%|███████▌  | 19/25 [00:02<00:00, 15.35it/s]Finetune Epoch:  4/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.3872. :  76%|███████▌  | 19/25 [00:02<00:00, 15.35it/s]Finetune Epoch:  4/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.3872. :  84%|████████▍ | 21/25 [00:02<00:00, 16.14it/s]Finetune Epoch:  4/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.3868. :  84%|████████▍ | 21/25 [00:02<00:00, 16.14it/s]Finetune Epoch:  4/ 5. Data: 1.91s. Batch: 1.95s. Loss: 2.3869. :  84%|████████▍ | 21/25 [00:02<00:00, 16.14it/s]Finetune Epoch:  4/ 5. Data: 1.91s. Batch: 1.95s. Loss: 2.3869. :  92%|█████████▏| 23/25 [00:02<00:00, 16.90it/s]Finetune Epoch:  4/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.3852. :  92%|█████████▏| 23/25 [00:02<00:00, 16.90it/s]Finetune Epoch:  4/ 5. Data: 1.96s. Batch: 2.01s. Loss: 2.3818. :  92%|█████████▏| 23/25 [00:02<00:00, 16.90it/s]Finetune Epoch:  4/ 5. Data: 1.96s. Batch: 2.01s. Loss: 2.3818. : 100%|██████████| 25/25 [00:02<00:00, 17.59it/s]Finetune Epoch:  4/ 5. Data: 1.96s. Batch: 2.01s. Loss: 2.3818. : 100%|██████████| 25/25 [00:02<00:00,  8.94it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.51s. Loss: 2.2618. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.51s. Loss: 2.2618. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.79s. Loss: 2.2195. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.53s. Loss: 2.2144. top1: 0.00. top5: 97.92. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.40s. Loss: 2.2147. top1: 0.00. top5: 98.44. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.32s. Loss: 2.2114. top1: 0.00. top5: 98.12. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.27s. Loss: 2.1991. top1: 0.00. top5: 98.44. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.2002. top1: 0.00. top5: 98.66. :   2%|▏         | 1/63 [00:01<01:33,  1.51s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.2002. top1: 0.00. top5: 98.66. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.20s. Loss: 2.1961. top1: 0.00. top5: 98.83. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.1887. top1: 0.00. top5: 98.96. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.1870. top1: 0.00. top5: 99.06. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.1865. top1: 0.00. top5: 99.15. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.1905. top1: 0.00. top5: 99.22. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.1927. top1: 0.00. top5: 99.28. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1902. top1: 0.00. top5: 99.11. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1907. top1: 0.00. top5: 99.17. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1890. top1: 0.20. top5: 99.02. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1889. top1: 0.18. top5: 99.08. :  11%|█         | 7/63 [00:01<00:09,  5.74it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1889. top1: 0.18. top5: 99.08. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1884. top1: 0.17. top5: 99.13. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1899. top1: 0.16. top5: 99.18. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1929. top1: 0.16. top5: 99.22. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1926. top1: 0.15. top5: 99.26. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1924. top1: 0.28. top5: 99.29. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1914. top1: 0.27. top5: 99.32. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1896. top1: 0.26. top5: 99.35. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1898. top1: 0.25. top5: 99.12. :  27%|██▋       | 17/63 [00:01<00:02, 15.86it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1898. top1: 0.25. top5: 99.12. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1919. top1: 0.24. top5: 99.16. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1922. top1: 0.23. top5: 99.19. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1930. top1: 0.22. top5: 99.22. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1913. top1: 0.22. top5: 99.25. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1923. top1: 0.21. top5: 99.27. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1931. top1: 0.30. top5: 99.29. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1933. top1: 0.29. top5: 99.32. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1894. top1: 0.28. top5: 99.34. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1878. top1: 0.37. top5: 99.36. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1835. top1: 0.54. top5: 99.38. :  40%|███▉      | 25/63 [00:01<00:01, 24.29it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1835. top1: 0.54. top5: 99.38. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1849. top1: 0.52. top5: 99.39. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1834. top1: 0.51. top5: 99.41. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1828. top1: 0.58. top5: 99.42. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1818. top1: 0.56. top5: 99.44. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1806. top1: 0.55. top5: 99.45. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1798. top1: 0.53. top5: 99.47. :  56%|█████▌    | 35/63 [00:01<00:00, 36.01it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1794. top1: 0.60. top5: 99.40. :  56%|█████▌    | 35/63 [00:02<00:00, 36.01it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1796. top1: 0.58. top5: 99.42. :  56%|█████▌    | 35/63 [00:02<00:00, 36.01it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1778. top1: 0.64. top5: 99.43. :  56%|█████▌    | 35/63 [00:02<00:00, 36.01it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1758. top1: 0.69. top5: 99.44. :  56%|█████▌    | 35/63 [00:02<00:00, 36.01it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1744. top1: 0.75. top5: 99.46. :  56%|█████▌    | 35/63 [00:02<00:00, 36.01it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1744. top1: 0.75. top5: 99.46. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1744. top1: 0.73. top5: 99.47. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1746. top1: 0.85. top5: 99.48. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1756. top1: 0.89. top5: 99.49. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1752. top1: 0.88. top5: 99.50. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1771. top1: 0.86. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1774. top1: 0.90. top5: 99.52. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1761. top1: 0.94. top5: 99.53. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1749. top1: 0.93. top5: 99.54. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1756. top1: 0.97. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1746. top1: 0.95. top5: 99.55. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1745. top1: 0.99. top5: 99.51. :  73%|███████▎  | 46/63 [00:02<00:00, 48.62it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1745. top1: 0.99. top5: 99.51. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1729. top1: 1.02. top5: 99.52. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1735. top1: 1.06. top5: 99.52. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1733. top1: 1.04. top5: 99.53. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1734. top1: 1.02. top5: 99.54. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1734. top1: 1.11. top5: 99.55. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1736. top1: 1.10. top5: 99.55. :  90%|█████████ | 57/63 [00:02<00:00, 60.40it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1736. top1: 1.10. top5: 99.55. : 100%|██████████| 63/63 [00:02<00:00, 26.45it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.44s. Batch: 1.48s. Loss: 2.3453. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.44s. Batch: 1.48s. Loss: 2.3453. :   4%|▍         | 1/25 [00:01<00:35,  1.48s/it]Finetune Epoch:  5/ 5. Data: 1.46s. Batch: 1.51s. Loss: 2.3414. :   4%|▍         | 1/25 [00:01<00:35,  1.48s/it]Finetune Epoch:  5/ 5. Data: 1.48s. Batch: 1.53s. Loss: 2.3517. :   4%|▍         | 1/25 [00:01<00:35,  1.48s/it]Finetune Epoch:  5/ 5. Data: 1.51s. Batch: 1.55s. Loss: 2.3492. :   4%|▍         | 1/25 [00:01<00:35,  1.48s/it]Finetune Epoch:  5/ 5. Data: 1.51s. Batch: 1.55s. Loss: 2.3492. :  16%|█▌        | 4/25 [00:01<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 1.54s. Batch: 1.58s. Loss: 2.3542. :  16%|█▌        | 4/25 [00:01<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 1.56s. Batch: 1.61s. Loss: 2.3522. :  16%|█▌        | 4/25 [00:01<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 1.56s. Batch: 1.61s. Loss: 2.3522. :  24%|██▍       | 6/25 [00:01<00:03,  4.85it/s]Finetune Epoch:  5/ 5. Data: 1.59s. Batch: 1.64s. Loss: 2.3589. :  24%|██▍       | 6/25 [00:01<00:03,  4.85it/s]Finetune Epoch:  5/ 5. Data: 1.62s. Batch: 1.66s. Loss: 2.3553. :  24%|██▍       | 6/25 [00:01<00:03,  4.85it/s]Finetune Epoch:  5/ 5. Data: 1.62s. Batch: 1.66s. Loss: 2.3553. :  32%|███▏      | 8/25 [00:01<00:02,  6.82it/s]Finetune Epoch:  5/ 5. Data: 1.64s. Batch: 1.69s. Loss: 2.3529. :  32%|███▏      | 8/25 [00:01<00:02,  6.82it/s]Finetune Epoch:  5/ 5. Data: 1.67s. Batch: 1.72s. Loss: 2.3529. :  32%|███▏      | 8/25 [00:01<00:02,  6.82it/s]Finetune Epoch:  5/ 5. Data: 1.67s. Batch: 1.72s. Loss: 2.3529. :  40%|████      | 10/25 [00:01<00:01,  8.88it/s]Finetune Epoch:  5/ 5. Data: 1.70s. Batch: 1.74s. Loss: 2.3550. :  40%|████      | 10/25 [00:02<00:01,  8.88it/s]Finetune Epoch:  5/ 5. Data: 1.72s. Batch: 1.77s. Loss: 2.3504. :  40%|████      | 10/25 [00:02<00:01,  8.88it/s]Finetune Epoch:  5/ 5. Data: 1.72s. Batch: 1.77s. Loss: 2.3504. :  48%|████▊     | 12/25 [00:02<00:01, 10.85it/s]Finetune Epoch:  5/ 5. Data: 1.75s. Batch: 1.80s. Loss: 2.3487. :  48%|████▊     | 12/25 [00:02<00:01, 10.85it/s]Finetune Epoch:  5/ 5. Data: 1.77s. Batch: 1.82s. Loss: 2.3469. :  48%|████▊     | 12/25 [00:02<00:01, 10.85it/s]Finetune Epoch:  5/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.3460. :  48%|████▊     | 12/25 [00:02<00:01, 10.85it/s]Finetune Epoch:  5/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.3460. :  60%|██████    | 15/25 [00:02<00:00, 13.65it/s]Finetune Epoch:  5/ 5. Data: 1.82s. Batch: 1.87s. Loss: 2.3440. :  60%|██████    | 15/25 [00:02<00:00, 13.65it/s]Finetune Epoch:  5/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.3434. :  60%|██████    | 15/25 [00:02<00:00, 13.65it/s]Finetune Epoch:  5/ 5. Data: 1.85s. Batch: 1.90s. Loss: 2.3434. :  68%|██████▊   | 17/25 [00:02<00:00, 14.29it/s]Finetune Epoch:  5/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.3427. :  68%|██████▊   | 17/25 [00:02<00:00, 14.29it/s]Finetune Epoch:  5/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.3426. :  68%|██████▊   | 17/25 [00:02<00:00, 14.29it/s]Finetune Epoch:  5/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.3426. :  76%|███████▌  | 19/25 [00:02<00:00, 15.45it/s]Finetune Epoch:  5/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.3410. :  76%|███████▌  | 19/25 [00:02<00:00, 15.45it/s]Finetune Epoch:  5/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.3396. :  76%|███████▌  | 19/25 [00:02<00:00, 15.45it/s]Finetune Epoch:  5/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.3383. :  76%|███████▌  | 19/25 [00:02<00:00, 15.45it/s]Finetune Epoch:  5/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.3383. :  88%|████████▊ | 22/25 [00:02<00:00, 17.94it/s]Finetune Epoch:  5/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.3388. :  88%|████████▊ | 22/25 [00:02<00:00, 17.94it/s]Finetune Epoch:  5/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.3395. :  88%|████████▊ | 22/25 [00:02<00:00, 17.94it/s]Finetune Epoch:  5/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.3364. :  88%|████████▊ | 22/25 [00:02<00:00, 17.94it/s]Finetune Epoch:  5/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.3364. : 100%|██████████| 25/25 [00:02<00:00, 18.67it/s]Finetune Epoch:  5/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.3364. : 100%|██████████| 25/25 [00:02<00:00,  8.74it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.41s. Loss: 2.2053. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.41s. Loss: 2.2053. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.72s. Loss: 2.1654. top1: 1.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.49s. Loss: 2.1609. top1: 2.08. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.37s. Loss: 2.1596. top1: 1.56. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.30s. Loss: 2.1581. top1: 1.25. top5: 98.75. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.1493. top1: 1.04. top5: 98.96. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.1519. top1: 0.89. top5: 99.11. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.1493. top1: 0.78. top5: 99.22. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.1440. top1: 1.04. top5: 99.31. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.1433. top1: 0.94. top5: 99.38. :   2%|▏         | 1/63 [00:01<01:27,  1.42s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.1433. top1: 0.94. top5: 99.38. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.1427. top1: 0.85. top5: 99.43. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.1468. top1: 0.78. top5: 99.48. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.1486. top1: 0.72. top5: 99.52. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.1455. top1: 0.67. top5: 99.33. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1462. top1: 0.62. top5: 99.38. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.1454. top1: 0.78. top5: 99.41. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1448. top1: 0.74. top5: 99.45. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1447. top1: 0.69. top5: 99.48. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.1463. top1: 0.66. top5: 99.51. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1486. top1: 0.62. top5: 99.53. :  16%|█▌        | 10/63 [00:01<00:06,  8.83it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1486. top1: 0.62. top5: 99.53. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1485. top1: 0.60. top5: 99.55. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.1478. top1: 0.71. top5: 99.57. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1474. top1: 0.68. top5: 99.59. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1464. top1: 0.65. top5: 99.61. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1466. top1: 0.62. top5: 99.50. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1485. top1: 0.60. top5: 99.52. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1486. top1: 0.58. top5: 99.54. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1492. top1: 0.56. top5: 99.55. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1476. top1: 0.54. top5: 99.57. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1484. top1: 0.62. top5: 99.58. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1491. top1: 0.71. top5: 99.60. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1455. top1: 0.88. top5: 99.61. :  32%|███▏      | 20/63 [00:01<00:02, 19.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1455. top1: 0.88. top5: 99.61. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1385. top1: 1.04. top5: 99.62. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1338. top1: 1.38. top5: 99.63. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1275. top1: 1.79. top5: 99.64. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1264. top1: 1.91. top5: 99.65. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1220. top1: 1.94. top5: 99.66. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1187. top1: 2.14. top5: 99.67. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1152. top1: 2.32. top5: 99.68. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1112. top1: 2.50. top5: 99.69. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1075. top1: 2.74. top5: 99.70. :  51%|█████     | 32/63 [00:01<00:00, 33.02it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1075. top1: 2.74. top5: 99.70. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1043. top1: 2.98. top5: 99.63. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1023. top1: 2.98. top5: 99.64. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0987. top1: 3.20. top5: 99.64. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0945. top1: 3.33. top5: 99.65. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0914. top1: 3.46. top5: 99.66. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0897. top1: 3.52. top5: 99.67. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0879. top1: 3.71. top5: 99.67. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0869. top1: 3.76. top5: 99.68. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0846. top1: 3.94. top5: 99.69. :  65%|██████▌   | 41/63 [00:01<00:00, 41.98it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0846. top1: 3.94. top5: 99.69. :  79%|███████▉  | 50/63 [00:01<00:00, 50.34it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0847. top1: 3.92. top5: 99.69. :  79%|███████▉  | 50/63 [00:01<00:00, 50.34it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0831. top1: 3.91. top5: 99.70. :  79%|███████▉  | 50/63 [00:01<00:00, 50.34it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0803. top1: 4.07. top5: 99.71. :  79%|███████▉  | 50/63 [00:01<00:00, 50.34it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0778. top1: 4.22. top5: 99.71. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0772. top1: 4.32. top5: 99.72. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0752. top1: 4.41. top5: 99.72. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0743. top1: 4.44. top5: 99.67. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0721. top1: 4.63. top5: 99.68. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0719. top1: 4.71. top5: 99.68. :  79%|███████▉  | 50/63 [00:02<00:00, 50.34it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.0719. top1: 4.71. top5: 99.68. :  94%|█████████▎| 59/63 [00:02<00:00, 55.89it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.0701. top1: 4.69. top5: 99.69. :  94%|█████████▎| 59/63 [00:02<00:00, 55.89it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.0691. top1: 4.82. top5: 99.69. :  94%|█████████▎| 59/63 [00:02<00:00, 55.89it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.0684. top1: 4.94. top5: 99.70. :  94%|█████████▎| 59/63 [00:02<00:00, 55.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.0681. top1: 4.90. top5: 99.70. :  94%|█████████▎| 59/63 [00:02<00:00, 55.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.03s. Loss: 2.0681. top1: 4.90. top5: 99.70. : 100%|██████████| 63/63 [00:02<00:00, 27.48it/s]
total 9984 correct 5019 accuracy 50.270432692307686
[INFO] main.py:349 > [2-2] Set environment for the current task
[INFO] finetune.py:104 > Apply before_task
[INFO] finetune.py:146 > Reset the optimizer and scheduler states
[INFO] finetune.py:152 > Increasing the head of fc 2 -> 10
[INFO] main.py:357 > [2-3] Start to train under online
[INFO] main.py:372 > Train over streamed data once
batch_size : 128 stream_batch_size : 64 memory_batch_size : 42 pseudo_stream_size 64
num_stuff 156
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
image shape torch.Size([64, 3, 32, 32])
[INFO] rainbow_memory.py:120 > Streamed samples: 800
[INFO] rainbow_memory.py:121 > In-memory samples: 0
[INFO] rainbow_memory.py:122 > Pseudo samples: 9984
[INFO] rainbow_memory.py:128 > Train samples: 10784
[INFO] rainbow_memory.py:129 > Test samples: 2000
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
two
stream torch.Size([64, 3, 32, 32]) pseudo torch.Size([64, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
count 12
task0/train/loss 5.886258487900098 0
task0/test/loss 1.455396623001434 0
task0/test/acc 0.561 0
task0/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 0 | Epoch 1/1 | train_loss 5.8863 | train_acc 0.8052 | test_loss 1.4554 | test_acc 0.5610 | lr 0.0050
[INFO] finetune.py:169 > Update memory over 10 classes by uncertainty
uncertainty
[WARNING] finetune.py:736 > Fill the unused slots by breaking the equilibrium.
[INFO] finetune.py:223 > Memory statistic
[INFO] finetune.py:225 > 
deer    277
dog     223
Name: klass, dtype: int64
[INFO] main.py:388 > Train over memory
batch_size : 64 stream_batch_size : 22 memory_batch_size : 21 pseudo_stream_size 21
num_stuff 0
[INFO] rainbow_memory.py:120 > Streamed samples: 0
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 0
[INFO] rainbow_memory.py:128 > Train samples: 500
[INFO] rainbow_memory.py:129 > Test samples: 2000
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task0/train/loss 0.9289014711976051 0
task0/test/loss 0.8196465608837841 0
task0/test/acc 0.5135 0
task0/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 0 | Epoch 1/2 | train_loss 0.9289 | train_acc 0.5520 | test_loss 0.8196 | test_acc 0.5135 | lr 0.0050
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task0/train/loss 6.8713627606630325 1
task0/test/loss 7.31785401898426 1
task0/test/acc 0.58 1
task0/train/lr 0.05 1
[INFO] rainbow_memory.py:184 > Task 0 | Epoch 2/2 | train_loss 6.8714 | train_acc 0.4820 | test_loss 7.3179 | test_acc 0.5800 | lr 0.0500
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (0)
[INFO] main.py:398 > [2-4] Update the information for the current task
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (0)
[INFO] main.py:405 > [2-5] Report task result
Metrics/TaskAcc 0.58 0

##################################################
# Task 1 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 30  current step :  0
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.10s. Batch: 0.23s. S_Loss: 2.3040. T_Loss: 2.4844. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.10s. Batch: 0.23s. S_Loss: 2.3040. T_Loss: 2.4844. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  4.20it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.09s. Batch: 0.22s. S_Loss: 2.3853. T_Loss: 2.3958. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  4.20it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.09s. Batch: 0.22s. S_Loss: 2.3853. T_Loss: 2.3958. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.39it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.06s. Batch: 0.19s. S_Loss: 2.4022. T_Loss: 2.4042. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.39it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.06s. Batch: 0.19s. S_Loss: 2.4022. T_Loss: 2.4042. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.68it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.4136. T_Loss: 2.4499. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.68it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.4136. T_Loss: 2.4499. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.65it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.16s. S_Loss: 2.3853. T_Loss: 2.4472. Mask: 0.0063. :  40%|████      | 4/10 [00:00<00:00,  6.65it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.16s. S_Loss: 2.3853. T_Loss: 2.4472. Mask: 0.0063. :  50%|█████     | 5/10 [00:00<00:00,  7.32it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3985. T_Loss: 2.4334. Mask: 0.0052. :  50%|█████     | 5/10 [00:00<00:00,  7.32it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3985. T_Loss: 2.4334. Mask: 0.0052. :  60%|██████    | 6/10 [00:00<00:00,  7.58it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3847. T_Loss: 2.4352. Mask: 0.0045. :  60%|██████    | 6/10 [00:01<00:00,  7.58it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3847. T_Loss: 2.4352. Mask: 0.0045. :  70%|███████   | 7/10 [00:01<00:00,  7.95it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3621. T_Loss: 2.4063. Mask: 0.0039. :  70%|███████   | 7/10 [00:01<00:00,  7.95it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3621. T_Loss: 2.4063. Mask: 0.0039. :  80%|████████  | 8/10 [00:01<00:00,  8.11it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3766. T_Loss: 2.4025. Mask: 0.0035. :  80%|████████  | 8/10 [00:01<00:00,  8.11it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3766. T_Loss: 2.4025. Mask: 0.0035. :  90%|█████████ | 9/10 [00:01<00:00,  8.30it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3827. T_Loss: 2.3902. Mask: 0.0031. :  90%|█████████ | 9/10 [00:01<00:00,  8.30it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3827. T_Loss: 2.3902. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  8.45it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3827. T_Loss: 2.3902. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  7.25it/s]
total : 30  current step :  1
total : 30  current step :  2
total : 30  current step :  3
total : 30  current step :  4
total : 30  current step :  5
total : 30  current step :  6
total : 30  current step :  7
total : 30  current step :  8
total : 30  current step :  9
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 5.9456. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 5.9456. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 5.9547. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 5.7555. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 5.7282. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 5.7441. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 5.7455. top1: 0.52. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 5.7549. top1: 0.45. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 5.8411. top1: 0.78. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 5.8411. top1: 0.78. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 5.8302. top1: 0.69. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 5.8386. top1: 0.62. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 5.8753. top1: 0.57. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 5.8743. top1: 0.78. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 5.8651. top1: 0.96. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.9266. top1: 1.12. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.8859. top1: 1.04. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.8385. top1: 0.98. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.8385. top1: 0.98. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.8563. top1: 1.10. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.8932. top1: 1.22. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.8726. top1: 1.32. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.8548. top1: 1.25. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.8793. top1: 1.34. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.9221. top1: 1.28. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.9251. top1: 1.49. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.9081. top1: 1.43. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9325. top1: 1.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9223. top1: 1.44. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9214. top1: 1.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.32it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9214. top1: 1.50. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9201. top1: 1.45. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.9085. top1: 1.51. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.9272. top1: 1.46. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.9228. top1: 1.41. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.3148. top1: 1.46. top5: 97.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.7170. top1: 1.42. top5: 94.70. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 7.1191. top1: 1.38. top5: 91.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.5299. top1: 1.34. top5: 89.29. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.9386. top1: 1.30. top5: 86.81. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.3050. top1: 1.27. top5: 84.46. :  43%|████▎     | 27/63 [00:02<00:01, 23.24it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.3050. top1: 1.27. top5: 84.46. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.6038. top1: 1.23. top5: 82.24. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.9592. top1: 1.20. top5: 80.13. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 9.2499. top1: 1.17. top5: 78.12. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 9.5102. top1: 1.14. top5: 76.22. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 9.7509. top1: 1.12. top5: 74.40. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.0125. top1: 1.09. top5: 72.67. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.2344. top1: 1.07. top5: 71.02. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.4834. top1: 1.04. top5: 69.44. :  59%|█████▊    | 37/63 [00:02<00:00, 33.92it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.4834. top1: 1.04. top5: 69.44. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.7898. top1: 1.02. top5: 67.93. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.0546. top1: 1.00. top5: 66.49. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.2532. top1: 0.98. top5: 65.10. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.4577. top1: 0.96. top5: 63.78. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.6633. top1: 0.94. top5: 62.50. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 11.8371. top1: 0.92. top5: 61.27. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.0426. top1: 0.90. top5: 60.10. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.2144. top1: 0.88. top5: 58.96. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.3750. top1: 0.87. top5: 57.87. :  71%|███████▏  | 45/63 [00:02<00:00, 40.99it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.3750. top1: 0.87. top5: 57.87. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4953. top1: 0.85. top5: 56.82. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6357. top1: 0.84. top5: 55.80. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.8255. top1: 0.82. top5: 54.82. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.9664. top1: 0.81. top5: 53.88. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.1563. top1: 0.79. top5: 52.97. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.2953. top1: 0.78. top5: 52.08. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.4174. top1: 0.77. top5: 51.23. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.5508. top1: 0.76. top5: 50.40. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.6245. top1: 0.75. top5: 50.00. :  86%|████████▌ | 54/63 [00:02<00:00, 49.42it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 13.6245. top1: 0.75. top5: 50.00. : 100%|██████████| 63/63 [00:02<00:00, 22.78it/s]
total : 30  current step :  10
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2964. T_Loss: 2.0592. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2964. T_Loss: 2.0592. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  8.09it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2595. T_Loss: 2.1467. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  8.09it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2595. T_Loss: 2.1467. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  7.73it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2891. T_Loss: 2.1307. Mask: 0.0104. :  20%|██        | 2/10 [00:00<00:01,  7.73it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2846. T_Loss: 2.1216. Mask: 0.0078. :  30%|███       | 3/10 [00:00<00:00,  7.73it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2846. T_Loss: 2.1216. Mask: 0.0078. :  40%|████      | 4/10 [00:00<00:00,  8.75it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2831. T_Loss: 2.1464. Mask: 0.0125. :  40%|████      | 4/10 [00:00<00:00,  8.75it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2831. T_Loss: 2.1464. Mask: 0.0125. :  50%|█████     | 5/10 [00:00<00:00,  8.59it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3064. T_Loss: 2.1195. Mask: 0.0104. :  50%|█████     | 5/10 [00:00<00:00,  8.59it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3064. T_Loss: 2.1195. Mask: 0.0104. :  60%|██████    | 6/10 [00:00<00:00,  7.60it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3173. T_Loss: 2.0814. Mask: 0.0089. :  60%|██████    | 6/10 [00:00<00:00,  7.60it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3173. T_Loss: 2.0814. Mask: 0.0089. :  70%|███████   | 7/10 [00:00<00:00,  7.74it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3000. T_Loss: 2.0549. Mask: 0.0156. :  70%|███████   | 7/10 [00:00<00:00,  7.74it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.3000. T_Loss: 2.0549. Mask: 0.0156. :  80%|████████  | 8/10 [00:00<00:00,  7.98it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.2845. T_Loss: 2.0420. Mask: 0.0208. :  80%|████████  | 8/10 [00:01<00:00,  7.98it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.2845. T_Loss: 2.0420. Mask: 0.0208. :  90%|█████████ | 9/10 [00:01<00:00,  7.80it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.2721. T_Loss: 2.0280. Mask: 0.0250. :  90%|█████████ | 9/10 [00:01<00:00,  7.80it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.2721. T_Loss: 2.0280. Mask: 0.0250. : 100%|██████████| 10/10 [00:01<00:00,  7.84it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.12s. S_Loss: 2.2721. T_Loss: 2.0280. Mask: 0.0250. : 100%|██████████| 10/10 [00:01<00:00,  7.96it/s]
total : 30  current step :  11
total : 30  current step :  12
total : 30  current step :  13
total : 30  current step :  14
total : 30  current step :  15
total : 30  current step :  16
total : 30  current step :  17
total : 30  current step :  18
total : 30  current step :  19
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 5.1367. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.87s. Loss: 5.1367. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.95s. Loss: 5.1559. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 4.9981. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 4.9700. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 4.9805. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 4.9848. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 4.9985. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 5.0712. top1: 0.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 5.0576. top1: 0.35. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:56,  1.88s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 5.0576. top1: 0.35. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.13it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 5.0677. top1: 0.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.13it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 5.1062. top1: 0.28. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 5.1066. top1: 0.52. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 5.1029. top1: 0.72. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 5.1545. top1: 0.67. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.1173. top1: 0.62. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.0739. top1: 0.59. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.13it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.0739. top1: 0.59. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.0882. top1: 0.55. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.1214. top1: 0.52. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.1026. top1: 0.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.0889. top1: 0.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.1090. top1: 0.74. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.1433. top1: 0.71. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.1472. top1: 0.82. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.1317. top1: 0.78. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.1501. top1: 0.75. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.1414. top1: 0.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.1409. top1: 0.81. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.86it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.1409. top1: 0.81. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.1401. top1: 0.78. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.1309. top1: 0.75. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.1462. top1: 0.73. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.1412. top1: 0.71. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.4274. top1: 0.68. top5: 97.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.7142. top1: 0.66. top5: 94.70. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.0039. top1: 0.64. top5: 91.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.3013. top1: 0.62. top5: 89.29. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.5996. top1: 0.61. top5: 86.81. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.8657. top1: 0.59. top5: 84.46. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.0799. top1: 0.58. top5: 82.24. :  43%|████▎     | 27/63 [00:02<00:01, 23.07it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.0799. top1: 0.58. top5: 82.24. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.3377. top1: 0.56. top5: 80.13. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.5471. top1: 0.55. top5: 78.12. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.7338. top1: 0.53. top5: 76.22. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.9059. top1: 0.52. top5: 74.40. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.0944. top1: 0.51. top5: 72.67. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.2530. top1: 0.50. top5: 71.02. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.4343. top1: 0.49. top5: 69.44. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.6610. top1: 0.48. top5: 67.93. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.8544. top1: 0.47. top5: 66.49. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.9974. top1: 0.46. top5: 65.10. :  60%|██████    | 38/63 [00:02<00:00, 35.18it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.9974. top1: 0.46. top5: 65.10. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.1451. top1: 0.45. top5: 63.78. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.2947. top1: 0.44. top5: 62.50. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.4203. top1: 0.43. top5: 61.27. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.5700. top1: 0.42. top5: 60.10. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.6938. top1: 0.41. top5: 58.96. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.8087. top1: 0.41. top5: 57.87. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.8934. top1: 0.40. top5: 56.82. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.9935. top1: 0.39. top5: 55.80. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.1334. top1: 0.38. top5: 54.82. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.2354. top1: 0.38. top5: 53.88. :  76%|███████▌  | 48/63 [00:02<00:00, 45.97it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.2354. top1: 0.38. top5: 53.88. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.3771. top1: 0.37. top5: 52.97. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.4771. top1: 0.36. top5: 52.08. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.5659. top1: 0.36. top5: 51.23. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.6631. top1: 0.35. top5: 50.40. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.7170. top1: 0.35. top5: 50.00. :  92%|█████████▏| 58/63 [00:02<00:00, 56.06it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 10.7170. top1: 0.35. top5: 50.00. : 100%|██████████| 63/63 [00:02<00:00, 22.87it/s]
total : 30  current step :  20
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3027. T_Loss: 1.5577. Mask: 0.0312. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3027. T_Loss: 1.5577. Mask: 0.0312. :  10%|█         | 1/10 [00:00<00:01,  8.42it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3239. T_Loss: 1.6299. Mask: 0.0625. :  10%|█         | 1/10 [00:00<00:01,  8.42it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3239. T_Loss: 1.6299. Mask: 0.0625. :  20%|██        | 2/10 [00:00<00:00,  8.42it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3107. T_Loss: 1.6817. Mask: 0.0521. :  20%|██        | 2/10 [00:00<00:00,  8.42it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.3107. T_Loss: 1.6817. Mask: 0.0521. :  30%|███       | 3/10 [00:00<00:00,  8.35it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2830. T_Loss: 1.6815. Mask: 0.0859. :  30%|███       | 3/10 [00:00<00:00,  8.35it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2830. T_Loss: 1.6815. Mask: 0.0859. :  40%|████      | 4/10 [00:00<00:00,  8.35it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2572. T_Loss: 1.6641. Mask: 0.1187. :  40%|████      | 4/10 [00:00<00:00,  8.35it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2572. T_Loss: 1.6641. Mask: 0.1187. :  50%|█████     | 5/10 [00:00<00:00,  8.38it/s]total : 30  current step :  21
total : 30  current step :  22
total : 30  current step :  23
total : 30  current step :  24
total : 30  current step :  25
Train Iter:  26/ 30. LR: 0.0000. Data: 0.32s. Batch: 0.45s. S_Loss: 2.2442. T_Loss: 1.6622. Mask: 0.1458. :  50%|█████     | 5/10 [00:02<00:00,  8.38it/s]Train Iter:  26/ 30. LR: 0.0000. Data: 0.32s. Batch: 0.45s. S_Loss: 2.2442. T_Loss: 1.6622. Mask: 0.1458. :  60%|██████    | 6/10 [00:02<00:03,  1.27it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.28s. Batch: 0.40s. S_Loss: 2.2421. T_Loss: 1.6524. Mask: 0.1696. :  60%|██████    | 6/10 [00:02<00:03,  1.27it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.28s. Batch: 0.40s. S_Loss: 2.2421. T_Loss: 1.6524. Mask: 0.1696. :  70%|███████   | 7/10 [00:02<00:01,  1.76it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.36s. S_Loss: 2.2453. T_Loss: 1.6461. Mask: 0.1953. :  70%|███████   | 7/10 [00:02<00:01,  1.76it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.36s. S_Loss: 2.2453. T_Loss: 1.6461. Mask: 0.1953. :  80%|████████  | 8/10 [00:02<00:00,  2.34it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.22s. Batch: 0.34s. S_Loss: 2.2510. T_Loss: 1.6446. Mask: 0.2361. :  80%|████████  | 8/10 [00:03<00:00,  2.34it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.22s. Batch: 0.34s. S_Loss: 2.2510. T_Loss: 1.6446. Mask: 0.2361. :  90%|█████████ | 9/10 [00:03<00:00,  3.01it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.20s. Batch: 0.32s. S_Loss: 2.2559. T_Loss: 1.6310. Mask: 0.2656. :  90%|█████████ | 9/10 [00:03<00:00,  3.01it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.20s. Batch: 0.32s. S_Loss: 2.2559. T_Loss: 1.6310. Mask: 0.2656. : 100%|██████████| 10/10 [00:03<00:00,  3.73it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.20s. Batch: 0.32s. S_Loss: 2.2559. T_Loss: 1.6310. Mask: 0.2656. : 100%|██████████| 10/10 [00:03<00:00,  3.15it/s]
total : 30  current step :  26
total : 30  current step :  27
total : 30  current step :  28
total : 30  current step :  29
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 4.3905. top1: 0.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 4.3905. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 4.4023. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 4.2765. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 4.2493. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 4.2567. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 4.2608. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 4.2748. top1: 0.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 4.3346. top1: 0.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 4.3209. top1: 0.35. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 4.3209. top1: 0.35. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 4.3312. top1: 0.31. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 4.3690. top1: 0.28. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 4.3696. top1: 0.52. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 4.3696. top1: 0.48. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 4.4128. top1: 0.45. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.3793. top1: 0.42. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.28it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.3408. top1: 0.39. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.28it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.3525. top1: 0.37. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.28it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.3525. top1: 0.37. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.3820. top1: 0.35. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.3661. top1: 0.33. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.3558. top1: 0.31. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.3723. top1: 0.30. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.4000. top1: 0.28. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.4038. top1: 0.27. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.3898. top1: 0.26. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.4043. top1: 0.25. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.3970. top1: 0.24. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.3965. top1: 0.35. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.07it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.3965. top1: 0.35. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.3957. top1: 0.33. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.3883. top1: 0.32. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.4009. top1: 0.31. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.3958. top1: 0.30. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6129. top1: 0.29. top5: 97.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.8256. top1: 0.28. top5: 94.70. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.0430. top1: 0.28. top5: 91.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.2671. top1: 0.27. top5: 89.29. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.4937. top1: 0.26. top5: 86.81. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.6948. top1: 0.25. top5: 84.46. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.8554. top1: 0.25. top5: 82.24. :  43%|████▎     | 27/63 [00:02<00:01, 23.13it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.8554. top1: 0.25. top5: 82.24. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.0498. top1: 0.24. top5: 80.13. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.2068. top1: 0.23. top5: 78.12. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.3465. top1: 0.23. top5: 76.22. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.4749. top1: 0.22. top5: 74.40. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.6161. top1: 0.22. top5: 72.67. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.7342. top1: 0.21. top5: 71.02. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.8712. top1: 0.21. top5: 69.44. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.0449. top1: 0.20. top5: 67.93. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.1914. top1: 0.20. top5: 66.49. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.2987. top1: 0.20. top5: 65.10. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.4095. top1: 0.19. top5: 63.78. :  60%|██████    | 38/63 [00:02<00:00, 35.34it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.4095. top1: 0.19. top5: 63.78. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.5227. top1: 0.19. top5: 62.50. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.6170. top1: 0.18. top5: 61.27. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.7303. top1: 0.18. top5: 60.10. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.8231. top1: 0.18. top5: 58.96. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.9087. top1: 0.17. top5: 57.87. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.9714. top1: 0.17. top5: 56.82. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.0455. top1: 0.17. top5: 55.80. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.1523. top1: 0.16. top5: 54.82. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.2290. top1: 0.16. top5: 53.88. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.3383. top1: 0.16. top5: 52.97. :  78%|███████▊  | 49/63 [00:02<00:00, 46.37it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.3383. top1: 0.16. top5: 52.97. :  94%|█████████▎| 59/63 [00:02<00:00, 55.73it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.4133. top1: 0.16. top5: 52.08. :  94%|█████████▎| 59/63 [00:02<00:00, 55.73it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.4807. top1: 0.15. top5: 51.23. :  94%|█████████▎| 59/63 [00:02<00:00, 55.73it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.5542. top1: 0.15. top5: 50.40. :  94%|█████████▎| 59/63 [00:02<00:00, 55.73it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.5951. top1: 0.15. top5: 50.00. :  94%|█████████▎| 59/63 [00:02<00:00, 55.73it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.5951. top1: 0.15. top5: 50.00. : 100%|██████████| 63/63 [00:02<00:00, 23.06it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.1770. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.1770. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.84s. Batch: 1.88s. Loss: 2.1603. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.86s. Batch: 1.90s. Loss: 2.1501. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.92s. Loss: 2.1400. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.92s. Loss: 2.1400. :  16%|█▌        | 4/25 [00:01<00:08,  2.58it/s]Finetune Epoch:  1/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.1390. :  16%|█▌        | 4/25 [00:02<00:08,  2.58it/s]Finetune Epoch:  1/ 5. Data: 1.93s. Batch: 1.97s. Loss: 2.1418. :  16%|█▌        | 4/25 [00:02<00:08,  2.58it/s]Finetune Epoch:  1/ 5. Data: 1.95s. Batch: 1.99s. Loss: 2.1363. :  16%|█▌        | 4/25 [00:02<00:08,  2.58it/s]Finetune Epoch:  1/ 5. Data: 1.95s. Batch: 1.99s. Loss: 2.1363. :  28%|██▊       | 7/25 [00:02<00:03,  4.92it/s]Finetune Epoch:  1/ 5. Data: 1.97s. Batch: 2.01s. Loss: 2.1431. :  28%|██▊       | 7/25 [00:02<00:03,  4.92it/s]Finetune Epoch:  1/ 5. Data: 1.99s. Batch: 2.04s. Loss: 2.1437. :  28%|██▊       | 7/25 [00:02<00:03,  4.92it/s]Finetune Epoch:  1/ 5. Data: 2.02s. Batch: 2.06s. Loss: 2.1408. :  28%|██▊       | 7/25 [00:02<00:03,  4.92it/s]Finetune Epoch:  1/ 5. Data: 2.02s. Batch: 2.06s. Loss: 2.1408. :  40%|████      | 10/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  1/ 5. Data: 2.04s. Batch: 2.08s. Loss: 2.1415. :  40%|████      | 10/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  1/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.1461. :  40%|████      | 10/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  1/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.1461. :  48%|████▊     | 12/25 [00:02<00:01,  8.95it/s]Finetune Epoch:  1/ 5. Data: 2.09s. Batch: 2.13s. Loss: 2.1433. :  48%|████▊     | 12/25 [00:02<00:01,  8.95it/s]Finetune Epoch:  1/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.1439. :  48%|████▊     | 12/25 [00:02<00:01,  8.95it/s]Finetune Epoch:  1/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.1439. :  56%|█████▌    | 14/25 [00:02<00:01, 10.67it/s]Finetune Epoch:  1/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.1392. :  56%|█████▌    | 14/25 [00:02<00:01, 10.67it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.1393. :  56%|█████▌    | 14/25 [00:02<00:01, 10.67it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.1393. :  64%|██████▍   | 16/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  1/ 5. Data: 2.19s. Batch: 2.23s. Loss: 2.1392. :  64%|██████▍   | 16/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  1/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.1377. :  64%|██████▍   | 16/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  1/ 5. Data: 2.24s. Batch: 2.28s. Loss: 2.1376. :  64%|██████▍   | 16/25 [00:02<00:00, 11.82it/s]Finetune Epoch:  1/ 5. Data: 2.24s. Batch: 2.28s. Loss: 2.1376. :  76%|███████▌  | 19/25 [00:02<00:00, 14.41it/s]Finetune Epoch:  1/ 5. Data: 2.26s. Batch: 2.31s. Loss: 2.1382. :  76%|███████▌  | 19/25 [00:02<00:00, 14.41it/s]Finetune Epoch:  1/ 5. Data: 2.29s. Batch: 2.33s. Loss: 2.1384. :  76%|███████▌  | 19/25 [00:02<00:00, 14.41it/s]Finetune Epoch:  1/ 5. Data: 2.31s. Batch: 2.36s. Loss: 2.1378. :  76%|███████▌  | 19/25 [00:02<00:00, 14.41it/s]Finetune Epoch:  1/ 5. Data: 2.31s. Batch: 2.36s. Loss: 2.1378. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch:  1/ 5. Data: 2.34s. Batch: 2.38s. Loss: 2.1365. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch:  1/ 5. Data: 2.36s. Batch: 2.41s. Loss: 2.1369. :  88%|████████▊ | 22/25 [00:02<00:00, 16.65it/s]Finetune Epoch:  1/ 5. Data: 2.39s. Batch: 2.43s. Loss: 2.1366. :  88%|████████▊ | 22/25 [00:03<00:00, 16.65it/s]Finetune Epoch:  1/ 5. Data: 2.39s. Batch: 2.43s. Loss: 2.1366. : 100%|██████████| 25/25 [00:03<00:00, 17.41it/s]Finetune Epoch:  1/ 5. Data: 2.39s. Batch: 2.43s. Loss: 2.1366. : 100%|██████████| 25/25 [00:03<00:00,  7.79it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 4.2175. top1: 3.12. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.81s. Loss: 4.2175. top1: 3.12. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 4.2304. top1: 1.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 4.1009. top1: 1.04. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 4.0782. top1: 1.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 4.0901. top1: 1.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 4.0918. top1: 2.08. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 4.0999. top1: 2.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 4.1639. top1: 2.34. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.81s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 4.1639. top1: 2.34. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 4.1543. top1: 2.78. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 4.1607. top1: 2.81. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 4.1903. top1: 2.56. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 4.1893. top1: 2.60. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 4.1887. top1: 2.64. top5: 100.00. :  13%|█▎        | 8/63 [00:01<00:09,  5.59it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 4.2325. top1: 2.90. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.59it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.1997. top1: 2.92. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.1640. top1: 2.73. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:09,  5.59it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.1640. top1: 2.73. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.1782. top1: 2.76. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.2051. top1: 2.78. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.1914. top1: 2.80. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.1813. top1: 2.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.1989. top1: 2.68. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.2273. top1: 2.56. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.2312. top1: 2.72. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.2180. top1: 2.60. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.2346. top1: 2.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.2281. top1: 2.52. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.2273. top1: 2.66. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 11.99it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.2273. top1: 2.66. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.2265. top1: 2.57. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.2196. top1: 2.59. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.2328. top1: 2.50. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.2286. top1: 2.42. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.5129. top1: 2.44. top5: 97.66. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.8017. top1: 2.37. top5: 94.70. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.0914. top1: 2.30. top5: 91.91. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.3881. top1: 2.23. top5: 89.29. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.6855. top1: 2.17. top5: 86.81. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.9512. top1: 2.11. top5: 84.46. :  43%|████▎     | 27/63 [00:02<00:01, 23.04it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.9512. top1: 2.11. top5: 84.46. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.1674. top1: 2.06. top5: 82.24. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.4232. top1: 2.00. top5: 80.13. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6329. top1: 1.95. top5: 78.12. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.8215. top1: 1.91. top5: 76.22. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.9948. top1: 1.86. top5: 74.40. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.1825. top1: 1.82. top5: 72.67. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.3428. top1: 1.78. top5: 71.02. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.5235. top1: 1.74. top5: 69.44. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.7465. top1: 1.70. top5: 67.93. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.9379. top1: 1.66. top5: 66.49. :  59%|█████▊    | 37/63 [00:02<00:00, 33.60it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.9379. top1: 1.66. top5: 66.49. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.0810. top1: 1.63. top5: 65.10. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.2279. top1: 1.59. top5: 63.78. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.3769. top1: 1.56. top5: 62.50. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.5033. top1: 1.53. top5: 61.27. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.6518. top1: 1.50. top5: 60.10. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.7755. top1: 1.47. top5: 58.96. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.8905. top1: 1.45. top5: 57.87. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.9775. top1: 1.42. top5: 56.82. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.0780. top1: 1.40. top5: 55.80. :  75%|███████▍  | 47/63 [00:02<00:00, 44.22it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.0780. top1: 1.40. top5: 55.80. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.2161. top1: 1.37. top5: 54.82. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.3183. top1: 1.35. top5: 53.88. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.4577. top1: 1.32. top5: 52.97. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.5576. top1: 1.30. top5: 52.08. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.6467. top1: 1.28. top5: 51.23. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.7435. top1: 1.26. top5: 50.40. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.7968. top1: 1.25. top5: 50.00. :  89%|████████▉ | 56/63 [00:02<00:00, 52.53it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 9.7968. top1: 1.25. top5: 50.00. : 100%|██████████| 63/63 [00:02<00:00, 22.72it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.1744. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.1744. :   4%|▍         | 1/25 [00:01<00:46,  1.95s/it]Finetune Epoch:  2/ 5. Data: 1.93s. Batch: 1.97s. Loss: 2.1529. :   4%|▍         | 1/25 [00:01<00:46,  1.95s/it]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.1503. :   4%|▍         | 1/25 [00:02<00:46,  1.95s/it]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.1503. :  12%|█▏        | 3/25 [00:02<00:11,  1.84it/s]Finetune Epoch:  2/ 5. Data: 1.98s. Batch: 2.02s. Loss: 2.1332. :  12%|█▏        | 3/25 [00:02<00:11,  1.84it/s]Finetune Epoch:  2/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.1312. :  12%|█▏        | 3/25 [00:02<00:11,  1.84it/s]Finetune Epoch:  2/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.1312. :  20%|██        | 5/25 [00:02<00:05,  3.43it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.1288. :  20%|██        | 5/25 [00:02<00:05,  3.43it/s]Finetune Epoch:  2/ 5. Data: 2.06s. Batch: 2.10s. Loss: 2.1279. :  20%|██        | 5/25 [00:02<00:05,  3.43it/s]Finetune Epoch:  2/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.1294. :  20%|██        | 5/25 [00:02<00:05,  3.43it/s]Finetune Epoch:  2/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.1294. :  32%|███▏      | 8/25 [00:02<00:02,  6.02it/s]Finetune Epoch:  2/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.1221. :  32%|███▏      | 8/25 [00:02<00:02,  6.02it/s]Finetune Epoch:  2/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.1192. :  32%|███▏      | 8/25 [00:02<00:02,  6.02it/s]Finetune Epoch:  2/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.1192. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch:  2/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.1162. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch:  2/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.1180. :  40%|████      | 10/25 [00:02<00:01,  7.72it/s]Finetune Epoch:  2/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.1180. :  48%|████▊     | 12/25 [00:02<00:01,  9.47it/s]Finetune Epoch:  2/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.1116. :  48%|████▊     | 12/25 [00:02<00:01,  9.47it/s]Finetune Epoch:  2/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.1106. :  48%|████▊     | 12/25 [00:02<00:01,  9.47it/s]Finetune Epoch:  2/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.1097. :  48%|████▊     | 12/25 [00:02<00:01,  9.47it/s]Finetune Epoch:  2/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.1097. :  60%|██████    | 15/25 [00:02<00:00, 12.10it/s]Finetune Epoch:  2/ 5. Data: 2.29s. Batch: 2.34s. Loss: 2.1065. :  60%|██████    | 15/25 [00:02<00:00, 12.10it/s]Finetune Epoch:  2/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.1046. :  60%|██████    | 15/25 [00:02<00:00, 12.10it/s]Finetune Epoch:  2/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.1046. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  2/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.1058. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  2/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.1058. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  2/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.1058. :  76%|███████▌  | 19/25 [00:02<00:00, 13.83it/s]Finetune Epoch:  2/ 5. Data: 2.40s. Batch: 2.46s. Loss: 2.1039. :  76%|███████▌  | 19/25 [00:02<00:00, 13.83it/s]Finetune Epoch:  2/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.1032. :  76%|███████▌  | 19/25 [00:03<00:00, 13.83it/s]Finetune Epoch:  2/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.1032. :  84%|████████▍ | 21/25 [00:03<00:00, 15.01it/s]Finetune Epoch:  2/ 5. Data: 2.46s. Batch: 2.51s. Loss: 2.1020. :  84%|████████▍ | 21/25 [00:03<00:00, 15.01it/s]Finetune Epoch:  2/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.1008. :  84%|████████▍ | 21/25 [00:03<00:00, 15.01it/s]Finetune Epoch:  2/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.1008. :  92%|█████████▏| 23/25 [00:03<00:00, 15.83it/s]Finetune Epoch:  2/ 5. Data: 2.51s. Batch: 2.57s. Loss: 2.0986. :  92%|█████████▏| 23/25 [00:03<00:00, 15.83it/s]Finetune Epoch:  2/ 5. Data: 2.54s. Batch: 2.59s. Loss: 2.0989. :  92%|█████████▏| 23/25 [00:03<00:00, 15.83it/s]Finetune Epoch:  2/ 5. Data: 2.54s. Batch: 2.59s. Loss: 2.0989. : 100%|██████████| 25/25 [00:03<00:00, 16.16it/s]Finetune Epoch:  2/ 5. Data: 2.54s. Batch: 2.59s. Loss: 2.0989. : 100%|██████████| 25/25 [00:03<00:00,  7.21it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 2.8545. top1: 6.25. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 2.8545. top1: 6.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 2.8582. top1: 6.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 2.7804. top1: 6.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 2.7624. top1: 7.81. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 2.7740. top1: 9.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 2.7727. top1: 8.85. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 2.7762. top1: 8.93. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 2.8191. top1: 8.20. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.8144. top1: 8.68. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.8144. top1: 8.68. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.8185. top1: 9.38. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.8391. top1: 9.09. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.8376. top1: 9.38. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.8408. top1: 9.38. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.8701. top1: 9.82. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.8466. top1: 10.00. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.32it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.8228. top1: 9.96. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:08,  6.32it/s] Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.8228. top1: 9.96. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.8332. top1: 9.56. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.8499. top1: 9.20. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.8432. top1: 9.21. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.8385. top1: 9.22. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.8497. top1: 9.23. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.8674. top1: 9.23. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.8706. top1: 9.51. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.8613. top1: 9.77. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.8721. top1: 9.50. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.8687. top1: 9.74. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.8675. top1: 9.95. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.8662. top1: 9.82. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.22it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.8662. top1: 9.82. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.8627. top1: 9.81. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.8713. top1: 9.69. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.8680. top1: 9.58. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.0916. top1: 9.57. top5: 97.66. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.3187. top1: 9.28. top5: 94.70. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5470. top1: 9.01. top5: 91.91. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.7808. top1: 8.75. top5: 89.29. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0167. top1: 8.51. top5: 86.81. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.2271. top1: 8.28. top5: 84.46. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.3990. top1: 8.06. top5: 82.24. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5993. top1: 7.85. top5: 80.13. :  44%|████▍     | 28/63 [00:02<00:01, 24.67it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5993. top1: 7.85. top5: 80.13. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.7648. top1: 7.66. top5: 78.12. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.9151. top1: 7.47. top5: 76.22. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.0524. top1: 7.29. top5: 74.40. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.1993. top1: 7.12. top5: 72.67. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.3263. top1: 6.96. top5: 71.02. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.4686. top1: 6.81. top5: 69.44. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.6431. top1: 6.66. top5: 67.93. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.7928. top1: 6.52. top5: 66.49. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.9054. top1: 6.38. top5: 65.10. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.0198. top1: 6.25. top5: 63.78. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.1374. top1: 6.12. top5: 62.50. :  62%|██████▏   | 39/63 [00:02<00:00, 36.67it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.1374. top1: 6.12. top5: 62.50. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.2378. top1: 6.00. top5: 61.27. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.3538. top1: 5.89. top5: 60.10. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.4510. top1: 5.78. top5: 58.96. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.5412. top1: 5.67. top5: 57.87. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.6115. top1: 5.57. top5: 56.82. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.6901. top1: 5.47. top5: 55.80. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.7985. top1: 5.37. top5: 54.82. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.8795. top1: 5.28. top5: 53.88. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.9887. top1: 5.19. top5: 52.97. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.0673. top1: 5.10. top5: 52.08. :  79%|███████▉  | 50/63 [00:02<00:00, 47.87it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.0673. top1: 5.10. top5: 52.08. :  95%|█████████▌| 60/63 [00:02<00:00, 55.80it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.1385. top1: 5.02. top5: 51.23. :  95%|█████████▌| 60/63 [00:02<00:00, 55.80it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.2148. top1: 4.94. top5: 50.40. :  95%|█████████▌| 60/63 [00:02<00:00, 55.80it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.2566. top1: 4.90. top5: 50.00. :  95%|█████████▌| 60/63 [00:02<00:00, 55.80it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.2566. top1: 4.90. top5: 50.00. : 100%|██████████| 63/63 [00:02<00:00, 23.43it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.87s. Batch: 1.92s. Loss: 2.0556. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.87s. Batch: 1.92s. Loss: 2.0556. :   4%|▍         | 1/25 [00:01<00:46,  1.92s/it]Finetune Epoch:  3/ 5. Data: 1.90s. Batch: 1.94s. Loss: 2.0566. :   4%|▍         | 1/25 [00:01<00:46,  1.92s/it]Finetune Epoch:  3/ 5. Data: 1.92s. Batch: 1.97s. Loss: 2.0802. :   4%|▍         | 1/25 [00:02<00:46,  1.92s/it]Finetune Epoch:  3/ 5. Data: 1.94s. Batch: 1.99s. Loss: 2.0863. :   4%|▍         | 1/25 [00:02<00:46,  1.92s/it]Finetune Epoch:  3/ 5. Data: 1.94s. Batch: 1.99s. Loss: 2.0863. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch:  3/ 5. Data: 1.97s. Batch: 2.02s. Loss: 2.0916. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch:  3/ 5. Data: 1.99s. Batch: 2.04s. Loss: 2.0878. :  16%|█▌        | 4/25 [00:02<00:08,  2.49it/s]Finetune Epoch:  3/ 5. Data: 1.99s. Batch: 2.04s. Loss: 2.0878. :  24%|██▍       | 6/25 [00:02<00:04,  4.01it/s]Finetune Epoch:  3/ 5. Data: 2.02s. Batch: 2.07s. Loss: 2.0809. :  24%|██▍       | 6/25 [00:02<00:04,  4.01it/s]Finetune Epoch:  3/ 5. Data: 2.04s. Batch: 2.09s. Loss: 2.0791. :  24%|██▍       | 6/25 [00:02<00:04,  4.01it/s]Finetune Epoch:  3/ 5. Data: 2.04s. Batch: 2.09s. Loss: 2.0791. :  32%|███▏      | 8/25 [00:02<00:02,  5.77it/s]Finetune Epoch:  3/ 5. Data: 2.07s. Batch: 2.12s. Loss: 2.0796. :  32%|███▏      | 8/25 [00:02<00:02,  5.77it/s]Finetune Epoch:  3/ 5. Data: 2.09s. Batch: 2.14s. Loss: 2.0843. :  32%|███▏      | 8/25 [00:02<00:02,  5.77it/s]Finetune Epoch:  3/ 5. Data: 2.09s. Batch: 2.14s. Loss: 2.0843. :  40%|████      | 10/25 [00:02<00:01,  7.70it/s]Finetune Epoch:  3/ 5. Data: 2.12s. Batch: 2.17s. Loss: 2.0812. :  40%|████      | 10/25 [00:02<00:01,  7.70it/s]Finetune Epoch:  3/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.0799. :  40%|████      | 10/25 [00:02<00:01,  7.70it/s]Finetune Epoch:  3/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.0799. :  48%|████▊     | 12/25 [00:02<00:01,  9.67it/s]Finetune Epoch:  3/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.0815. :  48%|████▊     | 12/25 [00:02<00:01,  9.67it/s]Finetune Epoch:  3/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.0828. :  48%|████▊     | 12/25 [00:02<00:01,  9.67it/s]Finetune Epoch:  3/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.0828. :  56%|█████▌    | 14/25 [00:02<00:00, 11.61it/s]Finetune Epoch:  3/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.0801. :  56%|█████▌    | 14/25 [00:02<00:00, 11.61it/s]Finetune Epoch:  3/ 5. Data: 2.25s. Batch: 2.29s. Loss: 2.0789. :  56%|█████▌    | 14/25 [00:02<00:00, 11.61it/s]Finetune Epoch:  3/ 5. Data: 2.25s. Batch: 2.29s. Loss: 2.0789. :  64%|██████▍   | 16/25 [00:02<00:00, 13.27it/s]Finetune Epoch:  3/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.0772. :  64%|██████▍   | 16/25 [00:02<00:00, 13.27it/s]Finetune Epoch:  3/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.0739. :  64%|██████▍   | 16/25 [00:02<00:00, 13.27it/s]Finetune Epoch:  3/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.0739. :  72%|███████▏  | 18/25 [00:02<00:00, 14.19it/s]Finetune Epoch:  3/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.0704. :  72%|███████▏  | 18/25 [00:02<00:00, 14.19it/s]Finetune Epoch:  3/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.0678. :  72%|███████▏  | 18/25 [00:02<00:00, 14.19it/s]Finetune Epoch:  3/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.0678. :  80%|████████  | 20/25 [00:02<00:00, 15.44it/s]Finetune Epoch:  3/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.0677. :  80%|████████  | 20/25 [00:02<00:00, 15.44it/s]Finetune Epoch:  3/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.0657. :  80%|████████  | 20/25 [00:02<00:00, 15.44it/s]Finetune Epoch:  3/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.0649. :  80%|████████  | 20/25 [00:03<00:00, 15.44it/s]Finetune Epoch:  3/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.0649. :  92%|█████████▏| 23/25 [00:03<00:00, 17.07it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.0641. :  92%|█████████▏| 23/25 [00:03<00:00, 17.07it/s]Finetune Epoch:  3/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.0613. :  92%|█████████▏| 23/25 [00:03<00:00, 17.07it/s]Finetune Epoch:  3/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.0613. : 100%|██████████| 25/25 [00:03<00:00, 17.59it/s]Finetune Epoch:  3/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.0613. : 100%|██████████| 25/25 [00:03<00:00,  7.53it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 2.0535. top1: 25.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.77s. Loss: 2.0535. top1: 25.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.89s. Loss: 2.0507. top1: 23.44. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 2.0058. top1: 27.08. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 1.9915. top1: 27.34. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.9998. top1: 27.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.9972. top1: 26.56. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.9993. top1: 26.79. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.0265. top1: 26.17. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.0251. top1: 26.39. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:49,  1.77s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.0251. top1: 26.39. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.0272. top1: 26.88. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.0409. top1: 26.70. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.0398. top1: 27.34. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.0435. top1: 26.68. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.0627. top1: 26.79. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.0470. top1: 28.12. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.0323. top1: 27.93. top5: 100.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.48it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.0323. top1: 27.93. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.48it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.0385. top1: 27.57. top5: 100.00. :  25%|██▌       | 16/63 [00:01<00:03, 12.48it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.0489. top1: 27.08. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.0460. top1: 27.14. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.0436. top1: 27.03. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.0501. top1: 26.93. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.0611. top1: 26.85. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.0636. top1: 27.04. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.0574. top1: 27.21. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.0640. top1: 26.62. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.0625. top1: 27.04. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.0613. top1: 27.55. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0599. top1: 27.46. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.48it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0599. top1: 27.46. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0584. top1: 27.59. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0637. top1: 27.40. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0613. top1: 27.12. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.2430. top1: 26.76. top5: 97.66. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4277. top1: 25.95. top5: 94.70. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6139. top1: 25.18. top5: 91.91. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.8049. top1: 24.46. top5: 89.29. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9981. top1: 23.78. top5: 86.81. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.1708. top1: 23.14. top5: 84.46. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.3121. top1: 22.53. top5: 82.24. :  44%|████▍     | 28/63 [00:02<00:01, 25.12it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.3121. top1: 22.53. top5: 82.24. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.4740. top1: 21.96. top5: 80.13. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.6095. top1: 21.41. top5: 78.12. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.7333. top1: 20.88. top5: 76.22. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8460. top1: 20.39. top5: 74.40. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.9650. top1: 19.91. top5: 72.67. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0688. top1: 19.46. top5: 71.09. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.1849. top1: 19.03. top5: 69.51. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3260. top1: 18.61. top5: 68.00. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4469. top1: 18.22. top5: 66.56. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.5383. top1: 17.84. top5: 65.17. :  60%|██████    | 38/63 [00:02<00:00, 35.59it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.5383. top1: 17.84. top5: 65.17. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6299. top1: 17.47. top5: 63.84. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.7259. top1: 17.12. top5: 62.56. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.8083. top1: 16.79. top5: 61.34. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9018. top1: 16.47. top5: 60.16. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.9809. top1: 16.16. top5: 59.02. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.0541. top1: 15.86. top5: 57.93. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.1128. top1: 15.57. top5: 56.88. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.1761. top1: 15.29. top5: 55.86. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.2644. top1: 15.02. top5: 54.88. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.3309. top1: 14.76. top5: 53.93. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.4190. top1: 14.51. top5: 53.02. :  76%|███████▌  | 48/63 [00:02<00:00, 46.10it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.4190. top1: 14.51. top5: 53.02. :  94%|█████████▎| 59/63 [00:02<00:00, 57.56it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.4831. top1: 14.27. top5: 52.14. :  94%|█████████▎| 59/63 [00:02<00:00, 57.56it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5420. top1: 14.04. top5: 51.28. :  94%|█████████▎| 59/63 [00:02<00:00, 57.56it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6043. top1: 13.81. top5: 50.45. :  94%|█████████▎| 59/63 [00:02<00:00, 57.56it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6382. top1: 13.70. top5: 50.05. :  94%|█████████▎| 59/63 [00:02<00:00, 57.56it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6382. top1: 13.70. top5: 50.05. : 100%|██████████| 63/63 [00:02<00:00, 23.64it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.82s. Batch: 1.86s. Loss: 2.0227. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.82s. Batch: 1.86s. Loss: 2.0227. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  4/ 5. Data: 1.84s. Batch: 1.89s. Loss: 2.0413. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  4/ 5. Data: 1.87s. Batch: 1.92s. Loss: 2.0310. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  4/ 5. Data: 1.87s. Batch: 1.92s. Loss: 2.0310. :  12%|█▏        | 3/25 [00:01<00:11,  1.90it/s]Finetune Epoch:  4/ 5. Data: 1.90s. Batch: 1.95s. Loss: 2.0302. :  12%|█▏        | 3/25 [00:02<00:11,  1.90it/s]Finetune Epoch:  4/ 5. Data: 1.93s. Batch: 1.97s. Loss: 2.0283. :  12%|█▏        | 3/25 [00:02<00:11,  1.90it/s]Finetune Epoch:  4/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.0253. :  12%|█▏        | 3/25 [00:02<00:11,  1.90it/s]Finetune Epoch:  4/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.0253. :  24%|██▍       | 6/25 [00:02<00:04,  4.28it/s]Finetune Epoch:  4/ 5. Data: 1.98s. Batch: 2.02s. Loss: 2.0267. :  24%|██▍       | 6/25 [00:02<00:04,  4.28it/s]Finetune Epoch:  4/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.0303. :  24%|██▍       | 6/25 [00:02<00:04,  4.28it/s]Finetune Epoch:  4/ 5. Data: 2.03s. Batch: 2.07s. Loss: 2.0323. :  24%|██▍       | 6/25 [00:02<00:04,  4.28it/s]Finetune Epoch:  4/ 5. Data: 2.03s. Batch: 2.07s. Loss: 2.0323. :  36%|███▌      | 9/25 [00:02<00:02,  6.79it/s]Finetune Epoch:  4/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.0293. :  36%|███▌      | 9/25 [00:02<00:02,  6.79it/s]Finetune Epoch:  4/ 5. Data: 2.08s. Batch: 2.12s. Loss: 2.0312. :  36%|███▌      | 9/25 [00:02<00:02,  6.79it/s]Finetune Epoch:  4/ 5. Data: 2.10s. Batch: 2.15s. Loss: 2.0308. :  36%|███▌      | 9/25 [00:02<00:02,  6.79it/s]Finetune Epoch:  4/ 5. Data: 2.10s. Batch: 2.15s. Loss: 2.0308. :  48%|████▊     | 12/25 [00:02<00:01,  9.25it/s]Finetune Epoch:  4/ 5. Data: 2.12s. Batch: 2.17s. Loss: 2.0324. :  48%|████▊     | 12/25 [00:02<00:01,  9.25it/s]Finetune Epoch:  4/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.0282. :  48%|████▊     | 12/25 [00:02<00:01,  9.25it/s]Finetune Epoch:  4/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.0256. :  48%|████▊     | 12/25 [00:02<00:01,  9.25it/s]Finetune Epoch:  4/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.0256. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  4/ 5. Data: 2.20s. Batch: 2.25s. Loss: 2.0248. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  4/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.0217. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  4/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.0217. :  68%|██████▊   | 17/25 [00:02<00:00, 12.58it/s]Finetune Epoch:  4/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.0216. :  68%|██████▊   | 17/25 [00:02<00:00, 12.58it/s]Finetune Epoch:  4/ 5. Data: 2.28s. Batch: 2.32s. Loss: 2.0182. :  68%|██████▊   | 17/25 [00:02<00:00, 12.58it/s]Finetune Epoch:  4/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.0169. :  68%|██████▊   | 17/25 [00:02<00:00, 12.58it/s]Finetune Epoch:  4/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.0169. :  80%|████████  | 20/25 [00:02<00:00, 14.63it/s]Finetune Epoch:  4/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.0154. :  80%|████████  | 20/25 [00:02<00:00, 14.63it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.0154. :  80%|████████  | 20/25 [00:02<00:00, 14.63it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.0154. :  88%|████████▊ | 22/25 [00:02<00:00, 15.56it/s]Finetune Epoch:  4/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.0143. :  88%|████████▊ | 22/25 [00:02<00:00, 15.56it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.0127. :  88%|████████▊ | 22/25 [00:03<00:00, 15.56it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.0127. :  96%|█████████▌| 24/25 [00:03<00:00, 16.37it/s]Finetune Epoch:  4/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.0149. :  96%|█████████▌| 24/25 [00:03<00:00, 16.37it/s]Finetune Epoch:  4/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.0149. : 100%|██████████| 25/25 [00:03<00:00,  7.54it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.5756. top1: 59.38. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 1.5756. top1: 59.38. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.92s. Loss: 1.5691. top1: 62.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.62s. Loss: 1.5446. top1: 63.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.47s. Loss: 1.5345. top1: 64.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 1.5387. top1: 61.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 1.5374. top1: 63.54. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.5395. top1: 64.29. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.5558. top1: 62.11. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.5558. top1: 60.76. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.5560. top1: 61.25. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:53,  1.82s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.5560. top1: 61.25. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.5646. top1: 60.80. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.5644. top1: 61.98. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.5679. top1: 61.30. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.5802. top1: 60.71. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.5708. top1: 62.08. top5: 100.00. :  16%|█▌        | 10/63 [00:01<00:07,  7.02it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.5620. top1: 62.11. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  7.02it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.5649. top1: 61.95. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:07,  7.02it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.5649. top1: 61.95. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.5714. top1: 61.28. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.5703. top1: 60.53. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.5689. top1: 60.31. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.5725. top1: 59.97. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5790. top1: 60.09. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5808. top1: 60.46. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5770. top1: 60.42. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5806. top1: 59.62. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5799. top1: 59.25. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5788. top1: 59.72. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5779. top1: 59.49. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5773. top1: 59.27. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.88it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5773. top1: 59.27. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5804. top1: 59.27. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5789. top1: 59.17. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.7320. top1: 57.81. top5: 97.66. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.8876. top1: 56.06. top5: 94.70. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.0448. top1: 54.41. top5: 91.91. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2064. top1: 52.86. top5: 89.29. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3699. top1: 51.39. top5: 86.81. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5168. top1: 50.00. top5: 84.46. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6369. top1: 48.68. top5: 82.24. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.7725. top1: 47.44. top5: 80.13. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.8876. top1: 46.25. top5: 78.12. :  46%|████▌     | 29/63 [00:02<00:01, 25.32it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.8876. top1: 46.25. top5: 78.12. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9928. top1: 45.12. top5: 76.22. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.0887. top1: 44.05. top5: 74.40. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1888. top1: 43.02. top5: 72.67. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2760. top1: 42.05. top5: 71.09. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3745. top1: 41.11. top5: 69.51. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.4933. top1: 40.22. top5: 68.00. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5941. top1: 39.36. top5: 66.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.6709. top1: 38.54. top5: 65.17. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.7469. top1: 37.76. top5: 63.84. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8283. top1: 37.00. top5: 62.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8985. top1: 36.27. top5: 61.34. :  63%|██████▎   | 40/63 [00:02<00:00, 37.33it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8985. top1: 36.27. top5: 61.34. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.9764. top1: 35.58. top5: 60.16. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0432. top1: 34.91. top5: 59.02. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.1047. top1: 34.26. top5: 57.93. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.1552. top1: 33.64. top5: 56.88. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.2080. top1: 33.04. top5: 55.86. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.2824. top1: 32.46. top5: 54.88. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.3392. top1: 31.90. top5: 53.93. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.4130. top1: 31.36. top5: 53.02. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.4670. top1: 30.83. top5: 52.14. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.5173. top1: 30.33. top5: 51.28. :  81%|████████  | 51/63 [00:02<00:00, 48.67it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.5173. top1: 30.33. top5: 51.28. :  97%|█████████▋| 61/63 [00:02<00:00, 57.03it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.5701. top1: 29.84. top5: 50.45. :  97%|█████████▋| 61/63 [00:02<00:00, 57.03it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.5987. top1: 29.60. top5: 50.05. :  97%|█████████▋| 61/63 [00:02<00:00, 57.03it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.5987. top1: 29.60. top5: 50.05. : 100%|██████████| 63/63 [00:02<00:00, 23.23it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.83s. Batch: 1.88s. Loss: 1.9465. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.83s. Batch: 1.88s. Loss: 1.9465. :   4%|▍         | 1/25 [00:01<00:45,  1.88s/it]Finetune Epoch:  5/ 5. Data: 1.86s. Batch: 1.91s. Loss: 1.9608. :   4%|▍         | 1/25 [00:01<00:45,  1.88s/it]Finetune Epoch:  5/ 5. Data: 1.88s. Batch: 1.93s. Loss: 1.9721. :   4%|▍         | 1/25 [00:01<00:45,  1.88s/it]Finetune Epoch:  5/ 5. Data: 1.88s. Batch: 1.93s. Loss: 1.9721. :  12%|█▏        | 3/25 [00:01<00:11,  1.89it/s]Finetune Epoch:  5/ 5. Data: 1.91s. Batch: 1.96s. Loss: 1.9738. :  12%|█▏        | 3/25 [00:02<00:11,  1.89it/s]Finetune Epoch:  5/ 5. Data: 1.94s. Batch: 1.99s. Loss: 1.9713. :  12%|█▏        | 3/25 [00:02<00:11,  1.89it/s]Finetune Epoch:  5/ 5. Data: 1.94s. Batch: 1.99s. Loss: 1.9713. :  20%|██        | 5/25 [00:02<00:05,  3.51it/s]Finetune Epoch:  5/ 5. Data: 1.97s. Batch: 2.02s. Loss: 1.9821. :  20%|██        | 5/25 [00:02<00:05,  3.51it/s]Finetune Epoch:  5/ 5. Data: 1.99s. Batch: 2.05s. Loss: 1.9932. :  20%|██        | 5/25 [00:02<00:05,  3.51it/s]Finetune Epoch:  5/ 5. Data: 1.99s. Batch: 2.05s. Loss: 1.9932. :  28%|██▊       | 7/25 [00:02<00:03,  5.35it/s]Finetune Epoch:  5/ 5. Data: 2.02s. Batch: 2.07s. Loss: 1.9892. :  28%|██▊       | 7/25 [00:02<00:03,  5.35it/s]Finetune Epoch:  5/ 5. Data: 2.05s. Batch: 2.10s. Loss: 1.9846. :  28%|██▊       | 7/25 [00:02<00:03,  5.35it/s]Finetune Epoch:  5/ 5. Data: 2.05s. Batch: 2.10s. Loss: 1.9846. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/ 5. Data: 2.07s. Batch: 2.12s. Loss: 1.9886. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/ 5. Data: 2.10s. Batch: 2.15s. Loss: 1.9856. :  36%|███▌      | 9/25 [00:02<00:02,  7.36it/s]Finetune Epoch:  5/ 5. Data: 2.10s. Batch: 2.15s. Loss: 1.9856. :  44%|████▍     | 11/25 [00:02<00:01,  9.38it/s]Finetune Epoch:  5/ 5. Data: 2.13s. Batch: 2.18s. Loss: 1.9870. :  44%|████▍     | 11/25 [00:02<00:01,  9.38it/s]Finetune Epoch:  5/ 5. Data: 2.15s. Batch: 2.20s. Loss: 1.9888. :  44%|████▍     | 11/25 [00:02<00:01,  9.38it/s]Finetune Epoch:  5/ 5. Data: 2.15s. Batch: 2.20s. Loss: 1.9888. :  52%|█████▏    | 13/25 [00:02<00:01, 11.37it/s]Finetune Epoch:  5/ 5. Data: 2.18s. Batch: 2.23s. Loss: 1.9845. :  52%|█████▏    | 13/25 [00:02<00:01, 11.37it/s]Finetune Epoch:  5/ 5. Data: 2.20s. Batch: 2.26s. Loss: 1.9852. :  52%|█████▏    | 13/25 [00:02<00:01, 11.37it/s]Finetune Epoch:  5/ 5. Data: 2.20s. Batch: 2.26s. Loss: 1.9852. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  5/ 5. Data: 2.23s. Batch: 2.28s. Loss: 1.9822. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  5/ 5. Data: 2.26s. Batch: 2.31s. Loss: 1.9810. :  60%|██████    | 15/25 [00:02<00:00, 13.18it/s]Finetune Epoch:  5/ 5. Data: 2.26s. Batch: 2.31s. Loss: 1.9810. :  68%|██████▊   | 17/25 [00:02<00:00, 14.55it/s]Finetune Epoch:  5/ 5. Data: 2.28s. Batch: 2.33s. Loss: 1.9775. :  68%|██████▊   | 17/25 [00:02<00:00, 14.55it/s]Finetune Epoch:  5/ 5. Data: 2.31s. Batch: 2.36s. Loss: 1.9788. :  68%|██████▊   | 17/25 [00:02<00:00, 14.55it/s]Finetune Epoch:  5/ 5. Data: 2.31s. Batch: 2.36s. Loss: 1.9788. :  76%|███████▌  | 19/25 [00:02<00:00, 15.54it/s]Finetune Epoch:  5/ 5. Data: 2.34s. Batch: 2.39s. Loss: 1.9776. :  76%|███████▌  | 19/25 [00:02<00:00, 15.54it/s]Finetune Epoch:  5/ 5. Data: 2.36s. Batch: 2.41s. Loss: 1.9790. :  76%|███████▌  | 19/25 [00:02<00:00, 15.54it/s]Finetune Epoch:  5/ 5. Data: 2.39s. Batch: 2.44s. Loss: 1.9772. :  76%|███████▌  | 19/25 [00:02<00:00, 15.54it/s]Finetune Epoch:  5/ 5. Data: 2.39s. Batch: 2.44s. Loss: 1.9772. :  88%|████████▊ | 22/25 [00:02<00:00, 17.30it/s]Finetune Epoch:  5/ 5. Data: 2.41s. Batch: 2.46s. Loss: 1.9761. :  88%|████████▊ | 22/25 [00:03<00:00, 17.30it/s]Finetune Epoch:  5/ 5. Data: 2.44s. Batch: 2.49s. Loss: 1.9761. :  88%|████████▊ | 22/25 [00:03<00:00, 17.30it/s]Finetune Epoch:  5/ 5. Data: 2.46s. Batch: 2.51s. Loss: 1.9737. :  88%|████████▊ | 22/25 [00:03<00:00, 17.30it/s]Finetune Epoch:  5/ 5. Data: 2.46s. Batch: 2.51s. Loss: 1.9737. : 100%|██████████| 25/25 [00:03<00:00, 18.21it/s]Finetune Epoch:  5/ 5. Data: 2.46s. Batch: 2.51s. Loss: 1.9737. : 100%|██████████| 25/25 [00:03<00:00,  7.51it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 1.3120. top1: 87.50. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.80s. Loss: 1.3120. top1: 87.50. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 1.3013. top1: 89.06. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 1.2879. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 1.2807. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 1.2829. top1: 90.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.2834. top1: 90.10. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.2854. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.2952. top1: 90.23. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.2952. top1: 90.28. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.2942. top1: 90.31. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.2998. top1: 90.62. top5: 100.00. :   2%|▏         | 1/63 [00:01<01:51,  1.80s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.2998. top1: 90.62. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.78it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.3002. top1: 90.89. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.78it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.3033. top1: 90.14. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.78it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.3112. top1: 89.73. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.78it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.3057. top1: 90.42. top5: 100.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.78it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.3001. top1: 90.82. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.78it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.3013. top1: 90.26. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.78it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.3013. top1: 90.26. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.3054. top1: 90.10. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.3050. top1: 89.14. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.3038. top1: 88.91. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.3058. top1: 88.84. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.3097. top1: 88.64. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3109. top1: 88.72. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.3088. top1: 88.93. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3106. top1: 88.75. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3099. top1: 88.46. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3091. top1: 88.77. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.3086. top1: 88.95. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3082. top1: 88.69. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.28it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3082. top1: 88.69. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3102. top1: 88.33. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3093. top1: 88.51. top5: 100.00. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4406. top1: 86.43. top5: 97.66. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5744. top1: 83.81. top5: 94.70. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.7099. top1: 81.34. top5: 91.91. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.8493. top1: 79.02. top5: 89.29. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.9901. top1: 76.82. top5: 86.81. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1172. top1: 74.75. top5: 84.46. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2211. top1: 72.78. top5: 82.24. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3364. top1: 70.91. top5: 80.13. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.4361. top1: 69.14. top5: 78.12. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5267. top1: 67.45. top5: 76.22. :  46%|████▌     | 29/63 [00:02<00:01, 24.52it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5267. top1: 67.45. top5: 76.22. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6099. top1: 65.85. top5: 74.40. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6957. top1: 64.32. top5: 72.67. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7702. top1: 62.86. top5: 71.09. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8555. top1: 61.46. top5: 69.51. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9577. top1: 60.12. top5: 68.00. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.0433. top1: 58.84. top5: 66.56. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1091. top1: 57.62. top5: 65.17. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1738. top1: 56.44. top5: 63.84. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2441. top1: 55.31. top5: 62.56. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3049. top1: 54.23. top5: 61.34. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3712. top1: 53.19. top5: 60.16. :  65%|██████▌   | 41/63 [00:02<00:00, 37.61it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3712. top1: 53.19. top5: 60.16. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.4287. top1: 52.18. top5: 59.02. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.4815. top1: 51.22. top5: 57.93. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5254. top1: 50.28. top5: 56.88. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5703. top1: 49.39. top5: 55.86. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.6341. top1: 48.52. top5: 54.88. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.6835. top1: 47.68. top5: 53.93. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.7468. top1: 46.88. top5: 53.02. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.7931. top1: 46.09. top5: 52.14. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.8368. top1: 45.34. top5: 51.28. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.8824. top1: 44.61. top5: 50.45. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.9069. top1: 44.25. top5: 50.05. :  83%|████████▎ | 52/63 [00:02<00:00, 49.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.9069. top1: 44.25. top5: 50.05. : 100%|██████████| 63/63 [00:02<00:00, 59.88it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.9069. top1: 44.25. top5: 50.05. : 100%|██████████| 63/63 [00:02<00:00, 23.62it/s]
total 9984 correct 5598 accuracy 56.06971153846154
[INFO] main.py:349 > [2-2] Set environment for the current task
[INFO] finetune.py:104 > Apply before_task
[INFO] finetune.py:146 > Reset the optimizer and scheduler states
[INFO] finetune.py:152 > Increasing the head of fc 10 -> 10
[INFO] main.py:357 > [2-3] Start to train under online
[INFO] main.py:372 > Train over streamed data once
batch_size : 128 stream_batch_size : 44 memory_batch_size : 42 pseudo_stream_size 42
num_stuff 237
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
[INFO] rainbow_memory.py:120 > Streamed samples: 800
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 9984
[INFO] rainbow_memory.py:128 > Train samples: 11284
[INFO] rainbow_memory.py:129 > Test samples: 4000
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([38, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([124, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
count 18
task1/train/loss 8.395466103321976 0
task1/test/loss 5.933045971688333 0
task1/test/acc 0.2795 0
task1/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 1 | Epoch 1/1 | train_loss 8.3955 | train_acc 0.6732 | test_loss 5.9330 | test_acc 0.2795 | lr 0.0050
[INFO] finetune.py:169 > Update memory over 10 classes by uncertainty
uncertainty
[INFO] finetune.py:679 > Compute uncertainty by vr_randaug!
[WARNING] finetune.py:639 > Fill the unused slots by breaking the equilibrium.
[INFO] finetune.py:223 > Memory statistic
[INFO] finetune.py:225 > 
automobile    156
bird          130
deer          117
dog            97
Name: klass, dtype: int64
[INFO] main.py:388 > Train over memory
batch_size : 64 stream_batch_size : 22 memory_batch_size : 21 pseudo_stream_size 21
num_stuff 0
[INFO] rainbow_memory.py:120 > Streamed samples: 0
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 0
[INFO] rainbow_memory.py:128 > Train samples: 500
[INFO] rainbow_memory.py:129 > Test samples: 4000
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task1/train/loss 2.4377242078383765 0
task1/test/loss 1.441560277899543 0
task1/test/acc 0.253 0
task1/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 1 | Epoch 1/2 | train_loss 2.4377 | train_acc 0.3020 | test_loss 1.4416 | test_acc 0.2530 | lr 0.0050
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task1/train/loss 2.0752791315317154 1
task1/test/loss 2.149741667640078 1
task1/test/acc 0.25 1
task1/train/lr 0.05 1
[INFO] rainbow_memory.py:184 > Task 1 | Epoch 2/2 | train_loss 2.0753 | train_acc 0.2560 | test_loss 2.1497 | test_acc 0.2500 | lr 0.0500
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (1)
[INFO] main.py:398 > [2-4] Update the information for the current task
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (1)
[INFO] main.py:405 > [2-5] Report task result
Metrics/TaskAcc 0.253 1

##################################################
# Task 2 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 30  current step :  0
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 2.5219. T_Loss: 2.4520. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.12s. Batch: 0.26s. S_Loss: 2.5219. T_Loss: 2.4520. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.83it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.07s. Batch: 0.20s. S_Loss: 2.4650. T_Loss: 2.4506. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.83it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.07s. Batch: 0.20s. S_Loss: 2.4650. T_Loss: 2.4506. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  5.26it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.3991. T_Loss: 2.4197. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  5.26it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.3991. T_Loss: 2.4197. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  6.37it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.16s. S_Loss: 2.3880. T_Loss: 2.4606. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  6.37it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.16s. S_Loss: 2.3880. T_Loss: 2.4606. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.87it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.4355. T_Loss: 2.4714. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.87it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.4355. T_Loss: 2.4714. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.20it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.4469. T_Loss: 2.4835. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.20it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.4469. T_Loss: 2.4835. Mask: 0.0000. :  60%|██████    | 6/10 [00:00<00:00,  7.42it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4196. T_Loss: 2.4774. Mask: 0.0000. :  60%|██████    | 6/10 [00:01<00:00,  7.42it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4196. T_Loss: 2.4774. Mask: 0.0000. :  70%|███████   | 7/10 [00:01<00:00,  7.61it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4066. T_Loss: 2.4679. Mask: 0.0000. :  70%|███████   | 7/10 [00:01<00:00,  7.61it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4066. T_Loss: 2.4679. Mask: 0.0000. :  80%|████████  | 8/10 [00:01<00:00,  7.39it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3927. T_Loss: 2.4722. Mask: 0.0000. :  80%|████████  | 8/10 [00:01<00:00,  7.39it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3927. T_Loss: 2.4722. Mask: 0.0000. :  90%|█████████ | 9/10 [00:01<00:00,  7.51it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3942. T_Loss: 2.4604. Mask: 0.0031. :  90%|█████████ | 9/10 [00:01<00:00,  7.51it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3942. T_Loss: 2.4604. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  7.71it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3942. T_Loss: 2.4604. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  7.04it/s]
total : 30  current step :  1
total : 30  current step :  2
total : 30  current step :  3
total : 30  current step :  4
total : 30  current step :  5
total : 30  current step :  6
total : 30  current step :  7
total : 30  current step :  8
total : 30  current step :  9
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.97s. Loss: 2.2964. top1: 96.88. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.97s. Loss: 2.2964. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<02:02,  1.97s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.01s. Loss: 2.3911. top1: 92.19. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.68s. Loss: 2.3918. top1: 91.67. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.52s. Loss: 2.4304. top1: 93.75. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.42s. Loss: 2.4355. top1: 94.38. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.42s. Loss: 2.4355. top1: 94.38. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.35s. Loss: 2.4474. top1: 94.79. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 2.4483. top1: 95.09. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 2.4459. top1: 95.31. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 2.4267. top1: 95.83. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.4187. top1: 96.25. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.4382. top1: 96.02. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 2.4310. top1: 96.09. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.4145. top1: 96.39. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.4221. top1: 95.98. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.4256. top1: 95.62. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.4163. top1: 95.51. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4283. top1: 95.59. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.16it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.4283. top1: 95.59. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.4298. top1: 95.66. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.4301. top1: 95.39. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.4282. top1: 95.31. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.4339. top1: 95.54. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4146. top1: 95.45. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4280. top1: 95.11. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4393. top1: 94.92. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.31it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.4393. top1: 94.92. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4417. top1: 94.62. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4347. top1: 94.71. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.4364. top1: 94.79. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4429. top1: 94.87. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4435. top1: 94.72. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4364. top1: 94.79. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.4382. top1: 94.76. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.8035. top1: 92.58. top5: 98.44. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.3352. top1: 89.77. top5: 96.69. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.8254. top1: 87.13. top5: 95.13. :  38%|███▊      | 24/63 [00:02<00:02, 19.27it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.8254. top1: 87.13. top5: 95.13. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.2908. top1: 84.64. top5: 93.75. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.7353. top1: 82.29. top5: 92.10. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.2253. top1: 80.07. top5: 90.62. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.6327. top1: 77.96. top5: 88.98. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.9288. top1: 75.96. top5: 88.14. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.2586. top1: 74.06. top5: 86.88. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.6384. top1: 72.26. top5: 85.52. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.9009. top1: 70.54. top5: 84.67. :  54%|█████▍    | 34/63 [00:02<00:00, 29.81it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.9009. top1: 70.54. top5: 84.67. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.1971. top1: 68.90. top5: 83.72. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.5099. top1: 67.33. top5: 82.81. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 7.7659. top1: 65.83. top5: 81.81. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.0006. top1: 64.40. top5: 81.18. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 8.2544. top1: 63.03. top5: 80.05. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.5124. top1: 61.72. top5: 79.36. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.7658. top1: 60.46. top5: 78.57. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.0185. top1: 59.25. top5: 77.75. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.2581. top1: 58.09. top5: 76.84. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.4773. top1: 56.97. top5: 76.02. :  67%|██████▋   | 42/63 [00:02<00:00, 36.35it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.4773. top1: 56.97. top5: 76.02. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.6416. top1: 55.90. top5: 75.41. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.8278. top1: 54.86. top5: 74.94. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 9.9888. top1: 53.86. top5: 74.38. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.1518. top1: 52.90. top5: 74.05. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.2994. top1: 51.97. top5: 73.68. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.4576. top1: 51.08. top5: 73.01. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.6033. top1: 50.21. top5: 72.40. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.7394. top1: 49.38. top5: 71.93. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.8898. top1: 48.57. top5: 71.57. :  83%|████████▎ | 52/63 [00:02<00:00, 47.51it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 10.8898. top1: 48.57. top5: 71.57. :  97%|█████████▋| 61/63 [00:02<00:00, 55.07it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 11.0155. top1: 47.78. top5: 71.17. :  97%|█████████▋| 61/63 [00:02<00:00, 55.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 11.1094. top1: 47.40. top5: 70.95. :  97%|█████████▋| 61/63 [00:02<00:00, 55.07it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 11.1094. top1: 47.40. top5: 70.95. : 100%|██████████| 63/63 [00:02<00:00, 21.16it/s]
total : 30  current step :  10
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2318. T_Loss: 2.3465. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.2318. T_Loss: 2.3465. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  8.06it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2871. T_Loss: 2.2153. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  8.06it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2871. T_Loss: 2.2153. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  7.55it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2690. T_Loss: 2.1540. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  7.55it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2690. T_Loss: 2.1540. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:00,  7.79it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2668. T_Loss: 2.1072. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:00,  7.79it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2668. T_Loss: 2.1072. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  7.84it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2505. T_Loss: 2.0845. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  7.84it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2505. T_Loss: 2.0845. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.59it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2173. T_Loss: 2.0770. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.59it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2173. T_Loss: 2.0770. Mask: 0.0000. :  60%|██████    | 6/10 [00:00<00:00,  7.39it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2285. T_Loss: 2.0480. Mask: 0.0000. :  60%|██████    | 6/10 [00:00<00:00,  7.39it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2285. T_Loss: 2.0480. Mask: 0.0000. :  70%|███████   | 7/10 [00:00<00:00,  7.58it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2398. T_Loss: 2.0160. Mask: 0.0039. :  70%|███████   | 7/10 [00:01<00:00,  7.58it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2398. T_Loss: 2.0160. Mask: 0.0039. :  80%|████████  | 8/10 [00:01<00:00,  7.85it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2308. T_Loss: 1.9867. Mask: 0.0035. :  80%|████████  | 8/10 [00:01<00:00,  7.85it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.2308. T_Loss: 1.9867. Mask: 0.0035. :  90%|█████████ | 9/10 [00:01<00:00,  7.96it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2326. T_Loss: 1.9605. Mask: 0.0094. :  90%|█████████ | 9/10 [00:01<00:00,  7.96it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2326. T_Loss: 1.9605. Mask: 0.0094. : 100%|██████████| 10/10 [00:01<00:00,  7.99it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2326. T_Loss: 1.9605. Mask: 0.0094. : 100%|██████████| 10/10 [00:01<00:00,  7.80it/s]
total : 30  current step :  11
total : 30  current step :  12
total : 30  current step :  13
total : 30  current step :  14
total : 30  current step :  15
total : 30  current step :  16
total : 30  current step :  17
total : 30  current step :  18
total : 30  current step :  19
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.01s. Loss: 1.8105. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.01s. Loss: 1.8105. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.01s. Loss: 1.8738. top1: 95.31. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.68s. Loss: 1.8698. top1: 93.75. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.51s. Loss: 1.9052. top1: 95.31. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 1.9091. top1: 95.62. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.9192. top1: 96.35. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.9211. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.9187. top1: 97.27. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.9045. top1: 97.57. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.9045. top1: 97.57. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.8982. top1: 97.81. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.9142. top1: 97.73. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.9090. top1: 97.92. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.8965. top1: 98.08. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.9017. top1: 97.77. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.9044. top1: 97.50. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.8972. top1: 97.46. top5: 100.00. :  14%|█▍        | 9/63 [00:02<00:09,  5.75it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.8972. top1: 97.46. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.9066. top1: 97.43. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.9073. top1: 97.40. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.9074. top1: 97.20. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.9062. top1: 97.03. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.9111. top1: 97.17. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.8962. top1: 97.30. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.9061. top1: 97.15. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.9150. top1: 97.27. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.19it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.9150. top1: 97.27. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.9168. top1: 97.12. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.9116. top1: 97.24. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.9133. top1: 97.34. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.9184. top1: 97.32. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.9190. top1: 97.31. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.9136. top1: 97.40. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.9148. top1: 97.38. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.2004. top1: 95.12. top5: 98.44. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.6174. top1: 92.23. top5: 96.69. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.0019. top1: 89.52. top5: 95.13. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.3668. top1: 86.96. top5: 93.75. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.7161. top1: 84.55. top5: 92.45. :  38%|███▊      | 24/63 [00:02<00:02, 18.43it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.7161. top1: 84.55. top5: 92.45. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.1015. top1: 82.26. top5: 90.96. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.4211. top1: 80.10. top5: 89.39. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6524. top1: 78.04. top5: 88.62. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.9103. top1: 76.09. top5: 87.42. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.2096. top1: 74.24. top5: 86.13. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.4143. top1: 72.47. top5: 85.27. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.6476. top1: 70.78. top5: 84.30. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.8935. top1: 69.18. top5: 83.38. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.0941. top1: 67.64. top5: 82.50. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.2776. top1: 66.17. top5: 82.00. :  57%|█████▋    | 36/63 [00:02<00:00, 31.64it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.2776. top1: 66.17. top5: 82.00. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.4777. top1: 64.76. top5: 80.92. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.6805. top1: 63.41. top5: 80.27. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.8806. top1: 62.12. top5: 79.53. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.0786. top1: 60.88. top5: 78.81. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.2673. top1: 59.68. top5: 77.94. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.4392. top1: 58.53. top5: 77.16. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.5686. top1: 57.43. top5: 76.53. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.7146. top1: 56.37. top5: 76.22. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.8402. top1: 55.34. top5: 75.74. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.9680. top1: 54.35. top5: 75.45. :  73%|███████▎  | 46/63 [00:02<00:00, 42.45it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 7.9680. top1: 54.35. top5: 75.45. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.0825. top1: 53.40. top5: 75.27. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.2068. top1: 52.48. top5: 74.62. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 8.3212. top1: 51.59. top5: 73.99. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.4281. top1: 50.73. top5: 73.49. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.5462. top1: 49.90. top5: 73.21. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.6445. top1: 49.09. top5: 72.88. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.7190. top1: 48.70. top5: 72.65. :  89%|████████▉ | 56/63 [00:02<00:00, 53.04it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 8.7190. top1: 48.70. top5: 72.65. : 100%|██████████| 63/63 [00:02<00:00, 21.31it/s]
total : 30  current step :  20
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3341. T_Loss: 1.6354. Mask: 0.0938. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3341. T_Loss: 1.6354. Mask: 0.0938. :  10%|█         | 1/10 [00:00<00:01,  7.34it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2618. T_Loss: 1.6367. Mask: 0.1094. :  10%|█         | 1/10 [00:00<00:01,  7.34it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.2618. T_Loss: 1.6367. Mask: 0.1094. :  20%|██        | 2/10 [00:00<00:01,  7.49it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3404. T_Loss: 1.6291. Mask: 0.1458. :  20%|██        | 2/10 [00:00<00:01,  7.49it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3404. T_Loss: 1.6291. Mask: 0.1458. :  30%|███       | 3/10 [00:00<00:00,  7.41it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3651. T_Loss: 1.6765. Mask: 0.2188. :  30%|███       | 3/10 [00:00<00:00,  7.41it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3651. T_Loss: 1.6765. Mask: 0.2188. :  40%|████      | 4/10 [00:00<00:00,  7.93it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3470. T_Loss: 1.6502. Mask: 0.2500. :  40%|████      | 4/10 [00:00<00:00,  7.93it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3470. T_Loss: 1.6502. Mask: 0.2500. :  50%|█████     | 5/10 [00:00<00:00,  7.98it/s]total : 30  current step :  21
total : 30  current step :  22
total : 30  current step :  23
total : 30  current step :  24
total : 30  current step :  25
Train Iter:  26/ 30. LR: 0.0000. Data: 0.38s. Batch: 0.50s. S_Loss: 2.3404. T_Loss: 1.6599. Mask: 0.2865. :  50%|█████     | 5/10 [00:03<00:00,  7.98it/s]Train Iter:  26/ 30. LR: 0.0000. Data: 0.38s. Batch: 0.50s. S_Loss: 2.3404. T_Loss: 1.6599. Mask: 0.2865. :  60%|██████    | 6/10 [00:03<00:03,  1.12it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.32s. Batch: 0.45s. S_Loss: 2.3334. T_Loss: 1.6480. Mask: 0.3304. :  60%|██████    | 6/10 [00:03<00:03,  1.12it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.32s. Batch: 0.45s. S_Loss: 2.3334. T_Loss: 1.6480. Mask: 0.3304. :  70%|███████   | 7/10 [00:03<00:01,  1.56it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.28s. Batch: 0.41s. S_Loss: 2.3306. T_Loss: 1.6005. Mask: 0.3516. :  70%|███████   | 7/10 [00:03<00:01,  1.56it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.28s. Batch: 0.41s. S_Loss: 2.3306. T_Loss: 1.6005. Mask: 0.3516. :  80%|████████  | 8/10 [00:03<00:00,  2.12it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.25s. Batch: 0.37s. S_Loss: 2.3365. T_Loss: 1.6174. Mask: 0.4028. :  80%|████████  | 8/10 [00:03<00:00,  2.12it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.25s. Batch: 0.37s. S_Loss: 2.3365. T_Loss: 1.6174. Mask: 0.4028. :  90%|█████████ | 9/10 [00:03<00:00,  2.77it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.23s. Batch: 0.35s. S_Loss: 2.3382. T_Loss: 1.6196. Mask: 0.4313. :  90%|█████████ | 9/10 [00:03<00:00,  2.77it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.23s. Batch: 0.35s. S_Loss: 2.3382. T_Loss: 1.6196. Mask: 0.4313. : 100%|██████████| 10/10 [00:03<00:00,  3.49it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.23s. Batch: 0.35s. S_Loss: 2.3382. T_Loss: 1.6196. Mask: 0.4313. : 100%|██████████| 10/10 [00:03<00:00,  2.87it/s]
total : 30  current step :  26
total : 30  current step :  27
total : 30  current step :  28
total : 30  current step :  29
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.04s. Loss: 1.4844. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.04s. Loss: 1.4844. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.03s. Loss: 1.5374. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.70s. Loss: 1.5329. top1: 94.79. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.53s. Loss: 1.5620. top1: 96.09. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.5651. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.5735. top1: 97.40. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.5745. top1: 97.77. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:06,  2.05s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.5745. top1: 97.77. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.5720. top1: 98.05. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.5614. top1: 98.26. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.5559. top1: 98.44. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.5686. top1: 98.30. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.5652. top1: 98.44. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.5551. top1: 98.56. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.5595. top1: 98.21. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.5616. top1: 98.12. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.5561. top1: 98.05. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.5635. top1: 97.98. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.5637. top1: 98.09. top5: 100.00. :  11%|█         | 7/63 [00:02<00:12,  4.35it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.5637. top1: 98.09. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.5639. top1: 98.03. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.5633. top1: 97.97. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.5671. top1: 98.07. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.5555. top1: 98.15. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.5628. top1: 98.10. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.5697. top1: 98.18. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5712. top1: 98.12. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5673. top1: 98.20. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.5690. top1: 98.26. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5729. top1: 98.21. top5: 100.00. :  29%|██▊       | 18/63 [00:02<00:03, 13.24it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5729. top1: 98.21. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5736. top1: 98.17. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5695. top1: 98.23. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.5703. top1: 98.29. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.7980. top1: 96.00. top5: 98.73. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1321. top1: 93.09. top5: 96.97. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.4402. top1: 90.35. top5: 95.50. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.7322. top1: 87.77. top5: 94.11. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.0121. top1: 85.33. top5: 93.06. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.3213. top1: 83.02. top5: 91.64. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5774. top1: 80.84. top5: 90.05. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.7615. top1: 78.77. top5: 89.34. :  44%|████▍     | 28/63 [00:02<00:01, 22.46it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.7615. top1: 78.77. top5: 89.34. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.9676. top1: 76.80. top5: 88.20. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.2079. top1: 74.92. top5: 86.89. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.3708. top1: 73.14. top5: 86.09. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5581. top1: 71.44. top5: 85.10. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.7555. top1: 69.82. top5: 84.30. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.9158. top1: 68.26. top5: 83.54. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.0621. top1: 66.78. top5: 83.02. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.2229. top1: 65.36. top5: 82.11. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.3856. top1: 64.00. top5: 81.45. :  62%|██████▏   | 39/63 [00:02<00:00, 33.83it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.3856. top1: 64.00. top5: 81.45. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.5465. top1: 62.69. top5: 80.68. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.7049. top1: 61.44. top5: 79.94. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.8561. top1: 60.23. top5: 79.04. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.9937. top1: 59.07. top5: 78.19. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.0977. top1: 57.96. top5: 77.54. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.2146. top1: 56.89. top5: 77.26. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.3144. top1: 55.85. top5: 76.82. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.4164. top1: 54.85. top5: 76.45. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.5074. top1: 53.89. top5: 76.26. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.6072. top1: 52.96. top5: 75.59. :  76%|███████▌  | 48/63 [00:02<00:00, 42.18it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.6072. top1: 52.96. top5: 75.59. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.6986. top1: 52.07. top5: 74.95. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.7845. top1: 51.20. top5: 74.58. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.8791. top1: 50.36. top5: 74.33. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 6.9577. top1: 49.55. top5: 74.04. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.0178. top1: 49.15. top5: 73.75. :  92%|█████████▏| 58/63 [00:02<00:00, 52.65it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 7.0178. top1: 49.15. top5: 73.75. : 100%|██████████| 63/63 [00:02<00:00, 21.10it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.92s. Batch: 1.95s. Loss: 2.2758. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.92s. Batch: 1.95s. Loss: 2.2758. :   4%|▍         | 1/25 [00:01<00:46,  1.95s/it]Finetune Epoch:  1/ 5. Data: 1.95s. Batch: 1.98s. Loss: 2.3473. :   4%|▍         | 1/25 [00:02<00:46,  1.95s/it]Finetune Epoch:  1/ 5. Data: 1.97s. Batch: 2.00s. Loss: 2.3801. :   4%|▍         | 1/25 [00:02<00:46,  1.95s/it]Finetune Epoch:  1/ 5. Data: 1.99s. Batch: 2.02s. Loss: 2.3967. :   4%|▍         | 1/25 [00:02<00:46,  1.95s/it]Finetune Epoch:  1/ 5. Data: 1.99s. Batch: 2.02s. Loss: 2.3967. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  1/ 5. Data: 2.01s. Batch: 2.04s. Loss: 2.3837. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  1/ 5. Data: 2.03s. Batch: 2.07s. Loss: 2.3869. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  1/ 5. Data: 2.05s. Batch: 2.09s. Loss: 2.3829. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  1/ 5. Data: 2.05s. Batch: 2.09s. Loss: 2.3829. :  28%|██▊       | 7/25 [00:02<00:03,  4.69it/s]Finetune Epoch:  1/ 5. Data: 2.07s. Batch: 2.11s. Loss: 2.3793. :  28%|██▊       | 7/25 [00:02<00:03,  4.69it/s]Finetune Epoch:  1/ 5. Data: 2.10s. Batch: 2.14s. Loss: 2.3704. :  28%|██▊       | 7/25 [00:02<00:03,  4.69it/s]Finetune Epoch:  1/ 5. Data: 2.10s. Batch: 2.14s. Loss: 2.3704. :  36%|███▌      | 9/25 [00:02<00:02,  6.21it/s]Finetune Epoch:  1/ 5. Data: 2.12s. Batch: 2.17s. Loss: 2.3693. :  36%|███▌      | 9/25 [00:02<00:02,  6.21it/s]Finetune Epoch:  1/ 5. Data: 2.15s. Batch: 2.19s. Loss: 2.3655. :  36%|███▌      | 9/25 [00:02<00:02,  6.21it/s]Finetune Epoch:  1/ 5. Data: 2.15s. Batch: 2.19s. Loss: 2.3655. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch:  1/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.3684. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch:  1/ 5. Data: 2.20s. Batch: 2.24s. Loss: 2.3798. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch:  1/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.3836. :  44%|████▍     | 11/25 [00:02<00:01,  8.00it/s]Finetune Epoch:  1/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.3836. :  56%|█████▌    | 14/25 [00:02<00:01, 10.52it/s]Finetune Epoch:  1/ 5. Data: 2.25s. Batch: 2.29s. Loss: 2.3674. :  56%|█████▌    | 14/25 [00:02<00:01, 10.52it/s]Finetune Epoch:  1/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.3734. :  56%|█████▌    | 14/25 [00:02<00:01, 10.52it/s]Finetune Epoch:  1/ 5. Data: 2.30s. Batch: 2.34s. Loss: 2.3691. :  56%|█████▌    | 14/25 [00:02<00:01, 10.52it/s]Finetune Epoch:  1/ 5. Data: 2.30s. Batch: 2.34s. Loss: 2.3691. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  1/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.3716. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  1/ 5. Data: 2.35s. Batch: 2.39s. Loss: 2.3735. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  1/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.3809. :  68%|██████▊   | 17/25 [00:02<00:00, 12.90it/s]Finetune Epoch:  1/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.3809. :  80%|████████  | 20/25 [00:02<00:00, 14.93it/s]Finetune Epoch:  1/ 5. Data: 2.40s. Batch: 2.44s. Loss: 2.3783. :  80%|████████  | 20/25 [00:02<00:00, 14.93it/s]Finetune Epoch:  1/ 5. Data: 2.42s. Batch: 2.47s. Loss: 2.3793. :  80%|████████  | 20/25 [00:02<00:00, 14.93it/s]Finetune Epoch:  1/ 5. Data: 2.45s. Batch: 2.49s. Loss: 2.3728. :  80%|████████  | 20/25 [00:03<00:00, 14.93it/s]Finetune Epoch:  1/ 5. Data: 2.45s. Batch: 2.49s. Loss: 2.3728. :  92%|█████████▏| 23/25 [00:03<00:00, 16.34it/s]Finetune Epoch:  1/ 5. Data: 2.47s. Batch: 2.52s. Loss: 2.3694. :  92%|█████████▏| 23/25 [00:03<00:00, 16.34it/s]Finetune Epoch:  1/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.3674. :  92%|█████████▏| 23/25 [00:03<00:00, 16.34it/s]Finetune Epoch:  1/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.3674. : 100%|██████████| 25/25 [00:03<00:00,  7.48it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.08s. Loss: 1.2214. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.08s. Loss: 1.2214. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.05s. Loss: 1.2689. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.70s. Loss: 1.2655. top1: 95.83. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.53s. Loss: 1.2860. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.2877. top1: 97.50. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.2936. top1: 97.92. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.2930. top1: 98.21. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.2901. top1: 98.44. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.2834. top1: 98.61. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.2784. top1: 98.75. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.2875. top1: 98.58. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:08,  2.08s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.2875. top1: 98.58. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.2861. top1: 98.70. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.2784. top1: 98.80. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.2822. top1: 98.66. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.2839. top1: 98.75. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.2799. top1: 98.83. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2852. top1: 98.71. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.2849. top1: 98.78. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.2852. top1: 98.68. top5: 100.00. :  17%|█▋        | 11/63 [00:02<00:07,  6.86it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.2852. top1: 98.68. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2852. top1: 98.59. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2877. top1: 98.66. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.2798. top1: 98.72. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2847. top1: 98.78. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.2892. top1: 98.83. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2906. top1: 98.75. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2882. top1: 98.80. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.2897. top1: 98.84. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2925. top1: 98.88. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2931. top1: 98.81. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2906. top1: 98.85. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2908. top1: 98.89. top5: 100.00. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4549. top1: 96.58. top5: 99.41. :  30%|███       | 19/63 [00:02<00:03, 12.95it/s] Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4549. top1: 96.58. top5: 99.41. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.6980. top1: 93.66. top5: 98.01. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.9229. top1: 90.90. top5: 96.88. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.1359. top1: 88.30. top5: 95.98. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.3398. top1: 85.85. top5: 95.14. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.5659. top1: 83.53. top5: 94.17. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.7526. top1: 81.33. top5: 93.42. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.8853. top1: 79.25. top5: 92.95. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.0347. top1: 77.27. top5: 92.34. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2104. top1: 75.38. top5: 91.16. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.3278. top1: 73.59. top5: 90.55. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.4645. top1: 71.88. top5: 89.90. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.6091. top1: 70.24. top5: 89.49. :  51%|█████     | 32/63 [00:02<00:01, 25.23it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.6091. top1: 70.24. top5: 89.49. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.7252. top1: 68.68. top5: 89.03. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8306. top1: 67.19. top5: 88.93. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.9480. top1: 65.76. top5: 88.56. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0666. top1: 64.39. top5: 88.28. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.1844. top1: 63.07. top5: 87.82. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.2992. top1: 61.81. top5: 87.50. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4095. top1: 60.60. top5: 86.95. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.5098. top1: 59.44. top5: 86.30. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.5857. top1: 58.31. top5: 85.91. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6708. top1: 57.23. top5: 85.82. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.7423. top1: 56.19. top5: 85.40. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.8163. top1: 55.19. top5: 85.10. :  70%|██████▉   | 44/63 [00:02<00:00, 37.58it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.8163. top1: 55.19. top5: 85.10. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.8817. top1: 54.22. top5: 85.14. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9544. top1: 53.29. top5: 84.86. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.0206. top1: 52.38. top5: 84.48. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.0832. top1: 51.51. top5: 84.27. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.1518. top1: 50.67. top5: 83.97. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.2087. top1: 49.85. top5: 83.87. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.2532. top1: 49.45. top5: 83.80. :  89%|████████▉ | 56/63 [00:02<00:00, 50.19it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.2532. top1: 49.45. top5: 83.80. : 100%|██████████| 63/63 [00:02<00:00, 22.18it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.4413. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.4413. :   4%|▍         | 1/25 [00:02<00:49,  2.08s/it]Finetune Epoch:  2/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.3484. :   4%|▍         | 1/25 [00:02<00:49,  2.08s/it]Finetune Epoch:  2/ 5. Data: 2.08s. Batch: 2.12s. Loss: 2.3392. :   4%|▍         | 1/25 [00:02<00:49,  2.08s/it]Finetune Epoch:  2/ 5. Data: 2.10s. Batch: 2.14s. Loss: 2.3303. :   4%|▍         | 1/25 [00:02<00:49,  2.08s/it]Finetune Epoch:  2/ 5. Data: 2.10s. Batch: 2.14s. Loss: 2.3303. :  16%|█▌        | 4/25 [00:02<00:08,  2.35it/s]Finetune Epoch:  2/ 5. Data: 2.12s. Batch: 2.16s. Loss: 2.3216. :  16%|█▌        | 4/25 [00:02<00:08,  2.35it/s]Finetune Epoch:  2/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.3225. :  16%|█▌        | 4/25 [00:02<00:08,  2.35it/s]Finetune Epoch:  2/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.3262. :  16%|█▌        | 4/25 [00:02<00:08,  2.35it/s]Finetune Epoch:  2/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.3262. :  28%|██▊       | 7/25 [00:02<00:04,  4.48it/s]Finetune Epoch:  2/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.3134. :  28%|██▊       | 7/25 [00:02<00:04,  4.48it/s]Finetune Epoch:  2/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.3128. :  28%|██▊       | 7/25 [00:02<00:04,  4.48it/s]Finetune Epoch:  2/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.3128. :  36%|███▌      | 9/25 [00:02<00:02,  6.05it/s]Finetune Epoch:  2/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.3226. :  36%|███▌      | 9/25 [00:02<00:02,  6.05it/s]Finetune Epoch:  2/ 5. Data: 2.26s. Batch: 2.30s. Loss: 2.3328. :  36%|███▌      | 9/25 [00:02<00:02,  6.05it/s]Finetune Epoch:  2/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.3230. :  36%|███▌      | 9/25 [00:02<00:02,  6.05it/s]Finetune Epoch:  2/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.3230. :  48%|████▊     | 12/25 [00:02<00:01,  8.62it/s]Finetune Epoch:  2/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.3225. :  48%|████▊     | 12/25 [00:02<00:01,  8.62it/s]Finetune Epoch:  2/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.3289. :  48%|████▊     | 12/25 [00:02<00:01,  8.62it/s]Finetune Epoch:  2/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.3289. :  56%|█████▌    | 14/25 [00:02<00:01, 10.15it/s]Finetune Epoch:  2/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.3301. :  56%|█████▌    | 14/25 [00:02<00:01, 10.15it/s]Finetune Epoch:  2/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.3303. :  56%|█████▌    | 14/25 [00:02<00:01, 10.15it/s]Finetune Epoch:  2/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.3303. :  64%|██████▍   | 16/25 [00:02<00:00, 11.38it/s]Finetune Epoch:  2/ 5. Data: 2.41s. Batch: 2.45s. Loss: 2.3312. :  64%|██████▍   | 16/25 [00:02<00:00, 11.38it/s]Finetune Epoch:  2/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.3280. :  64%|██████▍   | 16/25 [00:02<00:00, 11.38it/s]Finetune Epoch:  2/ 5. Data: 2.46s. Batch: 2.51s. Loss: 2.3289. :  64%|██████▍   | 16/25 [00:02<00:00, 11.38it/s]Finetune Epoch:  2/ 5. Data: 2.46s. Batch: 2.51s. Loss: 2.3289. :  76%|███████▌  | 19/25 [00:02<00:00, 13.68it/s]Finetune Epoch:  2/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.3250. :  76%|███████▌  | 19/25 [00:03<00:00, 13.68it/s]Finetune Epoch:  2/ 5. Data: 2.51s. Batch: 2.56s. Loss: 2.3191. :  76%|███████▌  | 19/25 [00:03<00:00, 13.68it/s]Finetune Epoch:  2/ 5. Data: 2.54s. Batch: 2.58s. Loss: 2.3243. :  76%|███████▌  | 19/25 [00:03<00:00, 13.68it/s]Finetune Epoch:  2/ 5. Data: 2.54s. Batch: 2.58s. Loss: 2.3243. :  88%|████████▊ | 22/25 [00:03<00:00, 16.12it/s]Finetune Epoch:  2/ 5. Data: 2.56s. Batch: 2.61s. Loss: 2.3186. :  88%|████████▊ | 22/25 [00:03<00:00, 16.12it/s]Finetune Epoch:  2/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.3217. :  88%|████████▊ | 22/25 [00:03<00:00, 16.12it/s]Finetune Epoch:  2/ 5. Data: 2.61s. Batch: 2.65s. Loss: 2.3206. :  88%|████████▊ | 22/25 [00:03<00:00, 16.12it/s]Finetune Epoch:  2/ 5. Data: 2.61s. Batch: 2.65s. Loss: 2.3206. : 100%|██████████| 25/25 [00:03<00:00, 17.94it/s]Finetune Epoch:  2/ 5. Data: 2.61s. Batch: 2.65s. Loss: 2.3206. : 100%|██████████| 25/25 [00:03<00:00,  7.31it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.03s. Loss: 1.0766. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.03s. Loss: 1.0766. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.02s. Loss: 1.1214. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.69s. Loss: 1.1207. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.52s. Loss: 1.1328. top1: 97.66. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.42s. Loss: 1.1330. top1: 98.12. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.1358. top1: 98.44. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.1334. top1: 98.66. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.27s. Loss: 1.1300. top1: 98.83. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.1269. top1: 98.96. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1220. top1: 99.06. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:05,  2.03s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1220. top1: 99.06. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.1277. top1: 98.86. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1284. top1: 98.96. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.1228. top1: 99.04. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1262. top1: 98.88. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1277. top1: 98.96. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1251. top1: 99.02. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1286. top1: 99.08. top5: 100.00. :  16%|█▌        | 10/63 [00:02<00:08,  6.33it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1286. top1: 99.08. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1281. top1: 99.13. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1285. top1: 99.01. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1294. top1: 99.06. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1306. top1: 99.11. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1260. top1: 99.15. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1291. top1: 99.18. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1315. top1: 99.22. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1328. top1: 99.12. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1316. top1: 99.16. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1331. top1: 99.19. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1347. top1: 99.22. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 11.74it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1347. top1: 99.22. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1353. top1: 99.25. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1341. top1: 99.27. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1339. top1: 99.29. top5: 100.00. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2517. top1: 96.97. top5: 99.71. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s] Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4281. top1: 94.03. top5: 99.43. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5919. top1: 91.27. top5: 98.99. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.7472. top1: 88.66. top5: 98.30. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.8952. top1: 86.20. top5: 98.26. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.0602. top1: 83.87. top5: 97.80. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1959. top1: 81.66. top5: 97.53. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2915. top1: 79.57. top5: 97.20. :  44%|████▍     | 28/63 [00:02<00:01, 22.39it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2915. top1: 79.57. top5: 97.20. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.3998. top1: 77.58. top5: 96.72. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.5281. top1: 75.69. top5: 96.34. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.6123. top1: 73.88. top5: 96.35. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.7115. top1: 72.17. top5: 96.00. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.8173. top1: 70.53. top5: 95.74. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9014. top1: 68.96. top5: 95.69. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9770. top1: 67.46. top5: 95.72. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.0624. top1: 66.02. top5: 95.55. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1488. top1: 64.65. top5: 95.44. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2349. top1: 63.33. top5: 95.22. :  62%|██████▏   | 39/63 [00:02<00:00, 34.13it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2349. top1: 63.33. top5: 95.22. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3175. top1: 62.06. top5: 95.25. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.3975. top1: 60.85. top5: 94.98. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.4702. top1: 59.68. top5: 95.01. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5257. top1: 58.55. top5: 94.93. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5877. top1: 57.47. top5: 94.73. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.6388. top1: 56.42. top5: 94.55. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.6924. top1: 55.41. top5: 94.42. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.7393. top1: 54.44. top5: 94.41. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.7920. top1: 53.50. top5: 94.29. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8400. top1: 52.60. top5: 94.17. :  78%|███████▊  | 49/63 [00:02<00:00, 44.61it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.8400. top1: 52.60. top5: 94.17. :  94%|█████████▎| 59/63 [00:02<00:00, 53.16it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.8855. top1: 51.72. top5: 94.11. :  94%|█████████▎| 59/63 [00:02<00:00, 53.16it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.9352. top1: 50.87. top5: 94.01. :  94%|█████████▎| 59/63 [00:02<00:00, 53.16it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.9761. top1: 50.05. top5: 94.00. :  94%|█████████▎| 59/63 [00:02<00:00, 53.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0090. top1: 49.65. top5: 93.95. :  94%|█████████▎| 59/63 [00:02<00:00, 53.16it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0090. top1: 49.65. top5: 93.95. : 100%|██████████| 63/63 [00:02<00:00, 21.38it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.2758. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch:  3/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.2758. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  3/ 5. Data: 2.12s. Batch: 2.17s. Loss: 2.2901. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  3/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.2712. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  3/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.2712. :  12%|█▏        | 3/25 [00:02<00:13,  1.67it/s]Finetune Epoch:  3/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.2715. :  12%|█▏        | 3/25 [00:02<00:13,  1.67it/s]Finetune Epoch:  3/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.3087. :  12%|█▏        | 3/25 [00:02<00:13,  1.67it/s]Finetune Epoch:  3/ 5. Data: 2.23s. Batch: 2.27s. Loss: 2.3196. :  12%|█▏        | 3/25 [00:02<00:13,  1.67it/s]Finetune Epoch:  3/ 5. Data: 2.23s. Batch: 2.27s. Loss: 2.3196. :  24%|██▍       | 6/25 [00:02<00:04,  3.85it/s]Finetune Epoch:  3/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.3169. :  24%|██▍       | 6/25 [00:02<00:04,  3.85it/s]Finetune Epoch:  3/ 5. Data: 2.28s. Batch: 2.32s. Loss: 2.2989. :  24%|██▍       | 6/25 [00:02<00:04,  3.85it/s]Finetune Epoch:  3/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.2923. :  24%|██▍       | 6/25 [00:02<00:04,  3.85it/s]Finetune Epoch:  3/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.2923. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch:  3/ 5. Data: 2.33s. Batch: 2.37s. Loss: 2.2779. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch:  3/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.2873. :  36%|███▌      | 9/25 [00:02<00:02,  6.19it/s]Finetune Epoch:  3/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.2873. :  44%|████▍     | 11/25 [00:02<00:01,  7.81it/s]Finetune Epoch:  3/ 5. Data: 2.38s. Batch: 2.42s. Loss: 2.2861. :  44%|████▍     | 11/25 [00:02<00:01,  7.81it/s]Finetune Epoch:  3/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.2830. :  44%|████▍     | 11/25 [00:02<00:01,  7.81it/s]Finetune Epoch:  3/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.2830. :  52%|█████▏    | 13/25 [00:02<00:01,  9.59it/s]Finetune Epoch:  3/ 5. Data: 2.43s. Batch: 2.47s. Loss: 2.2892. :  52%|█████▏    | 13/25 [00:02<00:01,  9.59it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.2834. :  52%|█████▏    | 13/25 [00:02<00:01,  9.59it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.2834. :  60%|██████    | 15/25 [00:02<00:00, 11.36it/s]Finetune Epoch:  3/ 5. Data: 2.48s. Batch: 2.52s. Loss: 2.2914. :  60%|██████    | 15/25 [00:02<00:00, 11.36it/s]Finetune Epoch:  3/ 5. Data: 2.50s. Batch: 2.55s. Loss: 2.2948. :  60%|██████    | 15/25 [00:02<00:00, 11.36it/s]Finetune Epoch:  3/ 5. Data: 2.50s. Batch: 2.55s. Loss: 2.2948. :  68%|██████▊   | 17/25 [00:02<00:00, 13.02it/s]Finetune Epoch:  3/ 5. Data: 2.53s. Batch: 2.57s. Loss: 2.2921. :  68%|██████▊   | 17/25 [00:03<00:00, 13.02it/s]Finetune Epoch:  3/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2885. :  68%|██████▊   | 17/25 [00:03<00:00, 13.02it/s]Finetune Epoch:  3/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2885. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  3/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.2906. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  3/ 5. Data: 2.60s. Batch: 2.65s. Loss: 2.2858. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  3/ 5. Data: 2.60s. Batch: 2.65s. Loss: 2.2858. :  84%|████████▍ | 21/25 [00:03<00:00, 15.48it/s]Finetune Epoch:  3/ 5. Data: 2.63s. Batch: 2.68s. Loss: 2.2827. :  84%|████████▍ | 21/25 [00:03<00:00, 15.48it/s]Finetune Epoch:  3/ 5. Data: 2.65s. Batch: 2.70s. Loss: 2.2818. :  84%|████████▍ | 21/25 [00:03<00:00, 15.48it/s]Finetune Epoch:  3/ 5. Data: 2.65s. Batch: 2.70s. Loss: 2.2818. :  92%|█████████▏| 23/25 [00:03<00:00, 16.53it/s]Finetune Epoch:  3/ 5. Data: 2.68s. Batch: 2.73s. Loss: 2.2827. :  92%|█████████▏| 23/25 [00:03<00:00, 16.53it/s]Finetune Epoch:  3/ 5. Data: 2.71s. Batch: 2.75s. Loss: 2.2867. :  92%|█████████▏| 23/25 [00:03<00:00, 16.53it/s]Finetune Epoch:  3/ 5. Data: 2.71s. Batch: 2.75s. Loss: 2.2867. : 100%|██████████| 25/25 [00:03<00:00, 17.32it/s]Finetune Epoch:  3/ 5. Data: 2.71s. Batch: 2.75s. Loss: 2.2867. : 100%|██████████| 25/25 [00:03<00:00,  6.96it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.95s. Loss: 1.0284. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.95s. Loss: 1.0284. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:01<02:00,  1.95s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.00s. Loss: 1.0715. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:01<02:00,  1.95s/it] Test Iter:   3/ 63. Data: 0.00s. Batch: 0.67s. Loss: 1.0747. top1: 96.88. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:00,  1.95s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.51s. Loss: 1.0779. top1: 97.66. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:00,  1.95s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 1.0763. top1: 98.12. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:00,  1.95s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 1.0763. top1: 98.12. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.34s. Loss: 1.0753. top1: 98.44. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.0709. top1: 98.66. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.0669. top1: 98.83. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 1.0667. top1: 98.96. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.0619. top1: 99.06. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.0644. top1: 98.86. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.0671. top1: 98.96. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0635. top1: 99.04. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0666. top1: 99.11. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0681. top1: 99.17. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0666. top1: 99.22. top5: 100.00. :   8%|▊         | 5/63 [00:02<00:18,  3.19it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0666. top1: 99.22. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0685. top1: 99.26. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0680. top1: 99.31. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0687. top1: 99.18. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0702. top1: 99.22. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0703. top1: 99.26. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0686. top1: 99.29. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0704. top1: 99.32. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0708. top1: 99.35. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:03, 12.63it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0708. top1: 99.35. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0719. top1: 99.25. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0717. top1: 99.28. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0730. top1: 99.31. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0734. top1: 99.33. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0741. top1: 99.35. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0738. top1: 99.38. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0733. top1: 99.40. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1574. top1: 97.07. top5: 100.00. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2851. top1: 94.13. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s] Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4043. top1: 91.36. top5: 99.91. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5173. top1: 88.75. top5: 99.73. :  38%|███▊      | 24/63 [00:02<00:01, 20.02it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5173. top1: 88.75. top5: 99.73. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.6242. top1: 86.28. top5: 99.65. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.7445. top1: 83.95. top5: 99.66. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.8430. top1: 81.74. top5: 99.67. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.9122. top1: 79.65. top5: 99.68. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.9908. top1: 77.66. top5: 99.53. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.0842. top1: 75.76. top5: 99.47. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.1445. top1: 73.96. top5: 99.40. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2161. top1: 72.24. top5: 99.20. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.2933. top1: 70.60. top5: 99.15. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3540. top1: 69.03. top5: 99.17. :  56%|█████▌    | 35/63 [00:02<00:00, 32.09it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3540. top1: 69.03. top5: 99.17. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4080. top1: 67.53. top5: 99.18. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4699. top1: 66.09. top5: 99.20. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.5326. top1: 64.71. top5: 99.15. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.5954. top1: 63.39. top5: 99.11. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.6544. top1: 62.12. top5: 99.06. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7121. top1: 60.91. top5: 99.08. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.7648. top1: 59.74. top5: 99.10. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8054. top1: 58.61. top5: 99.06. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8504. top1: 57.52. top5: 99.07. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.8866. top1: 56.48. top5: 99.09. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9254. top1: 55.47. top5: 99.11. :  71%|███████▏  | 45/63 [00:02<00:00, 43.04it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9254. top1: 55.47. top5: 99.11. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9589. top1: 54.50. top5: 99.12. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9969. top1: 53.56. top5: 99.08. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.0317. top1: 52.65. top5: 98.99. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.0648. top1: 51.77. top5: 99.01. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1008. top1: 50.92. top5: 98.92. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1301. top1: 50.10. top5: 98.89. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1544. top1: 49.70. top5: 98.90. :  89%|████████▉ | 56/63 [00:02<00:00, 54.89it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1544. top1: 49.70. top5: 98.90. : 100%|██████████| 63/63 [00:02<00:00, 22.09it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/ 5. Data: 2.01s. Batch: 2.04s. Loss: 2.3684. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch:  4/ 5. Data: 2.01s. Batch: 2.04s. Loss: 2.3684. :   4%|▍         | 1/25 [00:02<00:49,  2.04s/it]Finetune Epoch:  4/ 5. Data: 2.03s. Batch: 2.07s. Loss: 2.3002. :   4%|▍         | 1/25 [00:02<00:49,  2.04s/it]Finetune Epoch:  4/ 5. Data: 2.06s. Batch: 2.10s. Loss: 2.3010. :   4%|▍         | 1/25 [00:02<00:49,  2.04s/it]Finetune Epoch:  4/ 5. Data: 2.06s. Batch: 2.10s. Loss: 2.3010. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch:  4/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.2796. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch:  4/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.2594. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch:  4/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.2583. :  12%|█▏        | 3/25 [00:02<00:12,  1.74it/s]Finetune Epoch:  4/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.2583. :  24%|██▍       | 6/25 [00:02<00:04,  3.98it/s]Finetune Epoch:  4/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.2502. :  24%|██▍       | 6/25 [00:02<00:04,  3.98it/s]Finetune Epoch:  4/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.2515. :  24%|██▍       | 6/25 [00:02<00:04,  3.98it/s]Finetune Epoch:  4/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.2657. :  24%|██▍       | 6/25 [00:02<00:04,  3.98it/s]Finetune Epoch:  4/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.2657. :  36%|███▌      | 9/25 [00:02<00:02,  6.47it/s]Finetune Epoch:  4/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.2597. :  36%|███▌      | 9/25 [00:02<00:02,  6.47it/s]Finetune Epoch:  4/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.2544. :  36%|███▌      | 9/25 [00:02<00:02,  6.47it/s]Finetune Epoch:  4/ 5. Data: 2.28s. Batch: 2.32s. Loss: 2.2602. :  36%|███▌      | 9/25 [00:02<00:02,  6.47it/s]Finetune Epoch:  4/ 5. Data: 2.28s. Batch: 2.32s. Loss: 2.2602. :  48%|████▊     | 12/25 [00:02<00:01,  8.90it/s]Finetune Epoch:  4/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.2639. :  48%|████▊     | 12/25 [00:02<00:01,  8.90it/s]Finetune Epoch:  4/ 5. Data: 2.33s. Batch: 2.37s. Loss: 2.2611. :  48%|████▊     | 12/25 [00:02<00:01,  8.90it/s]Finetune Epoch:  4/ 5. Data: 2.33s. Batch: 2.37s. Loss: 2.2611. :  56%|█████▌    | 14/25 [00:02<00:01, 10.48it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.2551. :  56%|█████▌    | 14/25 [00:02<00:01, 10.48it/s]Finetune Epoch:  4/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.2569. :  56%|█████▌    | 14/25 [00:02<00:01, 10.48it/s]Finetune Epoch:  4/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.2569. :  64%|██████▍   | 16/25 [00:02<00:00, 11.64it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.2519. :  64%|██████▍   | 16/25 [00:02<00:00, 11.64it/s]Finetune Epoch:  4/ 5. Data: 2.43s. Batch: 2.47s. Loss: 2.2500. :  64%|██████▍   | 16/25 [00:02<00:00, 11.64it/s]Finetune Epoch:  4/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.2495. :  64%|██████▍   | 16/25 [00:02<00:00, 11.64it/s]Finetune Epoch:  4/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.2495. :  76%|███████▌  | 19/25 [00:02<00:00, 13.82it/s]Finetune Epoch:  4/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.2515. :  76%|███████▌  | 19/25 [00:03<00:00, 13.82it/s]Finetune Epoch:  4/ 5. Data: 2.50s. Batch: 2.55s. Loss: 2.2529. :  76%|███████▌  | 19/25 [00:03<00:00, 13.82it/s]Finetune Epoch:  4/ 5. Data: 2.50s. Batch: 2.55s. Loss: 2.2529. :  84%|████████▍ | 21/25 [00:03<00:00, 15.04it/s]Finetune Epoch:  4/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.2495. :  84%|████████▍ | 21/25 [00:03<00:00, 15.04it/s]Finetune Epoch:  4/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2454. :  84%|████████▍ | 21/25 [00:03<00:00, 15.04it/s]Finetune Epoch:  4/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2454. :  92%|█████████▏| 23/25 [00:03<00:00, 16.03it/s]Finetune Epoch:  4/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.2359. :  92%|█████████▏| 23/25 [00:03<00:00, 16.03it/s]Finetune Epoch:  4/ 5. Data: 2.60s. Batch: 2.65s. Loss: 2.2349. :  92%|█████████▏| 23/25 [00:03<00:00, 16.03it/s]Finetune Epoch:  4/ 5. Data: 2.60s. Batch: 2.65s. Loss: 2.2349. : 100%|██████████| 25/25 [00:03<00:00, 16.95it/s]Finetune Epoch:  4/ 5. Data: 2.60s. Batch: 2.65s. Loss: 2.2349. : 100%|██████████| 25/25 [00:03<00:00,  7.22it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.10s. Loss: 1.0456. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.10s. Loss: 1.0456. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.05s. Loss: 1.0857. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.71s. Loss: 1.0939. top1: 98.96. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.53s. Loss: 1.0890. top1: 99.22. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.43s. Loss: 1.0856. top1: 99.38. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.36s. Loss: 1.0813. top1: 99.48. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.0755. top1: 99.55. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:10,  2.10s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.31s. Loss: 1.0755. top1: 99.55. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.28s. Loss: 1.0714. top1: 99.61. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.25s. Loss: 1.0737. top1: 99.31. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.22s. Loss: 1.0688. top1: 99.38. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 1.0687. top1: 99.15. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.0729. top1: 99.22. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.0712. top1: 99.28. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.0738. top1: 99.33. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.0754. top1: 99.38. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0749. top1: 99.41. top5: 100.00. :  11%|█         | 7/63 [00:02<00:13,  4.27it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0749. top1: 99.41. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.0755. top1: 99.45. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.0752. top1: 99.48. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0761. top1: 99.34. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.0779. top1: 99.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0770. top1: 99.40. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.0775. top1: 99.43. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0783. top1: 99.46. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0771. top1: 99.48. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.0780. top1: 99.38. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0785. top1: 99.40. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0795. top1: 99.42. top5: 100.00. :  25%|██▌       | 16/63 [00:02<00:04, 11.26it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0795. top1: 99.42. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.0789. top1: 99.44. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0797. top1: 99.46. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0799. top1: 99.48. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.0793. top1: 99.50. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1396. top1: 97.17. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.2325. top1: 94.22. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3194. top1: 91.45. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4021. top1: 88.84. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4795. top1: 86.37. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.5673. top1: 84.04. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.6393. top1: 81.83. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.54it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.6393. top1: 81.83. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.6900. top1: 79.73. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.7474. top1: 77.73. top5: 99.92. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s] Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.8156. top1: 75.84. top5: 99.85. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.8592. top1: 74.03. top5: 99.85. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.9109. top1: 72.31. top5: 99.78. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.9675. top1: 70.67. top5: 99.79. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.0115. top1: 69.10. top5: 99.79. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.0502. top1: 67.60. top5: 99.80. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.0953. top1: 66.16. top5: 99.80. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1408. top1: 64.78. top5: 99.80. :  60%|██████    | 38/63 [00:02<00:00, 32.88it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1408. top1: 64.78. top5: 99.80. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1868. top1: 63.46. top5: 99.74. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2289. top1: 62.19. top5: 99.69. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.2705. top1: 60.97. top5: 99.69. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3088. top1: 59.80. top5: 99.70. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3388. top1: 58.67. top5: 99.71. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3717. top1: 57.58. top5: 99.71. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.3974. top1: 56.53. top5: 99.72. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4257. top1: 55.52. top5: 99.72. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4497. top1: 54.55. top5: 99.73. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4773. top1: 53.61. top5: 99.73. :  76%|███████▌  | 48/63 [00:02<00:00, 43.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.4773. top1: 53.61. top5: 99.73. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.5027. top1: 52.70. top5: 99.74. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.5271. top1: 51.82. top5: 99.74. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.5533. top1: 50.97. top5: 99.69. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5743. top1: 50.15. top5: 99.70. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5923. top1: 49.75. top5: 99.70. :  92%|█████████▏| 58/63 [00:02<00:00, 53.23it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.5923. top1: 49.75. top5: 99.70. : 100%|██████████| 63/63 [00:03<00:00, 20.94it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  5/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.2799. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch:  5/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.2799. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  5/ 5. Data: 2.11s. Batch: 2.18s. Loss: 2.2964. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  5/ 5. Data: 2.15s. Batch: 2.21s. Loss: 2.3074. :   4%|▍         | 1/25 [00:02<00:51,  2.13s/it]Finetune Epoch:  5/ 5. Data: 2.15s. Batch: 2.21s. Loss: 2.3074. :  12%|█▏        | 3/25 [00:02<00:13,  1.65it/s]Finetune Epoch:  5/ 5. Data: 2.18s. Batch: 2.24s. Loss: 2.2729. :  12%|█▏        | 3/25 [00:02<00:13,  1.65it/s]Finetune Epoch:  5/ 5. Data: 2.21s. Batch: 2.27s. Loss: 2.2477. :  12%|█▏        | 3/25 [00:02<00:13,  1.65it/s]Finetune Epoch:  5/ 5. Data: 2.21s. Batch: 2.27s. Loss: 2.2477. :  20%|██        | 5/25 [00:02<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 2.24s. Batch: 2.30s. Loss: 2.2258. :  20%|██        | 5/25 [00:02<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.2068. :  20%|██        | 5/25 [00:02<00:06,  3.10it/s]Finetune Epoch:  5/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.2068. :  28%|██▊       | 7/25 [00:02<00:03,  4.80it/s]Finetune Epoch:  5/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.2109. :  28%|██▊       | 7/25 [00:02<00:03,  4.80it/s]Finetune Epoch:  5/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.2123. :  28%|██▊       | 7/25 [00:02<00:03,  4.80it/s]Finetune Epoch:  5/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.2123. :  36%|███▌      | 9/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  5/ 5. Data: 2.35s. Batch: 2.41s. Loss: 2.2221. :  36%|███▌      | 9/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  5/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.2248. :  36%|███▌      | 9/25 [00:02<00:02,  6.69it/s]Finetune Epoch:  5/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.2248. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  5/ 5. Data: 2.41s. Batch: 2.46s. Loss: 2.2150. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  5/ 5. Data: 2.43s. Batch: 2.49s. Loss: 2.2253. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  5/ 5. Data: 2.43s. Batch: 2.49s. Loss: 2.2253. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch:  5/ 5. Data: 2.46s. Batch: 2.52s. Loss: 2.2208. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch:  5/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.2214. :  52%|█████▏    | 13/25 [00:02<00:01, 10.35it/s]Finetune Epoch:  5/ 5. Data: 2.49s. Batch: 2.54s. Loss: 2.2214. :  60%|██████    | 15/25 [00:02<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.52s. Batch: 2.57s. Loss: 2.2186. :  60%|██████    | 15/25 [00:02<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2141. :  60%|██████    | 15/25 [00:03<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.55s. Batch: 2.60s. Loss: 2.2141. :  68%|██████▊   | 17/25 [00:03<00:00, 12.96it/s]Finetune Epoch:  5/ 5. Data: 2.57s. Batch: 2.63s. Loss: 2.2090. :  68%|██████▊   | 17/25 [00:03<00:00, 12.96it/s]Finetune Epoch:  5/ 5. Data: 2.60s. Batch: 2.66s. Loss: 2.2045. :  68%|██████▊   | 17/25 [00:03<00:00, 12.96it/s]Finetune Epoch:  5/ 5. Data: 2.60s. Batch: 2.66s. Loss: 2.2045. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  5/ 5. Data: 2.63s. Batch: 2.69s. Loss: 2.2002. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  5/ 5. Data: 2.66s. Batch: 2.71s. Loss: 2.1982. :  76%|███████▌  | 19/25 [00:03<00:00, 14.27it/s]Finetune Epoch:  5/ 5. Data: 2.66s. Batch: 2.71s. Loss: 2.1982. :  84%|████████▍ | 21/25 [00:03<00:00, 15.36it/s]Finetune Epoch:  5/ 5. Data: 2.69s. Batch: 2.74s. Loss: 2.1977. :  84%|████████▍ | 21/25 [00:03<00:00, 15.36it/s]Finetune Epoch:  5/ 5. Data: 2.72s. Batch: 2.77s. Loss: 2.1982. :  84%|████████▍ | 21/25 [00:03<00:00, 15.36it/s]Finetune Epoch:  5/ 5. Data: 2.72s. Batch: 2.77s. Loss: 2.1982. :  92%|█████████▏| 23/25 [00:03<00:00, 16.14it/s]Finetune Epoch:  5/ 5. Data: 2.74s. Batch: 2.80s. Loss: 2.1980. :  92%|█████████▏| 23/25 [00:03<00:00, 16.14it/s]Finetune Epoch:  5/ 5. Data: 2.77s. Batch: 2.83s. Loss: 2.1913. :  92%|█████████▏| 23/25 [00:03<00:00, 16.14it/s]Finetune Epoch:  5/ 5. Data: 2.77s. Batch: 2.83s. Loss: 2.1913. : 100%|██████████| 25/25 [00:03<00:00, 16.90it/s]Finetune Epoch:  5/ 5. Data: 2.77s. Batch: 2.83s. Loss: 2.1913. : 100%|██████████| 25/25 [00:03<00:00,  6.76it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.01s. Loss: 1.1001. top1: 100.00. top5: 100.00. :   0%|          | 0/63 [00:02<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.01s. Loss: 1.1001. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.03s. Loss: 1.1375. top1: 100.00. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.69s. Loss: 1.1496. top1: 98.96. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it] Test Iter:   4/ 63. Data: 0.00s. Batch: 0.52s. Loss: 1.1378. top1: 99.22. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.42s. Loss: 1.1333. top1: 99.38. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.35s. Loss: 1.1268. top1: 99.48. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 1.1206. top1: 99.55. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.1165. top1: 99.61. top5: 100.00. :   2%|▏         | 1/63 [00:02<02:04,  2.01s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 1.1165. top1: 99.61. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.24s. Loss: 1.1207. top1: 99.31. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 1.1159. top1: 99.38. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 1.1136. top1: 99.15. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 1.1190. top1: 99.22. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 1.1188. top1: 99.28. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 1.1210. top1: 99.33. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 1.1226. top1: 99.38. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 1.1228. top1: 99.41. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1224. top1: 99.45. top5: 100.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.09it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 1.1224. top1: 99.45. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1224. top1: 99.48. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 1.1233. top1: 99.34. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1250. top1: 99.38. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 1.1233. top1: 99.40. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1254. top1: 99.43. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1254. top1: 99.46. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 1.1232. top1: 99.48. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1238. top1: 99.38. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1248. top1: 99.40. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1254. top1: 99.42. top5: 100.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.38it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 1.1254. top1: 99.42. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1240. top1: 99.44. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1250. top1: 99.46. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1256. top1: 99.48. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 1.1249. top1: 99.50. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.1681. top1: 97.17. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2354. top1: 94.22. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.2987. top1: 91.45. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.3593. top1: 88.84. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4154. top1: 86.37. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 1.4793. top1: 84.04. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.5318. top1: 81.83. top5: 100.00. :  43%|████▎     | 27/63 [00:02<00:01, 21.84it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.5318. top1: 81.83. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.5692. top1: 79.73. top5: 100.00. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.6112. top1: 77.73. top5: 99.92. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s] Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.6610. top1: 75.84. top5: 99.85. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.6925. top1: 74.03. top5: 99.85. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.7300. top1: 72.31. top5: 99.85. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.7712. top1: 70.67. top5: 99.86. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 1.8031. top1: 69.10. top5: 99.86. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.8309. top1: 67.60. top5: 99.86. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.8636. top1: 66.16. top5: 99.87. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.8964. top1: 64.78. top5: 99.87. :  60%|██████    | 38/63 [00:02<00:00, 33.45it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.8964. top1: 64.78. top5: 99.87. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.9299. top1: 63.46. top5: 99.87. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.9597. top1: 62.19. top5: 99.88. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 1.9897. top1: 60.97. top5: 99.88. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.0175. top1: 59.80. top5: 99.88. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.0398. top1: 58.67. top5: 99.88. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.0638. top1: 57.58. top5: 99.88. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.0820. top1: 56.53. top5: 99.89. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1026. top1: 55.52. top5: 99.89. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1197. top1: 54.55. top5: 99.89. :  76%|███████▌  | 48/63 [00:02<00:00, 43.77it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1197. top1: 54.55. top5: 99.89. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1398. top1: 53.61. top5: 99.89. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.1586. top1: 52.70. top5: 99.89. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1766. top1: 51.82. top5: 99.90. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.1957. top1: 50.97. top5: 99.90. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2105. top1: 50.15. top5: 99.90. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2237. top1: 49.75. top5: 99.90. :  90%|█████████ | 57/63 [00:02<00:00, 51.98it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.2237. top1: 49.75. top5: 99.90. : 100%|██████████| 63/63 [00:02<00:00, 21.50it/s]
total 9984 correct 5685 accuracy 56.941105769230774
[INFO] main.py:349 > [2-2] Set environment for the current task
[INFO] finetune.py:104 > Apply before_task
[INFO] finetune.py:146 > Reset the optimizer and scheduler states
[INFO] finetune.py:152 > Increasing the head of fc 10 -> 10
[INFO] main.py:357 > [2-3] Start to train under online
[INFO] main.py:372 > Train over streamed data once
batch_size : 128 stream_batch_size : 44 memory_batch_size : 42 pseudo_stream_size 42
num_stuff 237
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
[INFO] rainbow_memory.py:120 > Streamed samples: 800
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 9984
[INFO] rainbow_memory.py:128 > Train samples: 11284
[INFO] rainbow_memory.py:129 > Test samples: 6000
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([38, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([124, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
count 18
task2/train/loss 8.458017016450563 0
task2/test/loss 6.570217265917437 0
task2/test/acc 0.23066666666666666 0
task2/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 2 | Epoch 1/1 | train_loss 8.4580 | train_acc 0.6755 | test_loss 6.5702 | test_acc 0.2307 | lr 0.0050
[INFO] finetune.py:169 > Update memory over 10 classes by uncertainty
uncertainty
[INFO] finetune.py:679 > Compute uncertainty by vr_randaug!
[WARNING] finetune.py:639 > Fill the unused slots by breaking the equilibrium.
[INFO] finetune.py:223 > Memory statistic
[INFO] finetune.py:225 > 
frog          124
truck         114
automobile     68
bird           68
deer           65
dog            61
Name: klass, dtype: int64
[INFO] main.py:388 > Train over memory
batch_size : 64 stream_batch_size : 22 memory_batch_size : 21 pseudo_stream_size 21
num_stuff 0
[INFO] rainbow_memory.py:120 > Streamed samples: 0
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 0
[INFO] rainbow_memory.py:128 > Train samples: 500
[INFO] rainbow_memory.py:129 > Test samples: 6000
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task2/train/loss 3.4224417954683304 0
task2/test/loss 1.7975182786529318 0
task2/test/acc 0.203 0
task2/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 2 | Epoch 1/2 | train_loss 3.4224 | train_acc 0.2280 | test_loss 1.7975 | test_acc 0.2030 | lr 0.0050
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task2/train/loss 2.4671774009863534 1
task2/test/loss 1.8679929347265334 1
task2/test/acc 0.21583333333333332 1
task2/train/lr 0.05 1
[INFO] rainbow_memory.py:184 > Task 2 | Epoch 2/2 | train_loss 2.4672 | train_acc 0.2200 | test_loss 1.8680 | test_acc 0.2158 | lr 0.0500
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (2)
[INFO] main.py:398 > [2-4] Update the information for the current task
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (2)
[INFO] main.py:405 > [2-5] Report task result
Metrics/TaskAcc 0.21583333333333332 2

##################################################
# Task 3 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 30  current step :  0
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.19s. Batch: 0.33s. S_Loss: 2.2587. T_Loss: 2.8320. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.19s. Batch: 0.33s. S_Loss: 2.2587. T_Loss: 2.8320. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.02it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.09s. Batch: 0.22s. S_Loss: 2.3459. T_Loss: 2.7739. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.02it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.09s. Batch: 0.22s. S_Loss: 2.3459. T_Loss: 2.7739. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.84it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.06s. Batch: 0.19s. S_Loss: 2.3280. T_Loss: 2.7380. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.84it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.06s. Batch: 0.19s. S_Loss: 2.3280. T_Loss: 2.7380. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  6.02it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.3526. T_Loss: 2.6658. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  6.02it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.17s. S_Loss: 2.3526. T_Loss: 2.6658. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.68it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.16s. S_Loss: 2.3888. T_Loss: 2.6956. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.68it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.16s. S_Loss: 2.3888. T_Loss: 2.6956. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.35it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3762. T_Loss: 2.6464. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  7.35it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3762. T_Loss: 2.6464. Mask: 0.0000. :  60%|██████    | 6/10 [00:00<00:00,  7.80it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3868. T_Loss: 2.6443. Mask: 0.0045. :  60%|██████    | 6/10 [00:01<00:00,  7.80it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.15s. S_Loss: 2.3868. T_Loss: 2.6443. Mask: 0.0045. :  70%|███████   | 7/10 [00:01<00:00,  7.93it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.14s. S_Loss: 2.3891. T_Loss: 2.6440. Mask: 0.0039. :  70%|███████   | 7/10 [00:01<00:00,  7.93it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.14s. S_Loss: 2.3891. T_Loss: 2.6440. Mask: 0.0039. :  80%|████████  | 8/10 [00:01<00:00,  8.05it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4077. T_Loss: 2.6133. Mask: 0.0035. :  80%|████████  | 8/10 [00:01<00:00,  8.05it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4077. T_Loss: 2.6133. Mask: 0.0035. :  90%|█████████ | 9/10 [00:01<00:00,  7.70it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4092. T_Loss: 2.5995. Mask: 0.0063. :  90%|█████████ | 9/10 [00:01<00:00,  7.70it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4092. T_Loss: 2.5995. Mask: 0.0063. : 100%|██████████| 10/10 [00:01<00:00,  7.63it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4092. T_Loss: 2.5995. Mask: 0.0063. : 100%|██████████| 10/10 [00:01<00:00,  6.96it/s]
total : 30  current step :  1
total : 30  current step :  2
total : 30  current step :  3
total : 30  current step :  4
total : 30  current step :  5
total : 30  current step :  6
total : 30  current step :  7
total : 30  current step :  8
total : 30  current step :  9
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.91s. Loss: 21.0307. top1: 0.00. top5: 15.62. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.91s. Loss: 21.0307. top1: 0.00. top5: 15.62. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.96s. Loss: 21.4069. top1: 0.00. top5: 14.06. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 20.6831. top1: 0.00. top5: 19.79. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 19.8616. top1: 0.00. top5: 15.62. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 19.4166. top1: 0.00. top5: 16.25. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 19.0731. top1: 0.00. top5: 15.10. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 18.8628. top1: 0.00. top5: 16.07. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 18.8537. top1: 0.00. top5: 16.41. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 18.9217. top1: 0.00. top5: 17.36. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 18.8001. top1: 0.00. top5: 17.81. :   2%|▏         | 1/63 [00:01<01:58,  1.91s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 18.8936. top1: 0.00. top5: 17.33. :   2%|▏         | 1/63 [00:02<01:58,  1.91s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 19.0260. top1: 0.00. top5: 17.19. :   2%|▏         | 1/63 [00:02<01:58,  1.91s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 19.0260. top1: 0.00. top5: 17.19. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 18.9792. top1: 0.00. top5: 17.07. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 19.0239. top1: 0.00. top5: 16.52. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 19.1054. top1: 0.00. top5: 17.08. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 19.1252. top1: 0.00. top5: 17.38. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 19.0511. top1: 0.00. top5: 18.01. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 19.0513. top1: 0.00. top5: 17.88. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 18.9735. top1: 0.00. top5: 18.09. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 18.9577. top1: 0.00. top5: 17.81. :  19%|█▉        | 12/63 [00:02<00:06,  8.14it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 18.9577. top1: 0.00. top5: 17.81. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 18.9808. top1: 0.00. top5: 17.26. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 18.9569. top1: 0.00. top5: 17.05. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 18.9657. top1: 0.00. top5: 17.12. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 19.0613. top1: 0.00. top5: 17.45. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 19.0665. top1: 0.00. top5: 17.25. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 19.0893. top1: 0.00. top5: 16.95. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 19.0016. top1: 0.00. top5: 16.44. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 19.1091. top1: 0.00. top5: 16.52. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 19.0379. top1: 0.00. top5: 16.49. :  32%|███▏      | 20/63 [00:02<00:02, 14.54it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 19.0379. top1: 0.00. top5: 16.49. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.0104. top1: 0.00. top5: 16.04. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.0543. top1: 0.00. top5: 15.73. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.1631. top1: 0.00. top5: 15.33. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.1998. top1: 0.00. top5: 14.87. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.2411. top1: 0.00. top5: 14.43. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 19.2844. top1: 0.00. top5: 14.02. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.3342. top1: 0.00. top5: 13.63. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.4094. top1: 0.00. top5: 13.26. :  46%|████▌     | 29/63 [00:02<00:01, 23.12it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.4094. top1: 0.00. top5: 13.26. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.4689. top1: 0.00. top5: 12.91. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.4994. top1: 0.00. top5: 12.58. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.5461. top1: 0.00. top5: 12.27. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.5596. top1: 0.00. top5: 11.97. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.5690. top1: 0.00. top5: 11.68. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.5680. top1: 0.00. top5: 11.41. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.5859. top1: 0.00. top5: 11.15. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6233. top1: 0.00. top5: 10.90. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6691. top1: 0.00. top5: 10.67. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6569. top1: 0.00. top5: 10.44. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6949. top1: 0.00. top5: 10.22. :  59%|█████▊    | 37/63 [00:02<00:00, 30.67it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6949. top1: 0.00. top5: 10.22. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.6995. top1: 0.00. top5: 10.01. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.7135. top1: 0.00. top5: 9.81. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s] Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.7165. top1: 0.00. top5: 9.62. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.7605. top1: 0.00. top5: 9.44. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.7861. top1: 0.00. top5: 9.26. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.8270. top1: 0.00. top5: 9.09. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.8183. top1: 0.00. top5: 8.92. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8027. top1: 0.00. top5: 8.76. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8009. top1: 0.00. top5: 8.61. :  76%|███████▌  | 48/63 [00:02<00:00, 42.96it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8009. top1: 0.00. top5: 8.61. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8091. top1: 0.00. top5: 8.46. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8331. top1: 0.00. top5: 8.32. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8356. top1: 0.00. top5: 8.18. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8330. top1: 0.00. top5: 8.04. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8682. top1: 0.00. top5: 7.91. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8795. top1: 0.00. top5: 7.85. :  90%|█████████ | 57/63 [00:02<00:00, 51.75it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 19.8795. top1: 0.00. top5: 7.85. : 100%|██████████| 63/63 [00:02<00:00, 22.05it/s]
total : 30  current step :  10
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.2636. T_Loss: 2.6018. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.2636. T_Loss: 2.6018. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  6.95it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.3463. T_Loss: 2.5416. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:01,  6.95it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.3463. T_Loss: 2.5416. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  7.33it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3558. T_Loss: 2.5113. Mask: 0.0104. :  20%|██        | 2/10 [00:00<00:01,  7.33it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3558. T_Loss: 2.5113. Mask: 0.0104. :  30%|███       | 3/10 [00:00<00:00,  7.52it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3862. T_Loss: 2.4989. Mask: 0.0078. :  30%|███       | 3/10 [00:00<00:00,  7.52it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3862. T_Loss: 2.4989. Mask: 0.0078. :  40%|████      | 4/10 [00:00<00:00,  7.60it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3787. T_Loss: 2.4902. Mask: 0.0063. :  40%|████      | 4/10 [00:00<00:00,  7.60it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.13s. S_Loss: 2.3787. T_Loss: 2.4902. Mask: 0.0063. :  50%|█████     | 5/10 [00:00<00:00,  7.78it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3819. T_Loss: 2.4936. Mask: 0.0052. :  50%|█████     | 5/10 [00:00<00:00,  7.78it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.3819. T_Loss: 2.4936. Mask: 0.0052. :  60%|██████    | 6/10 [00:00<00:00,  7.55it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.4045. T_Loss: 2.4284. Mask: 0.0045. :  60%|██████    | 6/10 [00:01<00:00,  7.55it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.4045. T_Loss: 2.4284. Mask: 0.0045. :  70%|███████   | 7/10 [00:01<00:00,  6.01it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4040. T_Loss: 2.3979. Mask: 0.0078. :  70%|███████   | 7/10 [00:01<00:00,  6.01it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4040. T_Loss: 2.3979. Mask: 0.0078. :  80%|████████  | 8/10 [00:01<00:00,  6.55it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4228. T_Loss: 2.3442. Mask: 0.0104. :  80%|████████  | 8/10 [00:01<00:00,  6.55it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.4228. T_Loss: 2.3442. Mask: 0.0104. :  90%|█████████ | 9/10 [00:01<00:00,  6.94it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.4231. T_Loss: 2.2956. Mask: 0.0187. :  90%|█████████ | 9/10 [00:01<00:00,  6.94it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.4231. T_Loss: 2.2956. Mask: 0.0187. : 100%|██████████| 10/10 [00:01<00:00,  7.19it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.14s. S_Loss: 2.4231. T_Loss: 2.2956. Mask: 0.0187. : 100%|██████████| 10/10 [00:01<00:00,  7.07it/s]
total : 30  current step :  11
total : 30  current step :  12
total : 30  current step :  13
total : 30  current step :  14
total : 30  current step :  15
total : 30  current step :  16
total : 30  current step :  17
total : 30  current step :  18
total : 30  current step :  19
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.97s. Loss: 16.5441. top1: 0.00. top5: 21.88. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.97s. Loss: 16.5441. top1: 0.00. top5: 21.88. :   2%|▏         | 1/63 [00:01<02:02,  1.97s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.01s. Loss: 16.7994. top1: 0.00. top5: 18.75. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.68s. Loss: 16.2215. top1: 0.00. top5: 25.00. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.51s. Loss: 15.5655. top1: 0.00. top5: 20.31. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 15.2160. top1: 0.00. top5: 19.38. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.34s. Loss: 14.9443. top1: 0.00. top5: 18.75. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 14.7709. top1: 0.00. top5: 20.54. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 14.7675. top1: 0.00. top5: 20.70. :   2%|▏         | 1/63 [00:02<02:02,  1.97s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 14.7675. top1: 0.00. top5: 20.70. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 14.8168. top1: 0.00. top5: 22.22. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 14.7192. top1: 0.00. top5: 22.19. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 14.7932. top1: 0.00. top5: 21.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 14.9023. top1: 0.00. top5: 21.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 14.8618. top1: 0.00. top5: 21.88. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 14.8963. top1: 0.00. top5: 21.65. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 14.9612. top1: 0.00. top5: 22.08. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 14.9779. top1: 0.00. top5: 22.66. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 14.9209. top1: 0.00. top5: 23.16. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 14.9200. top1: 0.00. top5: 22.92. :  13%|█▎        | 8/63 [00:02<00:10,  5.17it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 14.9200. top1: 0.00. top5: 22.92. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 14.8575. top1: 0.00. top5: 23.03. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 14.8448. top1: 0.00. top5: 22.66. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 14.8628. top1: 0.00. top5: 21.88. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 14.8444. top1: 0.00. top5: 21.73. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 14.8507. top1: 0.00. top5: 21.74. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 14.9282. top1: 0.00. top5: 22.14. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 14.9319. top1: 0.00. top5: 21.88. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 14.9517. top1: 0.00. top5: 21.63. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 14.8822. top1: 0.00. top5: 21.41. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 14.9681. top1: 0.00. top5: 21.43. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 14.9109. top1: 0.00. top5: 21.23. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 14.8911. top1: 0.00. top5: 20.83. :  29%|██▊       | 18/63 [00:02<00:03, 13.30it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 14.8911. top1: 0.00. top5: 20.83. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 14.9245. top1: 0.00. top5: 20.36. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 15.0163. top1: 0.00. top5: 19.92. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 15.0500. top1: 0.00. top5: 19.32. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 15.0867. top1: 0.00. top5: 18.75. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 15.1253. top1: 0.00. top5: 18.21. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 15.1690. top1: 0.00. top5: 17.71. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.2328. top1: 0.00. top5: 17.23. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.2857. top1: 0.00. top5: 16.78. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3128. top1: 0.00. top5: 16.35. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3526. top1: 0.00. top5: 15.94. :  48%|████▊     | 30/63 [00:02<00:01, 24.78it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3526. top1: 0.00. top5: 15.94. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3675. top1: 0.00. top5: 15.55. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3783. top1: 0.00. top5: 15.18. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3795. top1: 0.00. top5: 14.83. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 15.3965. top1: 0.00. top5: 14.49. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4284. top1: 0.00. top5: 14.17. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4680. top1: 0.00. top5: 13.86. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4598. top1: 0.00. top5: 13.56. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4925. top1: 0.00. top5: 13.28. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4981. top1: 0.00. top5: 13.01. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5115. top1: 0.00. top5: 12.75. :  63%|██████▎   | 40/63 [00:02<00:00, 34.58it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5115. top1: 0.00. top5: 12.75. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5159. top1: 0.00. top5: 12.50. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5534. top1: 0.00. top5: 12.26. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5767. top1: 0.00. top5: 12.03. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6116. top1: 0.00. top5: 11.81. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6078. top1: 0.00. top5: 11.59. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5964. top1: 0.00. top5: 11.38. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5964. top1: 0.00. top5: 11.18. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6045. top1: 0.00. top5: 10.99. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6253. top1: 0.00. top5: 10.81. :  79%|███████▉  | 50/63 [00:02<00:00, 44.07it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6253. top1: 0.00. top5: 10.81. :  94%|█████████▎| 59/63 [00:02<00:00, 49.00it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 15.6284. top1: 0.00. top5: 10.62. :  94%|█████████▎| 59/63 [00:02<00:00, 49.00it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 15.6279. top1: 0.00. top5: 10.45. :  94%|█████████▎| 59/63 [00:02<00:00, 49.00it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 15.6567. top1: 0.00. top5: 10.28. :  94%|█████████▎| 59/63 [00:02<00:00, 49.00it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 15.6667. top1: 0.00. top5: 10.20. :  94%|█████████▎| 59/63 [00:02<00:00, 49.00it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 15.6667. top1: 0.00. top5: 10.20. : 100%|██████████| 63/63 [00:02<00:00, 21.80it/s]
total : 30  current step :  20
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.10s. S_Loss: 2.5047. T_Loss: 1.9961. Mask: 0.0625. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.10s. S_Loss: 2.5105. T_Loss: 1.8058. Mask: 0.0625. :  10%|█         | 1/10 [00:00<00:01,  4.96it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.10s. S_Loss: 2.5105. T_Loss: 1.8058. Mask: 0.0625. :  20%|██        | 2/10 [00:00<00:00,  9.90it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.10s. S_Loss: 2.5298. T_Loss: 1.8370. Mask: 0.1042. :  20%|██        | 2/10 [00:00<00:00,  9.90it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5356. T_Loss: 1.8055. Mask: 0.1250. :  30%|███       | 3/10 [00:00<00:00,  9.90it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5356. T_Loss: 1.8055. Mask: 0.1250. :  40%|████      | 4/10 [00:00<00:00,  9.16it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5424. T_Loss: 1.8185. Mask: 0.1500. :  40%|████      | 4/10 [00:00<00:00,  9.16it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5424. T_Loss: 1.8185. Mask: 0.1500. :  50%|█████     | 5/10 [00:00<00:00,  8.67it/s]total : 30  current step :  21
total : 30  current step :  22
total : 30  current step :  23
total : 30  current step :  24
total : 30  current step :  25
Train Iter:  26/ 30. LR: 0.0000. Data: 0.35s. Batch: 0.47s. S_Loss: 2.5378. T_Loss: 1.8108. Mask: 0.1823. :  50%|█████     | 5/10 [00:02<00:00,  8.67it/s]Train Iter:  26/ 30. LR: 0.0000. Data: 0.35s. Batch: 0.47s. S_Loss: 2.5378. T_Loss: 1.8108. Mask: 0.1823. :  60%|██████    | 6/10 [00:02<00:02,  1.34it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.30s. Batch: 0.42s. S_Loss: 2.5374. T_Loss: 1.8145. Mask: 0.1964. :  60%|██████    | 6/10 [00:02<00:02,  1.34it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.30s. Batch: 0.42s. S_Loss: 2.5374. T_Loss: 1.8145. Mask: 0.1964. :  70%|███████   | 7/10 [00:02<00:01,  1.78it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.26s. Batch: 0.38s. S_Loss: 2.5523. T_Loss: 1.8040. Mask: 0.2305. :  70%|███████   | 7/10 [00:03<00:01,  1.78it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.26s. Batch: 0.38s. S_Loss: 2.5523. T_Loss: 1.8040. Mask: 0.2305. :  80%|████████  | 8/10 [00:03<00:00,  2.31it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.35s. S_Loss: 2.5511. T_Loss: 1.7998. Mask: 0.2674. :  80%|████████  | 8/10 [00:03<00:00,  2.31it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.35s. S_Loss: 2.5511. T_Loss: 1.7998. Mask: 0.2674. :  90%|█████████ | 9/10 [00:03<00:00,  2.92it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.21s. Batch: 0.33s. S_Loss: 2.5552. T_Loss: 1.7953. Mask: 0.3156. :  90%|█████████ | 9/10 [00:03<00:00,  2.92it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.21s. Batch: 0.33s. S_Loss: 2.5552. T_Loss: 1.7953. Mask: 0.3156. : 100%|██████████| 10/10 [00:03<00:00,  3.65it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.21s. Batch: 0.33s. S_Loss: 2.5552. T_Loss: 1.7953. Mask: 0.3156. : 100%|██████████| 10/10 [00:03<00:00,  3.03it/s]
total : 30  current step :  26
total : 30  current step :  27
total : 30  current step :  28
total : 30  current step :  29
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.98s. Loss: 13.3527. top1: 0.00. top5: 28.12. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.98s. Loss: 13.3527. top1: 0.00. top5: 28.12. :   2%|▏         | 1/63 [00:01<02:02,  1.98s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.00s. Loss: 13.5261. top1: 0.00. top5: 21.88. :   2%|▏         | 1/63 [00:01<02:02,  1.98s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.67s. Loss: 13.0564. top1: 0.00. top5: 28.12. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.51s. Loss: 12.5243. top1: 0.00. top5: 23.44. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 12.2448. top1: 0.00. top5: 22.50. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.34s. Loss: 12.0294. top1: 0.00. top5: 21.35. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 11.8832. top1: 0.00. top5: 22.77. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 11.8815. top1: 0.00. top5: 23.44. :   2%|▏         | 1/63 [00:02<02:02,  1.98s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 11.8815. top1: 0.00. top5: 23.44. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 11.9171. top1: 0.00. top5: 24.65. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 11.8382. top1: 0.00. top5: 24.38. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 11.8983. top1: 0.00. top5: 24.43. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 11.9874. top1: 0.00. top5: 24.48. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 11.9532. top1: 0.00. top5: 24.76. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 11.9796. top1: 0.00. top5: 24.55. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 12.0311. top1: 0.00. top5: 25.42. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 12.0453. top1: 0.00. top5: 25.98. :  13%|█▎        | 8/63 [00:02<00:10,  5.15it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 12.0453. top1: 0.00. top5: 25.98. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 12.0006. top1: 0.00. top5: 26.29. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 11.9993. top1: 0.00. top5: 25.69. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 11.9486. top1: 0.00. top5: 25.82. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 11.9377. top1: 0.00. top5: 25.47. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 11.9513. top1: 0.00. top5: 24.70. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 11.9374. top1: 0.00. top5: 24.57. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 11.9416. top1: 0.00. top5: 24.86. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 12.0059. top1: 0.00. top5: 25.13. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 12.0086. top1: 0.00. top5: 24.75. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 12.0256. top1: 0.00. top5: 24.40. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 11.9699. top1: 0.00. top5: 24.07. :  25%|██▌       | 16/63 [00:02<00:04, 11.64it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 11.9699. top1: 0.00. top5: 24.07. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 12.0396. top1: 0.00. top5: 24.11. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 11.9928. top1: 0.00. top5: 24.14. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 11.9786. top1: 0.00. top5: 23.85. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 12.0049. top1: 0.00. top5: 23.29. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 12.0818. top1: 0.00. top5: 22.75. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 12.1109. top1: 0.00. top5: 22.06. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 12.1418. top1: 0.00. top5: 21.42. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 12.1747. top1: 0.00. top5: 20.80. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 12.2122. top1: 0.00. top5: 20.23. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.2654. top1: 0.00. top5: 19.68. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3113. top1: 0.00. top5: 19.16. :  43%|████▎     | 27/63 [00:02<00:01, 22.26it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3113. top1: 0.00. top5: 19.16. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3340. top1: 0.00. top5: 18.67. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3672. top1: 0.00. top5: 18.20. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3814. top1: 0.00. top5: 17.76. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3912. top1: 0.00. top5: 17.34. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.3928. top1: 0.00. top5: 16.93. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.4076. top1: 0.00. top5: 16.55. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 12.4341. top1: 0.00. top5: 16.18. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4677. top1: 0.00. top5: 15.83. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4615. top1: 0.00. top5: 15.49. :  60%|██████    | 38/63 [00:02<00:00, 34.10it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4615. top1: 0.00. top5: 15.49. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4890. top1: 0.00. top5: 15.17. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.4943. top1: 0.00. top5: 14.86. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5063. top1: 0.00. top5: 14.56. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5107. top1: 0.00. top5: 14.28. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5424. top1: 0.00. top5: 14.00. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5627. top1: 0.00. top5: 13.74. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5922. top1: 0.00. top5: 13.48. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5907. top1: 0.00. top5: 13.24. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5815. top1: 0.00. top5: 13.00. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5820. top1: 0.00. top5: 12.77. :  75%|███████▍  | 47/63 [00:02<00:00, 42.91it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5820. top1: 0.00. top5: 12.77. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 12.5895. top1: 0.00. top5: 12.55. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6071. top1: 0.00. top5: 12.34. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6098. top1: 0.00. top5: 12.14. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6102. top1: 0.00. top5: 11.94. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6337. top1: 0.00. top5: 11.74. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6423. top1: 0.00. top5: 11.65. :  90%|█████████ | 57/63 [00:02<00:00, 53.37it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 12.6423. top1: 0.00. top5: 11.65. : 100%|██████████| 63/63 [00:02<00:00, 21.97it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.5702. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.86s. Loss: 2.5702. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.84s. Batch: 1.88s. Loss: 2.5574. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.86s. Batch: 1.90s. Loss: 2.5684. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.92s. Loss: 2.5565. :   4%|▍         | 1/25 [00:01<00:44,  1.86s/it]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.92s. Loss: 2.5565. :  16%|█▌        | 4/25 [00:01<00:08,  2.62it/s]Finetune Epoch:  1/ 5. Data: 1.90s. Batch: 1.94s. Loss: 2.5672. :  16%|█▌        | 4/25 [00:02<00:08,  2.62it/s]Finetune Epoch:  1/ 5. Data: 1.92s. Batch: 1.96s. Loss: 2.5692. :  16%|█▌        | 4/25 [00:02<00:08,  2.62it/s]Finetune Epoch:  1/ 5. Data: 1.94s. Batch: 1.98s. Loss: 2.5747. :  16%|█▌        | 4/25 [00:02<00:08,  2.62it/s]Finetune Epoch:  1/ 5. Data: 1.94s. Batch: 1.98s. Loss: 2.5747. :  28%|██▊       | 7/25 [00:02<00:03,  5.02it/s]Finetune Epoch:  1/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.5810. :  28%|██▊       | 7/25 [00:02<00:03,  5.02it/s]Finetune Epoch:  1/ 5. Data: 1.98s. Batch: 2.02s. Loss: 2.5741. :  28%|██▊       | 7/25 [00:02<00:03,  5.02it/s]Finetune Epoch:  1/ 5. Data: 2.00s. Batch: 2.04s. Loss: 2.5709. :  28%|██▊       | 7/25 [00:02<00:03,  5.02it/s]Finetune Epoch:  1/ 5. Data: 2.00s. Batch: 2.04s. Loss: 2.5709. :  40%|████      | 10/25 [00:02<00:01,  7.54it/s]Finetune Epoch:  1/ 5. Data: 2.02s. Batch: 2.06s. Loss: 2.5649. :  40%|████      | 10/25 [00:02<00:01,  7.54it/s]Finetune Epoch:  1/ 5. Data: 2.04s. Batch: 2.08s. Loss: 2.5701. :  40%|████      | 10/25 [00:02<00:01,  7.54it/s]Finetune Epoch:  1/ 5. Data: 2.07s. Batch: 2.11s. Loss: 2.5743. :  40%|████      | 10/25 [00:02<00:01,  7.54it/s]Finetune Epoch:  1/ 5. Data: 2.07s. Batch: 2.11s. Loss: 2.5743. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  1/ 5. Data: 2.09s. Batch: 2.13s. Loss: 2.5747. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  1/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.5789. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  1/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.5779. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  1/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.5779. :  64%|██████▍   | 16/25 [00:02<00:00, 11.89it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.20s. Loss: 2.5780. :  64%|██████▍   | 16/25 [00:02<00:00, 11.89it/s]Finetune Epoch:  1/ 5. Data: 2.19s. Batch: 2.23s. Loss: 2.5781. :  64%|██████▍   | 16/25 [00:02<00:00, 11.89it/s]Finetune Epoch:  1/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.5787. :  64%|██████▍   | 16/25 [00:02<00:00, 11.89it/s]Finetune Epoch:  1/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.5787. :  76%|███████▌  | 19/25 [00:02<00:00, 13.90it/s]Finetune Epoch:  1/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.5783. :  76%|███████▌  | 19/25 [00:02<00:00, 13.90it/s]Finetune Epoch:  1/ 5. Data: 2.26s. Batch: 2.30s. Loss: 2.5748. :  76%|███████▌  | 19/25 [00:02<00:00, 13.90it/s]Finetune Epoch:  1/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.5710. :  76%|███████▌  | 19/25 [00:02<00:00, 13.90it/s]Finetune Epoch:  1/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.5710. :  88%|████████▊ | 22/25 [00:02<00:00, 15.43it/s]Finetune Epoch:  1/ 5. Data: 2.31s. Batch: 2.35s. Loss: 2.5712. :  88%|████████▊ | 22/25 [00:02<00:00, 15.43it/s]Finetune Epoch:  1/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.5682. :  88%|████████▊ | 22/25 [00:02<00:00, 15.43it/s]Finetune Epoch:  1/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.5660. :  88%|████████▊ | 22/25 [00:02<00:00, 15.43it/s]Finetune Epoch:  1/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.5660. : 100%|██████████| 25/25 [00:02<00:00, 16.62it/s]Finetune Epoch:  1/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.5660. : 100%|██████████| 25/25 [00:03<00:00,  7.69it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.92s. Loss: 5.1126. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.92s. Loss: 5.1126. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.97s. Loss: 5.0547. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.65s. Loss: 4.9096. top1: 0.00. top5: 1.04. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.49s. Loss: 4.7525. top1: 0.00. top5: 1.56. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 4.6784. top1: 0.00. top5: 1.25. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 4.6310. top1: 0.00. top5: 1.04. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 4.5836. top1: 0.00. top5: 0.89. :   2%|▏         | 1/63 [00:01<01:59,  1.92s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 4.5859. top1: 0.00. top5: 0.78. :   2%|▏         | 1/63 [00:02<01:59,  1.92s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 4.5900. top1: 0.00. top5: 0.69. :   2%|▏         | 1/63 [00:02<01:59,  1.92s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 4.5694. top1: 0.00. top5: 0.62. :   2%|▏         | 1/63 [00:02<01:59,  1.92s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 4.5905. top1: 0.00. top5: 0.57. :   2%|▏         | 1/63 [00:02<01:59,  1.92s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 4.5905. top1: 0.00. top5: 0.57. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 4.6199. top1: 0.00. top5: 0.52. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 4.6085. top1: 0.00. top5: 0.48. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 4.6125. top1: 0.00. top5: 0.45. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 4.6251. top1: 0.00. top5: 0.42. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.6305. top1: 0.00. top5: 0.39. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.6190. top1: 0.00. top5: 0.55. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.6176. top1: 0.00. top5: 0.52. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.6003. top1: 0.00. top5: 0.49. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.6003. top1: 0.00. top5: 0.49. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.5951. top1: 0.00. top5: 0.47. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.5984. top1: 0.00. top5: 0.45. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.5951. top1: 0.00. top5: 0.43. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.5959. top1: 0.00. top5: 0.68. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.6171. top1: 0.00. top5: 0.65. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.6154. top1: 0.00. top5: 0.62. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.6207. top1: 0.00. top5: 0.60. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.6071. top1: 0.00. top5: 0.69. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.6250. top1: 0.00. top5: 0.67. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.6089. top1: 0.00. top5: 0.65. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6091. top1: 0.00. top5: 0.73. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6163. top1: 0.00. top5: 0.71. :  30%|███       | 19/63 [00:02<00:03, 13.75it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6163. top1: 0.00. top5: 0.71. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6329. top1: 0.00. top5: 0.68. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6331. top1: 0.00. top5: 0.66. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6331. top1: 0.00. top5: 0.64. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.6337. top1: 0.00. top5: 0.62. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6391. top1: 0.00. top5: 0.61. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6475. top1: 0.00. top5: 0.59. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6588. top1: 0.00. top5: 0.58. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6570. top1: 0.00. top5: 0.56. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6607. top1: 0.00. top5: 0.55. :  49%|████▉     | 31/63 [00:02<00:01, 25.49it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6607. top1: 0.00. top5: 0.55. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6606. top1: 0.00. top5: 0.53. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6575. top1: 0.00. top5: 0.52. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6532. top1: 0.00. top5: 0.51. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6530. top1: 0.00. top5: 0.50. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6549. top1: 0.00. top5: 0.49. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6605. top1: 0.00. top5: 0.48. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6534. top1: 0.00. top5: 0.47. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6576. top1: 0.00. top5: 0.46. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6556. top1: 0.00. top5: 0.45. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6564. top1: 0.00. top5: 0.44. :  63%|██████▎   | 40/63 [00:02<00:00, 34.31it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6564. top1: 0.00. top5: 0.44. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6559. top1: 0.00. top5: 0.43. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6629. top1: 0.00. top5: 0.42. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6668. top1: 0.00. top5: 0.41. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6727. top1: 0.00. top5: 0.41. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6716. top1: 0.00. top5: 0.40. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.6661. top1: 0.00. top5: 0.39. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6642. top1: 0.00. top5: 0.38. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6647. top1: 0.00. top5: 0.38. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6684. top1: 0.00. top5: 0.37. :  79%|███████▉  | 50/63 [00:02<00:00, 44.63it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6684. top1: 0.00. top5: 0.37. :  94%|█████████▎| 59/63 [00:02<00:00, 52.18it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6653. top1: 0.00. top5: 0.36. :  94%|█████████▎| 59/63 [00:02<00:00, 52.18it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6638. top1: 0.00. top5: 0.36. :  94%|█████████▎| 59/63 [00:02<00:00, 52.18it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6673. top1: 0.00. top5: 0.35. :  94%|█████████▎| 59/63 [00:02<00:00, 52.18it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6695. top1: 0.00. top5: 0.35. :  94%|█████████▎| 59/63 [00:02<00:00, 52.18it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.6695. top1: 0.00. top5: 0.35. : 100%|██████████| 63/63 [00:02<00:00, 22.23it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.89s. Batch: 1.93s. Loss: 2.5206. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.89s. Batch: 1.93s. Loss: 2.5206. :   4%|▍         | 1/25 [00:01<00:46,  1.93s/it]Finetune Epoch:  2/ 5. Data: 1.91s. Batch: 1.95s. Loss: 2.5154. :   4%|▍         | 1/25 [00:01<00:46,  1.93s/it]Finetune Epoch:  2/ 5. Data: 1.93s. Batch: 1.97s. Loss: 2.5356. :   4%|▍         | 1/25 [00:02<00:46,  1.93s/it]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.5354. :   4%|▍         | 1/25 [00:02<00:46,  1.93s/it]Finetune Epoch:  2/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.5354. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  2/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.5340. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  2/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.5329. :  16%|█▌        | 4/25 [00:02<00:08,  2.47it/s]Finetune Epoch:  2/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.5329. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  2/ 5. Data: 2.04s. Batch: 2.08s. Loss: 2.5330. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  2/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.5353. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  2/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.5353. :  32%|███▏      | 8/25 [00:02<00:03,  5.61it/s]Finetune Epoch:  2/ 5. Data: 2.09s. Batch: 2.14s. Loss: 2.5383. :  32%|███▏      | 8/25 [00:02<00:03,  5.61it/s]Finetune Epoch:  2/ 5. Data: 2.12s. Batch: 2.17s. Loss: 2.5380. :  32%|███▏      | 8/25 [00:02<00:03,  5.61it/s]Finetune Epoch:  2/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.5336. :  32%|███▏      | 8/25 [00:02<00:03,  5.61it/s]Finetune Epoch:  2/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.5336. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  2/ 5. Data: 2.17s. Batch: 2.21s. Loss: 2.5301. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  2/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.5320. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  2/ 5. Data: 2.22s. Batch: 2.26s. Loss: 2.5287. :  44%|████▍     | 11/25 [00:02<00:01,  8.57it/s]Finetune Epoch:  2/ 5. Data: 2.22s. Batch: 2.26s. Loss: 2.5287. :  56%|█████▌    | 14/25 [00:02<00:00, 11.40it/s]Finetune Epoch:  2/ 5. Data: 2.24s. Batch: 2.28s. Loss: 2.5279. :  56%|█████▌    | 14/25 [00:02<00:00, 11.40it/s]Finetune Epoch:  2/ 5. Data: 2.26s. Batch: 2.31s. Loss: 2.5267. :  56%|█████▌    | 14/25 [00:02<00:00, 11.40it/s]Finetune Epoch:  2/ 5. Data: 2.29s. Batch: 2.33s. Loss: 2.5257. :  56%|█████▌    | 14/25 [00:02<00:00, 11.40it/s]Finetune Epoch:  2/ 5. Data: 2.29s. Batch: 2.33s. Loss: 2.5257. :  68%|██████▊   | 17/25 [00:02<00:00, 13.21it/s]Finetune Epoch:  2/ 5. Data: 2.31s. Batch: 2.36s. Loss: 2.5256. :  68%|██████▊   | 17/25 [00:02<00:00, 13.21it/s]Finetune Epoch:  2/ 5. Data: 2.34s. Batch: 2.38s. Loss: 2.5235. :  68%|██████▊   | 17/25 [00:02<00:00, 13.21it/s]Finetune Epoch:  2/ 5. Data: 2.36s. Batch: 2.41s. Loss: 2.5222. :  68%|██████▊   | 17/25 [00:02<00:00, 13.21it/s]Finetune Epoch:  2/ 5. Data: 2.36s. Batch: 2.41s. Loss: 2.5222. :  80%|████████  | 20/25 [00:02<00:00, 15.51it/s]Finetune Epoch:  2/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.5233. :  80%|████████  | 20/25 [00:02<00:00, 15.51it/s]Finetune Epoch:  2/ 5. Data: 2.41s. Batch: 2.45s. Loss: 2.5247. :  80%|████████  | 20/25 [00:02<00:00, 15.51it/s]Finetune Epoch:  2/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.5236. :  80%|████████  | 20/25 [00:02<00:00, 15.51it/s]Finetune Epoch:  2/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.5236. :  92%|█████████▏| 23/25 [00:02<00:00, 17.57it/s]Finetune Epoch:  2/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.5234. :  92%|█████████▏| 23/25 [00:03<00:00, 17.57it/s]Finetune Epoch:  2/ 5. Data: 2.48s. Batch: 2.52s. Loss: 2.5199. :  92%|█████████▏| 23/25 [00:03<00:00, 17.57it/s]Finetune Epoch:  2/ 5. Data: 2.48s. Batch: 2.52s. Loss: 2.5199. : 100%|██████████| 25/25 [00:03<00:00,  7.68it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 4.4265. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 4.4265. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.97s. Loss: 4.3596. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.65s. Loss: 4.2478. top1: 0.00. top5: 2.08. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.49s. Loss: 4.1275. top1: 0.00. top5: 2.34. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 4.0715. top1: 0.00. top5: 2.50. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 4.0380. top1: 0.00. top5: 2.08. :   2%|▏         | 1/63 [00:01<01:59,  1.94s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 4.0007. top1: 0.00. top5: 1.79. :   2%|▏         | 1/63 [00:02<01:59,  1.94s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 4.0027. top1: 0.00. top5: 1.56. :   2%|▏         | 1/63 [00:02<01:59,  1.94s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 4.0051. top1: 0.00. top5: 1.39. :   2%|▏         | 1/63 [00:02<01:59,  1.94s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 3.9897. top1: 0.00. top5: 1.25. :   2%|▏         | 1/63 [00:02<01:59,  1.94s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 4.0063. top1: 0.00. top5: 1.70. :   2%|▏         | 1/63 [00:02<01:59,  1.94s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 4.0063. top1: 0.00. top5: 1.70. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 4.0293. top1: 0.00. top5: 1.56. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 4.0200. top1: 0.00. top5: 1.68. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 4.0221. top1: 0.00. top5: 1.56. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 4.0308. top1: 0.00. top5: 1.88. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.0349. top1: 0.00. top5: 1.76. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 4.0263. top1: 0.00. top5: 1.84. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 4.0251. top1: 0.00. top5: 1.74. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.0118. top1: 0.00. top5: 1.64. :  17%|█▋        | 11/63 [00:02<00:07,  7.34it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.0118. top1: 0.00. top5: 1.64. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 4.0075. top1: 0.00. top5: 1.56. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.0100. top1: 0.00. top5: 1.49. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 4.0077. top1: 0.00. top5: 1.42. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.0082. top1: 0.00. top5: 1.63. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.0246. top1: 0.00. top5: 1.56. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.0229. top1: 0.00. top5: 1.62. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.0267. top1: 0.00. top5: 1.56. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.0169. top1: 0.00. top5: 1.62. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.0299. top1: 0.00. top5: 1.56. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.0169. top1: 0.00. top5: 1.62. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0179. top1: 0.00. top5: 1.67. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0234. top1: 0.00. top5: 1.61. :  30%|███       | 19/63 [00:02<00:03, 13.76it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0234. top1: 0.00. top5: 1.61. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0345. top1: 0.00. top5: 1.56. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0323. top1: 0.00. top5: 1.52. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0300. top1: 0.00. top5: 1.47. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.0280. top1: 0.00. top5: 1.43. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0308. top1: 0.00. top5: 1.39. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0351. top1: 0.00. top5: 1.35. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0426. top1: 0.00. top5: 1.32. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0392. top1: 0.00. top5: 1.28. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0406. top1: 0.00. top5: 1.25. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0391. top1: 0.00. top5: 1.22. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0351. top1: 0.00. top5: 1.19. :  49%|████▉     | 31/63 [00:02<00:01, 25.50it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0351. top1: 0.00. top5: 1.19. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.0305. top1: 0.00. top5: 1.16. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0291. top1: 0.00. top5: 1.14. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0289. top1: 0.00. top5: 1.11. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0320. top1: 0.00. top5: 1.15. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0251. top1: 0.00. top5: 1.13. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0275. top1: 0.00. top5: 1.11. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0248. top1: 0.00. top5: 1.15. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0244. top1: 0.00. top5: 1.12. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0235. top1: 0.00. top5: 1.10. :  67%|██████▋   | 42/63 [00:02<00:00, 36.60it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0235. top1: 0.00. top5: 1.10. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0280. top1: 0.00. top5: 1.08. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0302. top1: 0.00. top5: 1.06. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0340. top1: 0.00. top5: 1.04. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.0328. top1: 0.00. top5: 1.02. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0276. top1: 0.00. top5: 1.00. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0256. top1: 0.00. top5: 0.99. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0253. top1: 0.00. top5: 0.97. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0276. top1: 0.00. top5: 0.95. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0244. top1: 0.00. top5: 0.94. :  81%|████████  | 51/63 [00:02<00:00, 44.93it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0244. top1: 0.00. top5: 0.94. :  95%|█████████▌| 60/63 [00:02<00:00, 53.31it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0227. top1: 0.00. top5: 0.92. :  95%|█████████▌| 60/63 [00:02<00:00, 53.31it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0247. top1: 0.00. top5: 0.91. :  95%|█████████▌| 60/63 [00:02<00:00, 53.31it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0263. top1: 0.00. top5: 0.90. :  95%|█████████▌| 60/63 [00:02<00:00, 53.31it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.0263. top1: 0.00. top5: 0.90. : 100%|██████████| 63/63 [00:02<00:00, 22.24it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.85s. Batch: 1.89s. Loss: 2.4978. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.85s. Batch: 1.89s. Loss: 2.4978. :   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]Finetune Epoch:  3/ 5. Data: 1.87s. Batch: 1.91s. Loss: 2.4758. :   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]Finetune Epoch:  3/ 5. Data: 1.89s. Batch: 1.94s. Loss: 2.4997. :   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]Finetune Epoch:  3/ 5. Data: 1.92s. Batch: 1.96s. Loss: 2.4805. :   4%|▍         | 1/25 [00:02<00:45,  1.89s/it]Finetune Epoch:  3/ 5. Data: 1.92s. Batch: 1.96s. Loss: 2.4805. :  16%|█▌        | 4/25 [00:02<00:08,  2.54it/s]Finetune Epoch:  3/ 5. Data: 1.94s. Batch: 1.98s. Loss: 2.4811. :  16%|█▌        | 4/25 [00:02<00:08,  2.54it/s]Finetune Epoch:  3/ 5. Data: 1.96s. Batch: 2.01s. Loss: 2.4781. :  16%|█▌        | 4/25 [00:02<00:08,  2.54it/s]Finetune Epoch:  3/ 5. Data: 1.99s. Batch: 2.03s. Loss: 2.4839. :  16%|█▌        | 4/25 [00:02<00:08,  2.54it/s]Finetune Epoch:  3/ 5. Data: 1.99s. Batch: 2.03s. Loss: 2.4839. :  28%|██▊       | 7/25 [00:02<00:03,  4.72it/s]Finetune Epoch:  3/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.4869. :  28%|██▊       | 7/25 [00:02<00:03,  4.72it/s]Finetune Epoch:  3/ 5. Data: 2.04s. Batch: 2.08s. Loss: 2.4842. :  28%|██▊       | 7/25 [00:02<00:03,  4.72it/s]Finetune Epoch:  3/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.4789. :  28%|██▊       | 7/25 [00:02<00:03,  4.72it/s]Finetune Epoch:  3/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.4789. :  40%|████      | 10/25 [00:02<00:02,  7.08it/s]Finetune Epoch:  3/ 5. Data: 2.09s. Batch: 2.13s. Loss: 2.4759. :  40%|████      | 10/25 [00:02<00:02,  7.08it/s]Finetune Epoch:  3/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.4701. :  40%|████      | 10/25 [00:02<00:02,  7.08it/s]Finetune Epoch:  3/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.4701. :  48%|████▊     | 12/25 [00:02<00:01,  8.67it/s]Finetune Epoch:  3/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.4694. :  48%|████▊     | 12/25 [00:02<00:01,  8.67it/s]Finetune Epoch:  3/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.4699. :  48%|████▊     | 12/25 [00:02<00:01,  8.67it/s]Finetune Epoch:  3/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.4716. :  48%|████▊     | 12/25 [00:02<00:01,  8.67it/s]Finetune Epoch:  3/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.4716. :  60%|██████    | 15/25 [00:02<00:00, 11.15it/s]Finetune Epoch:  3/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.4704. :  60%|██████    | 15/25 [00:02<00:00, 11.15it/s]Finetune Epoch:  3/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.4707. :  60%|██████    | 15/25 [00:02<00:00, 11.15it/s]Finetune Epoch:  3/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.4707. :  68%|██████▊   | 17/25 [00:02<00:00, 12.32it/s]Finetune Epoch:  3/ 5. Data: 2.27s. Batch: 2.31s. Loss: 2.4701. :  68%|██████▊   | 17/25 [00:02<00:00, 12.32it/s]Finetune Epoch:  3/ 5. Data: 2.29s. Batch: 2.34s. Loss: 2.4695. :  68%|██████▊   | 17/25 [00:02<00:00, 12.32it/s]Finetune Epoch:  3/ 5. Data: 2.32s. Batch: 2.36s. Loss: 2.4676. :  68%|██████▊   | 17/25 [00:02<00:00, 12.32it/s]Finetune Epoch:  3/ 5. Data: 2.32s. Batch: 2.36s. Loss: 2.4676. :  80%|████████  | 20/25 [00:02<00:00, 14.25it/s]Finetune Epoch:  3/ 5. Data: 2.34s. Batch: 2.39s. Loss: 2.4674. :  80%|████████  | 20/25 [00:02<00:00, 14.25it/s]Finetune Epoch:  3/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.4661. :  80%|████████  | 20/25 [00:02<00:00, 14.25it/s]Finetune Epoch:  3/ 5. Data: 2.39s. Batch: 2.44s. Loss: 2.4642. :  80%|████████  | 20/25 [00:03<00:00, 14.25it/s]Finetune Epoch:  3/ 5. Data: 2.39s. Batch: 2.44s. Loss: 2.4642. :  92%|█████████▏| 23/25 [00:03<00:00, 15.76it/s]Finetune Epoch:  3/ 5. Data: 2.42s. Batch: 2.47s. Loss: 2.4632. :  92%|█████████▏| 23/25 [00:03<00:00, 15.76it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.49s. Loss: 2.4619. :  92%|█████████▏| 23/25 [00:03<00:00, 15.76it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.49s. Loss: 2.4619. : 100%|██████████| 25/25 [00:03<00:00, 16.60it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.49s. Loss: 2.4619. : 100%|██████████| 25/25 [00:03<00:00,  7.55it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 3.8950. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.86s. Loss: 3.8950. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 3.8226. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 3.7376. top1: 0.00. top5: 3.12. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 3.6469. top1: 0.00. top5: 3.91. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 3.6043. top1: 0.00. top5: 3.75. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 3.5809. top1: 0.00. top5: 3.12. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 3.5521. top1: 0.00. top5: 2.68. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 3.5529. top1: 0.00. top5: 2.73. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 3.5544. top1: 0.00. top5: 2.43. :   2%|▏         | 1/63 [00:01<01:55,  1.86s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 3.5544. top1: 0.00. top5: 2.43. :  14%|█▍        | 9/63 [00:01<00:08,  6.18it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 3.5429. top1: 0.00. top5: 2.50. :  14%|█▍        | 9/63 [00:01<00:08,  6.18it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 3.5556. top1: 0.00. top5: 2.84. :  14%|█▍        | 9/63 [00:01<00:08,  6.18it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 3.5729. top1: 0.00. top5: 2.60. :  14%|█▍        | 9/63 [00:01<00:08,  6.18it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 3.5650. top1: 0.00. top5: 2.64. :  14%|█▍        | 9/63 [00:02<00:08,  6.18it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 3.5661. top1: 0.00. top5: 2.90. :  14%|█▍        | 9/63 [00:02<00:08,  6.18it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 3.5719. top1: 0.00. top5: 3.12. :  14%|█▍        | 9/63 [00:02<00:08,  6.18it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 3.5746. top1: 0.00. top5: 2.93. :  14%|█▍        | 9/63 [00:02<00:08,  6.18it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 3.5683. top1: 0.00. top5: 2.94. :  14%|█▍        | 9/63 [00:02<00:08,  6.18it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 3.5683. top1: 0.00. top5: 2.94. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 3.5673. top1: 0.00. top5: 2.78. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 3.5572. top1: 0.00. top5: 2.63. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 3.5536. top1: 0.00. top5: 2.50. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 3.5556. top1: 0.00. top5: 2.68. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 3.5537. top1: 0.00. top5: 2.98. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.5539. top1: 0.00. top5: 3.12. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.5662. top1: 0.00. top5: 2.99. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.5647. top1: 0.00. top5: 3.38. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.5676. top1: 0.00. top5: 3.37. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.5606. top1: 0.00. top5: 3.47. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.5696. top1: 0.00. top5: 3.46. :  27%|██▋       | 17/63 [00:02<00:03, 12.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.5696. top1: 0.00. top5: 3.46. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.5594. top1: 0.00. top5: 3.56. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.5609. top1: 0.00. top5: 3.54. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.5650. top1: 0.00. top5: 3.63. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.5728. top1: 0.00. top5: 3.71. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.5699. top1: 0.00. top5: 3.69. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.5670. top1: 0.00. top5: 3.77. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5642. top1: 0.00. top5: 3.66. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5658. top1: 0.00. top5: 3.73. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5681. top1: 0.00. top5: 3.80. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5733. top1: 0.00. top5: 3.78. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5697. top1: 0.00. top5: 3.77. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5697. top1: 0.00. top5: 3.77. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5702. top1: 0.00. top5: 3.67. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5683. top1: 0.00. top5: 3.73. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.5644. top1: 0.00. top5: 3.72. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5602. top1: 0.00. top5: 3.78. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5586. top1: 0.00. top5: 3.69. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5575. top1: 0.00. top5: 3.61. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5594. top1: 0.00. top5: 3.60. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5532. top1: 0.00. top5: 3.66. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5547. top1: 0.00. top5: 3.58. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5521. top1: 0.00. top5: 3.57. :  62%|██████▏   | 39/63 [00:02<00:00, 35.88it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5521. top1: 0.00. top5: 3.57. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5513. top1: 0.00. top5: 3.56. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5504. top1: 0.00. top5: 3.49. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5536. top1: 0.00. top5: 3.43. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5550. top1: 0.00. top5: 3.36. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.5576. top1: 0.00. top5: 3.36. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5566. top1: 0.00. top5: 3.47. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5521. top1: 0.00. top5: 3.46. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5503. top1: 0.00. top5: 3.56. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5496. top1: 0.00. top5: 3.61. :  78%|███████▊  | 49/63 [00:02<00:00, 46.15it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5496. top1: 0.00. top5: 3.61. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5512. top1: 0.00. top5: 3.55. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5483. top1: 0.00. top5: 3.59. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5468. top1: 0.00. top5: 3.59. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5478. top1: 0.00. top5: 3.53. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5492. top1: 0.00. top5: 3.50. :  92%|█████████▏| 58/63 [00:02<00:00, 53.56it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.5492. top1: 0.00. top5: 3.50. : 100%|██████████| 63/63 [00:02<00:00, 22.66it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.92s. Batch: 1.98s. Loss: 2.4511. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.92s. Batch: 1.98s. Loss: 2.4511. :   4%|▍         | 1/25 [00:01<00:47,  1.98s/it]Finetune Epoch:  4/ 5. Data: 1.96s. Batch: 2.01s. Loss: 2.4248. :   4%|▍         | 1/25 [00:02<00:47,  1.98s/it]Finetune Epoch:  4/ 5. Data: 1.99s. Batch: 2.04s. Loss: 2.4203. :   4%|▍         | 1/25 [00:02<00:47,  1.98s/it]Finetune Epoch:  4/ 5. Data: 1.99s. Batch: 2.04s. Loss: 2.4203. :  12%|█▏        | 3/25 [00:02<00:12,  1.80it/s]Finetune Epoch:  4/ 5. Data: 2.01s. Batch: 2.07s. Loss: 2.4171. :  12%|█▏        | 3/25 [00:02<00:12,  1.80it/s]Finetune Epoch:  4/ 5. Data: 2.04s. Batch: 2.09s. Loss: 2.4090. :  12%|█▏        | 3/25 [00:02<00:12,  1.80it/s]Finetune Epoch:  4/ 5. Data: 2.04s. Batch: 2.09s. Loss: 2.4090. :  20%|██        | 5/25 [00:02<00:05,  3.35it/s]Finetune Epoch:  4/ 5. Data: 2.07s. Batch: 2.12s. Loss: 2.4136. :  20%|██        | 5/25 [00:02<00:05,  3.35it/s]Finetune Epoch:  4/ 5. Data: 2.10s. Batch: 2.15s. Loss: 2.4253. :  20%|██        | 5/25 [00:02<00:05,  3.35it/s]Finetune Epoch:  4/ 5. Data: 2.10s. Batch: 2.15s. Loss: 2.4253. :  28%|██▊       | 7/25 [00:02<00:03,  5.12it/s]Finetune Epoch:  4/ 5. Data: 2.12s. Batch: 2.18s. Loss: 2.4348. :  28%|██▊       | 7/25 [00:02<00:03,  5.12it/s]Finetune Epoch:  4/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.4295. :  28%|██▊       | 7/25 [00:02<00:03,  5.12it/s]Finetune Epoch:  4/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.4295. :  36%|███▌      | 9/25 [00:02<00:02,  7.10it/s]Finetune Epoch:  4/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.4293. :  36%|███▌      | 9/25 [00:02<00:02,  7.10it/s]Finetune Epoch:  4/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.4238. :  36%|███▌      | 9/25 [00:02<00:02,  7.10it/s]Finetune Epoch:  4/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.4238. :  44%|████▍     | 11/25 [00:02<00:01,  8.71it/s]Finetune Epoch:  4/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.4252. :  44%|████▍     | 11/25 [00:02<00:01,  8.71it/s]Finetune Epoch:  4/ 5. Data: 2.26s. Batch: 2.32s. Loss: 2.4259. :  44%|████▍     | 11/25 [00:02<00:01,  8.71it/s]Finetune Epoch:  4/ 5. Data: 2.26s. Batch: 2.32s. Loss: 2.4259. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch:  4/ 5. Data: 2.29s. Batch: 2.34s. Loss: 2.4227. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch:  4/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.4234. :  52%|█████▏    | 13/25 [00:02<00:01, 10.61it/s]Finetune Epoch:  4/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.4234. :  60%|██████    | 15/25 [00:02<00:00, 12.42it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.4233. :  60%|██████    | 15/25 [00:02<00:00, 12.42it/s]Finetune Epoch:  4/ 5. Data: 2.37s. Batch: 2.43s. Loss: 2.4233. :  60%|██████    | 15/25 [00:02<00:00, 12.42it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.4252. :  60%|██████    | 15/25 [00:02<00:00, 12.42it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.4252. :  72%|███████▏  | 18/25 [00:02<00:00, 14.92it/s]Finetune Epoch:  4/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.4235. :  72%|███████▏  | 18/25 [00:02<00:00, 14.92it/s]Finetune Epoch:  4/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.4199. :  72%|███████▏  | 18/25 [00:02<00:00, 14.92it/s]Finetune Epoch:  4/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.4189. :  72%|███████▏  | 18/25 [00:03<00:00, 14.92it/s]Finetune Epoch:  4/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.4189. :  84%|████████▍ | 21/25 [00:03<00:00, 16.46it/s]Finetune Epoch:  4/ 5. Data: 2.51s. Batch: 2.56s. Loss: 2.4150. :  84%|████████▍ | 21/25 [00:03<00:00, 16.46it/s]Finetune Epoch:  4/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.4144. :  84%|████████▍ | 21/25 [00:03<00:00, 16.46it/s]Finetune Epoch:  4/ 5. Data: 2.56s. Batch: 2.61s. Loss: 2.4121. :  84%|████████▍ | 21/25 [00:03<00:00, 16.46it/s]Finetune Epoch:  4/ 5. Data: 2.56s. Batch: 2.61s. Loss: 2.4121. :  96%|█████████▌| 24/25 [00:03<00:00, 17.86it/s]Finetune Epoch:  4/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.4105. :  96%|█████████▌| 24/25 [00:03<00:00, 17.86it/s]Finetune Epoch:  4/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.4105. : 100%|██████████| 25/25 [00:03<00:00,  7.23it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.89s. Loss: 3.4854. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.89s. Loss: 3.4854. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.95s. Loss: 3.4130. top1: 0.00. top5: 3.12. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.64s. Loss: 3.3497. top1: 0.00. top5: 6.25. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 3.2822. top1: 0.00. top5: 8.59. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.39s. Loss: 3.2499. top1: 0.00. top5: 7.50. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 3.2330. top1: 0.00. top5: 6.77. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 3.2108. top1: 0.00. top5: 6.25. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 3.2108. top1: 0.00. top5: 7.42. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 3.2116. top1: 0.00. top5: 7.64. :   2%|▏         | 1/63 [00:01<01:57,  1.89s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 3.2116. top1: 0.00. top5: 7.64. :  14%|█▍        | 9/63 [00:01<00:08,  6.09it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 3.2029. top1: 0.00. top5: 7.81. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 3.2125. top1: 0.00. top5: 7.95. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 3.2256. top1: 0.00. top5: 7.81. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 3.2190. top1: 0.00. top5: 7.93. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 3.2192. top1: 0.00. top5: 8.71. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 3.2229. top1: 0.00. top5: 9.58. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 3.2248. top1: 0.00. top5: 9.57. :  14%|█▍        | 9/63 [00:02<00:08,  6.09it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 3.2248. top1: 0.00. top5: 9.57. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 3.2201. top1: 0.00. top5: 9.38. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 3.2190. top1: 0.00. top5: 9.20. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 3.2116. top1: 0.00. top5: 9.38. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 3.2084. top1: 0.00. top5: 9.06. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 3.2101. top1: 0.00. top5: 9.23. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 3.2087. top1: 0.00. top5: 9.66. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.2087. top1: 0.00. top5: 9.65. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.2179. top1: 0.00. top5: 9.24. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 3.2168. top1: 0.00. top5: 9.62. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.2189. top1: 0.00. top5: 9.86. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.2139. top1: 0.00. top5: 9.72. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.2201. top1: 0.00. top5: 9.93. :  25%|██▌       | 16/63 [00:02<00:03, 11.84it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.2201. top1: 0.00. top5: 9.93. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 3.2120. top1: 0.00. top5: 10.13. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2139. top1: 0.00. top5: 10.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2169. top1: 0.00. top5: 10.08. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2226. top1: 0.00. top5: 10.16. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2197. top1: 0.00. top5: 10.04. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2167. top1: 0.00. top5: 10.29. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 3.2139. top1: 0.00. top5: 10.09. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2150. top1: 0.00. top5: 10.33. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2162. top1: 0.00. top5: 10.39. :  44%|████▍     | 28/63 [00:02<00:01, 24.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2162. top1: 0.00. top5: 10.39. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2200. top1: 0.00. top5: 10.28. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2167. top1: 0.00. top5: 10.18. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2169. top1: 0.00. top5: 10.16. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2150. top1: 0.00. top5: 10.06. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2116. top1: 0.00. top5: 10.04. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 3.2078. top1: 0.00. top5: 10.25. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2065. top1: 0.00. top5: 10.09. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2050. top1: 0.00. top5: 10.07. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2063. top1: 0.00. top5: 9.99. :  59%|█████▊    | 37/63 [00:02<00:00, 33.16it/s] Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2063. top1: 0.00. top5: 9.99. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2010. top1: 0.00. top5: 9.97. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2021. top1: 0.00. top5: 9.83. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1998. top1: 0.00. top5: 9.82. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1989. top1: 0.00. top5: 9.81. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.1982. top1: 0.00. top5: 9.80. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2005. top1: 0.00. top5: 9.80. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2014. top1: 0.00. top5: 9.73. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2034. top1: 0.00. top5: 9.66. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 3.2026. top1: 0.00. top5: 9.72. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1989. top1: 0.00. top5: 9.77. :  73%|███████▎  | 46/63 [00:02<00:00, 42.23it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1989. top1: 0.00. top5: 9.77. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1973. top1: 0.00. top5: 9.87. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1966. top1: 0.00. top5: 9.86. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1977. top1: 0.00. top5: 9.75. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1952. top1: 0.00. top5: 9.79. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1941. top1: 0.00. top5: 9.84. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1946. top1: 0.00. top5: 9.83. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1957. top1: 0.00. top5: 9.75. :  89%|████████▉ | 56/63 [00:02<00:00, 53.09it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 3.1957. top1: 0.00. top5: 9.75. : 100%|██████████| 63/63 [00:02<00:00, 22.40it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.84s. Batch: 1.89s. Loss: 2.3637. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  5/ 5. Data: 1.84s. Batch: 1.89s. Loss: 2.3637. :   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]Finetune Epoch:  5/ 5. Data: 1.87s. Batch: 1.91s. Loss: 2.3930. :   4%|▍         | 1/25 [00:01<00:45,  1.89s/it]Finetune Epoch:  5/ 5. Data: 1.89s. Batch: 1.94s. Loss: 2.4012. :   4%|▍         | 1/25 [00:02<00:45,  1.89s/it]Finetune Epoch:  5/ 5. Data: 1.89s. Batch: 1.94s. Loss: 2.4012. :  12%|█▏        | 3/25 [00:02<00:11,  1.88it/s]Finetune Epoch:  5/ 5. Data: 1.92s. Batch: 1.97s. Loss: 2.3792. :  12%|█▏        | 3/25 [00:02<00:11,  1.88it/s]Finetune Epoch:  5/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.3645. :  12%|█▏        | 3/25 [00:02<00:11,  1.88it/s]Finetune Epoch:  5/ 5. Data: 1.95s. Batch: 2.00s. Loss: 2.3645. :  20%|██        | 5/25 [00:02<00:05,  3.50it/s]Finetune Epoch:  5/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.3669. :  20%|██        | 5/25 [00:02<00:05,  3.50it/s]Finetune Epoch:  5/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.3640. :  20%|██        | 5/25 [00:02<00:05,  3.50it/s]Finetune Epoch:  5/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.3640. :  28%|██▊       | 7/25 [00:02<00:03,  5.34it/s]Finetune Epoch:  5/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.3681. :  28%|██▊       | 7/25 [00:02<00:03,  5.34it/s]Finetune Epoch:  5/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.3727. :  28%|██▊       | 7/25 [00:02<00:03,  5.34it/s]Finetune Epoch:  5/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.3727. :  36%|███▌      | 9/25 [00:02<00:02,  7.31it/s]Finetune Epoch:  5/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.3693. :  36%|███▌      | 9/25 [00:02<00:02,  7.31it/s]Finetune Epoch:  5/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.3725. :  36%|███▌      | 9/25 [00:02<00:02,  7.31it/s]Finetune Epoch:  5/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.3711. :  36%|███▌      | 9/25 [00:02<00:02,  7.31it/s]Finetune Epoch:  5/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.3711. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch:  5/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.3714. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch:  5/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.3680. :  48%|████▊     | 12/25 [00:02<00:01, 10.20it/s]Finetune Epoch:  5/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.3680. :  56%|█████▌    | 14/25 [00:02<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.21s. Batch: 2.26s. Loss: 2.3682. :  56%|█████▌    | 14/25 [00:02<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.3674. :  56%|█████▌    | 14/25 [00:02<00:00, 11.93it/s]Finetune Epoch:  5/ 5. Data: 2.24s. Batch: 2.29s. Loss: 2.3674. :  64%|██████▍   | 16/25 [00:02<00:00, 13.20it/s]Finetune Epoch:  5/ 5. Data: 2.27s. Batch: 2.31s. Loss: 2.3665. :  64%|██████▍   | 16/25 [00:02<00:00, 13.20it/s]Finetune Epoch:  5/ 5. Data: 2.29s. Batch: 2.34s. Loss: 2.3636. :  64%|██████▍   | 16/25 [00:02<00:00, 13.20it/s]Finetune Epoch:  5/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.3598. :  64%|██████▍   | 16/25 [00:02<00:00, 13.20it/s]Finetune Epoch:  5/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.3598. :  76%|███████▌  | 19/25 [00:02<00:00, 15.25it/s]Finetune Epoch:  5/ 5. Data: 2.34s. Batch: 2.39s. Loss: 2.3572. :  76%|███████▌  | 19/25 [00:02<00:00, 15.25it/s]Finetune Epoch:  5/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.3552. :  76%|███████▌  | 19/25 [00:02<00:00, 15.25it/s]Finetune Epoch:  5/ 5. Data: 2.37s. Batch: 2.42s. Loss: 2.3552. :  84%|████████▍ | 21/25 [00:02<00:00, 16.16it/s]Finetune Epoch:  5/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.3565. :  84%|████████▍ | 21/25 [00:02<00:00, 16.16it/s]Finetune Epoch:  5/ 5. Data: 2.42s. Batch: 2.47s. Loss: 2.3564. :  84%|████████▍ | 21/25 [00:03<00:00, 16.16it/s]Finetune Epoch:  5/ 5. Data: 2.42s. Batch: 2.47s. Loss: 2.3564. :  92%|█████████▏| 23/25 [00:03<00:00, 16.92it/s]Finetune Epoch:  5/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.3570. :  92%|█████████▏| 23/25 [00:03<00:00, 16.92it/s]Finetune Epoch:  5/ 5. Data: 2.47s. Batch: 2.52s. Loss: 2.3565. :  92%|█████████▏| 23/25 [00:03<00:00, 16.92it/s]Finetune Epoch:  5/ 5. Data: 2.47s. Batch: 2.52s. Loss: 2.3565. : 100%|██████████| 25/25 [00:03<00:00, 17.56it/s]Finetune Epoch:  5/ 5. Data: 2.47s. Batch: 2.52s. Loss: 2.3565. : 100%|██████████| 25/25 [00:03<00:00,  7.40it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 3.1806. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 3.1806. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:59,  1.93s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.97s. Loss: 3.1100. top1: 0.00. top5: 12.50. :   2%|▏         | 1/63 [00:01<01:59,  1.93s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.65s. Loss: 3.0630. top1: 0.00. top5: 13.54. :   2%|▏         | 1/63 [00:01<01:59,  1.93s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.49s. Loss: 3.0125. top1: 0.00. top5: 16.41. :   2%|▏         | 1/63 [00:01<01:59,  1.93s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 2.9876. top1: 0.00. top5: 15.00. :   2%|▏         | 1/63 [00:01<01:59,  1.93s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.34s. Loss: 2.9753. top1: 0.00. top5: 14.58. :   2%|▏         | 1/63 [00:02<01:59,  1.93s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 2.9583. top1: 0.00. top5: 14.73. :   2%|▏         | 1/63 [00:02<01:59,  1.93s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.9576. top1: 0.00. top5: 16.02. :   2%|▏         | 1/63 [00:02<01:59,  1.93s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 2.9576. top1: 0.00. top5: 16.02. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 2.9576. top1: 0.00. top5: 15.97. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 2.9507. top1: 0.00. top5: 16.56. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 2.9582. top1: 0.00. top5: 17.05. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 2.9681. top1: 0.00. top5: 16.67. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 2.9624. top1: 0.00. top5: 16.83. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 2.9623. top1: 0.00. top5: 17.41. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 2.9646. top1: 0.00. top5: 18.54. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.9657. top1: 0.00. top5: 18.75. :  13%|█▎        | 8/63 [00:02<00:10,  5.28it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.9657. top1: 0.00. top5: 18.75. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 2.9622. top1: 0.00. top5: 18.38. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 2.9613. top1: 0.00. top5: 18.23. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.9559. top1: 0.00. top5: 17.93. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 2.9531. top1: 0.00. top5: 17.66. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.9546. top1: 0.00. top5: 17.71. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.9536. top1: 0.00. top5: 18.18. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 2.9534. top1: 0.00. top5: 18.21. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.9604. top1: 0.00. top5: 18.10. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.9596. top1: 0.00. top5: 18.62. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 2.9612. top1: 0.00. top5: 18.87. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.9577. top1: 0.00. top5: 18.75. :  25%|██▌       | 16/63 [00:02<00:03, 11.88it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.9577. top1: 0.00. top5: 18.75. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.9618. top1: 0.00. top5: 18.97. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.9554. top1: 0.00. top5: 19.40. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 2.9575. top1: 0.00. top5: 19.06. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9596. top1: 0.00. top5: 19.15. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9635. top1: 0.00. top5: 19.24. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9603. top1: 0.00. top5: 19.51. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9569. top1: 0.00. top5: 19.85. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9539. top1: 0.00. top5: 20.27. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 2.9544. top1: 0.00. top5: 20.57. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9545. top1: 0.00. top5: 20.86. :  43%|████▎     | 27/63 [00:02<00:01, 22.87it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9545. top1: 0.00. top5: 20.86. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9569. top1: 0.00. top5: 20.81. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9537. top1: 0.00. top5: 20.99. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9533. top1: 0.00. top5: 21.02. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9513. top1: 0.00. top5: 21.11. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9480. top1: 0.00. top5: 21.06. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9445. top1: 0.00. top5: 21.37. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 2.9431. top1: 0.00. top5: 21.24. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9413. top1: 0.00. top5: 21.25. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9418. top1: 0.00. top5: 21.33. :  59%|█████▊    | 37/63 [00:02<00:00, 33.10it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9418. top1: 0.00. top5: 21.33. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9372. top1: 0.00. top5: 21.74. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9377. top1: 0.00. top5: 21.48. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9355. top1: 0.00. top5: 21.81. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9343. top1: 0.00. top5: 22.12. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9337. top1: 0.00. top5: 22.00. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9352. top1: 0.00. top5: 22.00. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9357. top1: 0.00. top5: 21.93. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9370. top1: 0.00. top5: 21.99. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9363. top1: 0.00. top5: 21.93. :  73%|███████▎  | 46/63 [00:02<00:00, 41.86it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9363. top1: 0.00. top5: 21.93. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9330. top1: 0.00. top5: 22.27. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 2.9315. top1: 0.00. top5: 22.31. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9306. top1: 0.00. top5: 22.58. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9313. top1: 0.00. top5: 22.51. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9290. top1: 0.00. top5: 22.60. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9281. top1: 0.00. top5: 22.69. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9280. top1: 0.00. top5: 22.93. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9289. top1: 0.00. top5: 22.90. :  87%|████████▋ | 55/63 [00:02<00:00, 50.62it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 2.9289. top1: 0.00. top5: 22.90. : 100%|██████████| 63/63 [00:02<00:00, 22.09it/s]
total 9984 correct 5943 accuracy 59.52524038461539
[INFO] main.py:349 > [2-2] Set environment for the current task
[INFO] finetune.py:104 > Apply before_task
[INFO] finetune.py:146 > Reset the optimizer and scheduler states
[INFO] finetune.py:152 > Increasing the head of fc 10 -> 10
[INFO] main.py:357 > [2-3] Start to train under online
[INFO] main.py:372 > Train over streamed data once
batch_size : 128 stream_batch_size : 44 memory_batch_size : 42 pseudo_stream_size 42
num_stuff 237
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
image shape torch.Size([42, 3, 32, 32])
[INFO] rainbow_memory.py:120 > Streamed samples: 800
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 9984
[INFO] rainbow_memory.py:128 > Train samples: 11284
[INFO] rainbow_memory.py:129 > Test samples: 8000
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([38, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([124, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
one
stream torch.Size([44, 3, 32, 32]) mem torch.Size([42, 3, 32, 32]) pseudo torch.Size([42, 3, 32, 32])
shape torch.Size([128, 3, 32, 32])
count 18
task3/train/loss 8.232996198866102 0
task3/test/loss 6.816009805752681 0
task3/test/acc 0.198625 0
task3/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 3 | Epoch 1/1 | train_loss 8.2330 | train_acc 0.6806 | test_loss 6.8160 | test_acc 0.1986 | lr 0.0050
[INFO] finetune.py:169 > Update memory over 10 classes by uncertainty
uncertainty
[INFO] finetune.py:679 > Compute uncertainty by vr_randaug!
[WARNING] finetune.py:639 > Fill the unused slots by breaking the equilibrium.
[INFO] finetune.py:223 > Memory statistic
[INFO] finetune.py:225 > 
airplane      94
horse         81
frog          63
truck         56
bird          54
automobile    52
dog           50
deer          50
Name: klass, dtype: int64
[INFO] main.py:388 > Train over memory
batch_size : 64 stream_batch_size : 22 memory_batch_size : 21 pseudo_stream_size 21
num_stuff 0
[INFO] rainbow_memory.py:120 > Streamed samples: 0
[INFO] rainbow_memory.py:121 > In-memory samples: 500
[INFO] rainbow_memory.py:122 > Pseudo samples: 0
[INFO] rainbow_memory.py:128 > Train samples: 500
[INFO] rainbow_memory.py:129 > Test samples: 8000
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task3/train/loss 2.932825813690821 0
task3/test/loss 2.7503281982390435 0
task3/test/acc 0.153 0
task3/train/lr 0.005000000000000001 0
[INFO] rainbow_memory.py:184 > Task 3 | Epoch 1/2 | train_loss 2.9328 | train_acc 0.1880 | test_loss 2.7503 | test_acc 0.1530 | lr 0.0050
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([21, 3, 32, 32])
three
shape torch.Size([17, 3, 32, 32])
count 24
task3/train/loss 2.432339996099472 1
task3/test/loss 2.1367148013560326 1
task3/test/acc 0.204 1
task3/train/lr 0.05 1
[INFO] rainbow_memory.py:184 > Task 3 | Epoch 2/2 | train_loss 2.4323 | train_acc 0.1760 | test_loss 2.1367 | test_acc 0.2040 | lr 0.0500
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (3)
[INFO] main.py:398 > [2-4] Update the information for the current task
[INFO] finetune.py:157 > Apply after_task
[WARNING] finetune.py:230 > Already updated the memory during this iter (3)
[INFO] main.py:405 > [2-5] Report task result
Metrics/TaskAcc 0.204 3

##################################################
# Task 4 iteration
##################################################

[INFO] main.py:316 > [2-1] Prepare a datalist for the current task
total : 30  current step :  0
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.4902. T_Loss: 2.1474. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:   1/ 30. LR: 0.0000. Data: 0.14s. Batch: 0.29s. S_Loss: 2.4902. T_Loss: 2.1474. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.45it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 2.3707. T_Loss: 2.1409. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:02,  3.45it/s]Train Iter:   2/ 30. LR: 0.0000. Data: 0.08s. Batch: 0.22s. S_Loss: 2.3707. T_Loss: 2.1409. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.89it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.19s. S_Loss: 2.2946. T_Loss: 2.0816. Mask: 0.0000. :  20%|██        | 2/10 [00:00<00:01,  4.89it/s]Train Iter:   3/ 30. LR: 0.0000. Data: 0.05s. Batch: 0.19s. S_Loss: 2.2946. T_Loss: 2.0816. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.91it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.17s. S_Loss: 2.3359. T_Loss: 2.1077. Mask: 0.0000. :  30%|███       | 3/10 [00:00<00:01,  5.91it/s]Train Iter:   4/ 30. LR: 0.0000. Data: 0.04s. Batch: 0.17s. S_Loss: 2.3359. T_Loss: 2.1077. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.55it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.17s. S_Loss: 2.3665. T_Loss: 2.0839. Mask: 0.0000. :  40%|████      | 4/10 [00:00<00:00,  6.55it/s]Train Iter:   5/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.17s. S_Loss: 2.3665. T_Loss: 2.0839. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  6.59it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.16s. S_Loss: 2.3815. T_Loss: 2.1336. Mask: 0.0000. :  50%|█████     | 5/10 [00:00<00:00,  6.59it/s]Train Iter:   6/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.16s. S_Loss: 2.3815. T_Loss: 2.1336. Mask: 0.0000. :  60%|██████    | 6/10 [00:00<00:00,  7.09it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.3505. T_Loss: 2.1051. Mask: 0.0045. :  60%|██████    | 6/10 [00:01<00:00,  7.09it/s]Train Iter:   7/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.3505. T_Loss: 2.1051. Mask: 0.0045. :  70%|███████   | 7/10 [00:01<00:00,  7.50it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.3461. T_Loss: 2.1114. Mask: 0.0039. :  70%|███████   | 7/10 [00:01<00:00,  7.50it/s]Train Iter:   8/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.15s. S_Loss: 2.3461. T_Loss: 2.1114. Mask: 0.0039. :  80%|████████  | 8/10 [00:01<00:00,  7.67it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3853. T_Loss: 2.1082. Mask: 0.0035. :  80%|████████  | 8/10 [00:01<00:00,  7.67it/s]Train Iter:   9/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3853. T_Loss: 2.1082. Mask: 0.0035. :  90%|█████████ | 9/10 [00:01<00:00,  7.99it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3749. T_Loss: 2.0763. Mask: 0.0031. :  90%|█████████ | 9/10 [00:01<00:00,  7.99it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3749. T_Loss: 2.0763. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  8.26it/s]Train Iter:  10/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.3749. T_Loss: 2.0763. Mask: 0.0031. : 100%|██████████| 10/10 [00:01<00:00,  7.01it/s]
total : 30  current step :  1
total : 30  current step :  2
total : 30  current step :  3
total : 30  current step :  4
total : 30  current step :  5
total : 30  current step :  6
total : 30  current step :  7
total : 30  current step :  8
total : 30  current step :  9
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 26.8721. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.82s. Loss: 26.8721. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.91s. Loss: 25.1849. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.61s. Loss: 26.1393. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.46s. Loss: 25.9043. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.37s. Loss: 26.0897. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.31s. Loss: 25.9689. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.27s. Loss: 26.0022. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.24s. Loss: 26.2818. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 26.8538. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 26.7440. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 26.6107. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:52,  1.82s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 26.6107. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.73it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 26.8156. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.73it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 26.9320. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.73it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 26.7332. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.73it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 26.7134. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:01<00:06,  7.73it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 26.7284. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.73it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 26.8039. top1: 0.00. top5: 0.00. :  17%|█▋        | 11/63 [00:02<00:06,  7.73it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 26.8039. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 26.6654. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 26.6543. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 26.6919. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 26.6806. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 26.7295. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 26.7410. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 26.7271. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 26.6409. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 26.5810. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 26.6388. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 26.5869. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.5398. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 12.59it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.5398. top1: 0.00. top5: 0.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.5872. top1: 0.00. top5: 0.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.5549. top1: 0.00. top5: 0.00. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.3986. top1: 0.00. top5: 1.66. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 26.1650. top1: 0.00. top5: 2.84. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 25.9341. top1: 0.00. top5: 4.14. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 25.6988. top1: 0.00. top5: 5.36. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 25.5619. top1: 0.00. top5: 6.51. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 25.3388. top1: 0.00. top5: 7.60. :  46%|████▌     | 29/63 [00:02<00:01, 25.01it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 25.3388. top1: 0.00. top5: 7.60. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 25.1929. top1: 0.00. top5: 8.72. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 24.9707. top1: 0.00. top5: 9.70. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 24.8422. top1: 0.00. top5: 10.78. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 24.7228. top1: 0.00. top5: 11.59. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 24.5684. top1: 0.00. top5: 12.72. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 24.4065. top1: 0.00. top5: 13.59. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 24.2145. top1: 0.00. top5: 13.99. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 24.0563. top1: 0.00. top5: 14.58. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.9368. top1: 0.00. top5: 15.35. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.8027. top1: 0.00. top5: 16.02. :  59%|█████▊    | 37/63 [00:02<00:00, 32.84it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.8027. top1: 0.00. top5: 16.02. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.7044. top1: 0.00. top5: 16.60. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.5972. top1: 0.00. top5: 16.96. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.4706. top1: 0.00. top5: 17.44. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.3561. top1: 0.00. top5: 17.77. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.2448. top1: 0.00. top5: 18.15. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 23.1250. top1: 0.00. top5: 18.51. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 23.0591. top1: 0.00. top5: 19.39. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.9273. top1: 0.00. top5: 19.83. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.8202. top1: 0.00. top5: 20.20. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.7516. top1: 0.00. top5: 20.67. :  75%|███████▍  | 47/63 [00:02<00:00, 43.84it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.7516. top1: 0.00. top5: 20.67. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.6870. top1: 0.00. top5: 21.34. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.5865. top1: 0.00. top5: 21.56. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.4992. top1: 0.00. top5: 21.56. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.4308. top1: 0.00. top5: 21.93. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.3476. top1: 0.00. top5: 22.18. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.3248. top1: 0.00. top5: 22.30. :  90%|█████████ | 57/63 [00:02<00:00, 54.27it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 22.3248. top1: 0.00. top5: 22.30. : 100%|██████████| 63/63 [00:02<00:00, 22.93it/s]
total : 30  current step :  10
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.4645. T_Loss: 2.2694. Mask: 0.0000. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  11/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.4645. T_Loss: 2.2694. Mask: 0.0000. :  10%|█         | 1/10 [00:00<00:00,  9.30it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.11s. S_Loss: 2.5004. T_Loss: 2.1204. Mask: 0.0156. :  10%|█         | 1/10 [00:00<00:00,  9.30it/s]Train Iter:  12/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.11s. S_Loss: 2.5004. T_Loss: 2.1204. Mask: 0.0156. :  20%|██        | 2/10 [00:00<00:00,  9.08it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.11s. S_Loss: 2.5296. T_Loss: 2.0957. Mask: 0.0104. :  20%|██        | 2/10 [00:00<00:00,  9.08it/s]Train Iter:  13/ 30. LR: 0.0000. Data: 0.01s. Batch: 0.11s. S_Loss: 2.5296. T_Loss: 2.0957. Mask: 0.0104. :  30%|███       | 3/10 [00:00<00:00,  8.60it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5233. T_Loss: 2.0902. Mask: 0.0156. :  30%|███       | 3/10 [00:00<00:00,  8.60it/s]Train Iter:  14/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.5233. T_Loss: 2.0902. Mask: 0.0156. :  40%|████      | 4/10 [00:00<00:00,  8.41it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5207. T_Loss: 1.9972. Mask: 0.0312. :  40%|████      | 4/10 [00:00<00:00,  8.41it/s]Train Iter:  15/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.11s. S_Loss: 2.5207. T_Loss: 1.9972. Mask: 0.0312. :  50%|█████     | 5/10 [00:00<00:00,  8.60it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.14s. S_Loss: 2.5205. T_Loss: 1.9864. Mask: 0.0365. :  50%|█████     | 5/10 [00:00<00:00,  8.60it/s]Train Iter:  16/ 30. LR: 0.0000. Data: 0.03s. Batch: 0.14s. S_Loss: 2.5205. T_Loss: 1.9864. Mask: 0.0365. :  60%|██████    | 6/10 [00:00<00:00,  5.80it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.5368. T_Loss: 1.9640. Mask: 0.0536. :  60%|██████    | 6/10 [00:00<00:00,  5.80it/s]Train Iter:  17/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.5368. T_Loss: 1.9640. Mask: 0.0536. :  70%|███████   | 7/10 [00:00<00:00,  6.40it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.5623. T_Loss: 1.9419. Mask: 0.0664. :  70%|███████   | 7/10 [00:01<00:00,  6.40it/s]Train Iter:  18/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.14s. S_Loss: 2.5623. T_Loss: 1.9419. Mask: 0.0664. :  80%|████████  | 8/10 [00:01<00:00,  6.93it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.13s. S_Loss: 2.5640. T_Loss: 1.9283. Mask: 0.0938. :  80%|████████  | 8/10 [00:01<00:00,  6.93it/s]Train Iter:  19/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.13s. S_Loss: 2.5640. T_Loss: 1.9283. Mask: 0.0938. :  90%|█████████ | 9/10 [00:01<00:00,  7.23it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.13s. S_Loss: 2.5503. T_Loss: 1.8741. Mask: 0.0969. :  90%|█████████ | 9/10 [00:01<00:00,  7.23it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.13s. S_Loss: 2.5503. T_Loss: 1.8741. Mask: 0.0969. : 100%|██████████| 10/10 [00:01<00:00,  7.63it/s]Train Iter:  20/ 30. LR: 0.0000. Data: 0.02s. Batch: 0.13s. S_Loss: 2.5503. T_Loss: 1.8741. Mask: 0.0969. : 100%|██████████| 10/10 [00:01<00:00,  7.46it/s]
total : 30  current step :  11
total : 30  current step :  12
total : 30  current step :  13
total : 30  current step :  14
total : 30  current step :  15
total : 30  current step :  16
total : 30  current step :  17
total : 30  current step :  18
total : 30  current step :  19
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 21.2931. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.85s. Loss: 21.2931. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.94s. Loss: 19.9138. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.63s. Loss: 20.6714. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.48s. Loss: 20.4784. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.38s. Loss: 20.6294. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.32s. Loss: 20.5268. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 20.5540. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:54,  1.85s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.28s. Loss: 20.5540. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:01<00:11,  4.76it/s]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 20.7743. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:01<00:11,  4.76it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.22s. Loss: 21.2391. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:01<00:11,  4.76it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.20s. Loss: 21.1495. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:01<00:11,  4.76it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.18s. Loss: 21.0366. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 21.2017. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 21.2949. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 21.1375. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 21.1210. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.13s. Loss: 21.1413. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 21.2014. top1: 0.00. top5: 0.00. :  11%|█         | 7/63 [00:02<00:11,  4.76it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.12s. Loss: 21.2014. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 21.0913. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.11s. Loss: 21.0839. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 21.1111. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.10s. Loss: 21.1042. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 21.1419. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 21.1515. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 21.1425. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 21.0738. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 21.0248. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 21.0727. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 21.0307. top1: 0.00. top5: 0.00. :  27%|██▋       | 17/63 [00:02<00:03, 13.44it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 21.0307. top1: 0.00. top5: 0.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 20.9907. top1: 0.00. top5: 0.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 21.0319. top1: 0.00. top5: 0.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 21.0061. top1: 0.00. top5: 0.00. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 20.8825. top1: 0.00. top5: 1.46. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 20.6984. top1: 0.00. top5: 2.56. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 20.5165. top1: 0.00. top5: 3.68. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 20.3289. top1: 0.00. top5: 4.91. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 20.2231. top1: 0.00. top5: 5.99. :  44%|████▍     | 28/63 [00:02<00:01, 24.39it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 20.2231. top1: 0.00. top5: 5.99. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 20.0464. top1: 0.00. top5: 7.01. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.9323. top1: 0.00. top5: 7.89. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.7552. top1: 0.00. top5: 8.57. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.6542. top1: 0.00. top5: 9.69. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.5605. top1: 0.00. top5: 10.21. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 19.4372. top1: 0.00. top5: 11.16. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.3080. top1: 0.00. top5: 11.92. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.1545. top1: 0.00. top5: 12.00. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 19.0290. top1: 0.00. top5: 12.50. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.9345. top1: 0.00. top5: 13.04. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.8281. top1: 0.00. top5: 13.63. :  57%|█████▋    | 36/63 [00:02<00:00, 32.05it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.8281. top1: 0.00. top5: 13.63. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.7514. top1: 0.00. top5: 14.19. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.6665. top1: 0.00. top5: 14.48. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.5666. top1: 0.00. top5: 14.94. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.4752. top1: 0.00. top5: 15.26. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.3866. top1: 0.00. top5: 15.62. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.2917. top1: 0.00. top5: 15.98. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 18.2401. top1: 0.00. top5: 16.84. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 18.1357. top1: 0.00. top5: 17.16. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 18.0511. top1: 0.00. top5: 17.52. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.9975. top1: 0.00. top5: 17.93. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.9462. top1: 0.00. top5: 18.64. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.8661. top1: 0.00. top5: 18.86. :  75%|███████▍  | 47/63 [00:02<00:00, 45.01it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.8661. top1: 0.00. top5: 18.86. :  94%|█████████▎| 59/63 [00:02<00:00, 58.39it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.7972. top1: 0.00. top5: 18.75. :  94%|█████████▎| 59/63 [00:02<00:00, 58.39it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.7432. top1: 0.00. top5: 19.06. :  94%|█████████▎| 59/63 [00:02<00:00, 58.39it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.6774. top1: 0.00. top5: 19.25. :  94%|█████████▎| 59/63 [00:02<00:00, 58.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.6595. top1: 0.00. top5: 19.40. :  94%|█████████▎| 59/63 [00:02<00:00, 58.39it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 17.6595. top1: 0.00. top5: 19.40. : 100%|██████████| 63/63 [00:02<00:00, 23.01it/s]
total : 30  current step :  20
  0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.8214. T_Loss: 1.9875. Mask: 0.3750. :   0%|          | 0/10 [00:00<?, ?it/s]Train Iter:  21/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.8214. T_Loss: 1.9875. Mask: 0.3750. :  10%|█         | 1/10 [00:00<00:01,  7.67it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.8110. T_Loss: 1.8043. Mask: 0.4375. :  10%|█         | 1/10 [00:00<00:01,  7.67it/s]Train Iter:  22/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.8110. T_Loss: 1.8043. Mask: 0.4375. :  20%|██        | 2/10 [00:00<00:01,  7.95it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.7805. T_Loss: 1.8595. Mask: 0.4896. :  20%|██        | 2/10 [00:00<00:01,  7.95it/s]Train Iter:  23/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.7805. T_Loss: 1.8595. Mask: 0.4896. :  30%|███       | 3/10 [00:00<00:00,  8.21it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.7184. T_Loss: 1.7813. Mask: 0.5000. :  30%|███       | 3/10 [00:00<00:00,  8.21it/s]Train Iter:  24/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.13s. S_Loss: 2.7184. T_Loss: 1.7813. Mask: 0.5000. :  40%|████      | 4/10 [00:00<00:00,  7.84it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.6788. T_Loss: 1.7105. Mask: 0.5125. :  40%|████      | 4/10 [00:00<00:00,  7.84it/s]Train Iter:  25/ 30. LR: 0.0000. Data: 0.00s. Batch: 0.12s. S_Loss: 2.6788. T_Loss: 1.7105. Mask: 0.5125. :  50%|█████     | 5/10 [00:00<00:00,  7.92it/s]total : 30  current step :  21
total : 30  current step :  22
total : 30  current step :  23
total : 30  current step :  24
total : 30  current step :  25
Train Iter:  26/ 30. LR: 0.0000. Data: 0.31s. Batch: 0.44s. S_Loss: 2.7246. T_Loss: 1.7428. Mask: 0.5469. :  50%|█████     | 5/10 [00:02<00:00,  7.92it/s]Train Iter:  26/ 30. LR: 0.0000. Data: 0.31s. Batch: 0.44s. S_Loss: 2.7246. T_Loss: 1.7428. Mask: 0.5469. :  60%|██████    | 6/10 [00:02<00:03,  1.31it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.27s. Batch: 0.39s. S_Loss: 2.7191. T_Loss: 1.7811. Mask: 0.5848. :  60%|██████    | 6/10 [00:02<00:03,  1.31it/s]Train Iter:  27/ 30. LR: 0.0000. Data: 0.27s. Batch: 0.39s. S_Loss: 2.7191. T_Loss: 1.7811. Mask: 0.5848. :  70%|███████   | 7/10 [00:02<00:01,  1.80it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.36s. S_Loss: 2.7148. T_Loss: 1.7540. Mask: 0.6211. :  70%|███████   | 7/10 [00:02<00:01,  1.80it/s]Train Iter:  28/ 30. LR: 0.0000. Data: 0.24s. Batch: 0.36s. S_Loss: 2.7148. T_Loss: 1.7540. Mask: 0.6211. :  80%|████████  | 8/10 [00:02<00:00,  2.38it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.21s. Batch: 0.33s. S_Loss: 2.7309. T_Loss: 1.7277. Mask: 0.6424. :  80%|████████  | 8/10 [00:03<00:00,  2.38it/s]Train Iter:  29/ 30. LR: 0.0000. Data: 0.21s. Batch: 0.33s. S_Loss: 2.7309. T_Loss: 1.7277. Mask: 0.6424. :  90%|█████████ | 9/10 [00:03<00:00,  3.04it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.19s. Batch: 0.31s. S_Loss: 2.7501. T_Loss: 1.7078. Mask: 0.6781. :  90%|█████████ | 9/10 [00:03<00:00,  3.04it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.19s. Batch: 0.31s. S_Loss: 2.7501. T_Loss: 1.7078. Mask: 0.6781. : 100%|██████████| 10/10 [00:03<00:00,  3.67it/s]Train Iter:  30/ 30. LR: 0.0000. Data: 0.19s. Batch: 0.31s. S_Loss: 2.7501. T_Loss: 1.7078. Mask: 0.6781. : 100%|██████████| 10/10 [00:03<00:00,  3.16it/s]
total : 30  current step :  26
total : 30  current step :  27
total : 30  current step :  28
total : 30  current step :  29
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 17.3301. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.78s. Loss: 17.3301. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.90s. Loss: 16.1726. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.60s. Loss: 16.7971. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.45s. Loss: 16.6386. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 16.7661. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 16.6780. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 16.7031. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 16.8828. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.21s. Loss: 17.2701. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.19s. Loss: 17.1948. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 17.0969. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 17.2330. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:50,  1.78s/it]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.16s. Loss: 17.2330. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.15s. Loss: 17.3094. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.14s. Loss: 17.1812. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 17.1672. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 17.1907. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 17.2389. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 17.1488. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 17.1433. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 17.1642. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 17.1603. top1: 0.00. top5: 0.00. :  19%|█▉        | 12/63 [00:01<00:05,  8.70it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 17.1603. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:01<00:02, 16.40it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 17.1904. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:01<00:02, 16.40it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 17.1985. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 17.1932. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 17.1373. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 17.0961. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 17.1364. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 17.1018. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 17.0674. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 17.1039. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 17.0829. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 16.9786. top1: 0.00. top5: 1.46. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.8252. top1: 0.00. top5: 2.65. :  33%|███▎      | 21/63 [00:02<00:02, 16.40it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.8252. top1: 0.00. top5: 2.65. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.6740. top1: 0.00. top5: 3.86. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.5176. top1: 0.00. top5: 5.09. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.4290. top1: 0.00. top5: 6.08. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.2823. top1: 0.00. top5: 7.09. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 16.1877. top1: 0.00. top5: 7.89. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 16.0407. top1: 0.00. top5: 8.65. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.9559. top1: 0.00. top5: 9.69. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.8767. top1: 0.00. top5: 10.21. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.7735. top1: 0.00. top5: 11.01. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.6653. top1: 0.00. top5: 11.48. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.5376. top1: 0.00. top5: 11.72. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4335. top1: 0.00. top5: 12.15. :  52%|█████▏    | 33/63 [00:02<00:01, 28.59it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.4335. top1: 0.00. top5: 12.15. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.3546. top1: 0.00. top5: 12.77. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.2662. top1: 0.00. top5: 13.43. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.2024. top1: 0.00. top5: 13.93. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.1316. top1: 0.00. top5: 14.09. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 15.0489. top1: 0.00. top5: 14.56. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.9726. top1: 0.00. top5: 14.89. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.8987. top1: 0.00. top5: 15.26. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.8200. top1: 0.00. top5: 15.57. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.7767. top1: 0.00. top5: 16.26. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.6909. top1: 0.00. top5: 16.59. :  71%|███████▏  | 45/63 [00:02<00:00, 41.41it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.6909. top1: 0.00. top5: 16.59. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.6212. top1: 0.00. top5: 16.96. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.5766. top1: 0.00. top5: 17.38. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.5333. top1: 0.00. top5: 18.05. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.4668. top1: 0.00. top5: 18.33. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.4096. top1: 0.00. top5: 18.33. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.3645. top1: 0.00. top5: 18.60. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.3097. top1: 0.00. top5: 18.80. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.2946. top1: 0.00. top5: 18.95. :  87%|████████▋ | 55/63 [00:02<00:00, 50.11it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 14.2946. top1: 0.00. top5: 18.95. : 100%|██████████| 63/63 [00:02<00:00, 24.27it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.77s. Batch: 1.81s. Loss: 2.6050. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  1/ 5. Data: 1.77s. Batch: 1.81s. Loss: 2.6050. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch:  1/ 5. Data: 1.81s. Batch: 1.85s. Loss: 2.7923. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch:  1/ 5. Data: 1.84s. Batch: 1.88s. Loss: 2.8098. :   4%|▍         | 1/25 [00:01<00:43,  1.81s/it]Finetune Epoch:  1/ 5. Data: 1.84s. Batch: 1.88s. Loss: 2.8098. :  12%|█▏        | 3/25 [00:01<00:11,  1.94it/s]Finetune Epoch:  1/ 5. Data: 1.86s. Batch: 1.90s. Loss: 2.8072. :  12%|█▏        | 3/25 [00:01<00:11,  1.94it/s]Finetune Epoch:  1/ 5. Data: 1.88s. Batch: 1.92s. Loss: 2.8231. :  12%|█▏        | 3/25 [00:02<00:11,  1.94it/s]Finetune Epoch:  1/ 5. Data: 1.90s. Batch: 1.94s. Loss: 2.8013. :  12%|█▏        | 3/25 [00:02<00:11,  1.94it/s]Finetune Epoch:  1/ 5. Data: 1.90s. Batch: 1.94s. Loss: 2.8013. :  24%|██▍       | 6/25 [00:02<00:04,  4.53it/s]Finetune Epoch:  1/ 5. Data: 1.92s. Batch: 1.96s. Loss: 2.8133. :  24%|██▍       | 6/25 [00:02<00:04,  4.53it/s]Finetune Epoch:  1/ 5. Data: 1.94s. Batch: 1.98s. Loss: 2.7928. :  24%|██▍       | 6/25 [00:02<00:04,  4.53it/s]Finetune Epoch:  1/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.7985. :  24%|██▍       | 6/25 [00:02<00:04,  4.53it/s]Finetune Epoch:  1/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.7985. :  36%|███▌      | 9/25 [00:02<00:02,  7.33it/s]Finetune Epoch:  1/ 5. Data: 1.98s. Batch: 2.02s. Loss: 2.8025. :  36%|███▌      | 9/25 [00:02<00:02,  7.33it/s]Finetune Epoch:  1/ 5. Data: 2.00s. Batch: 2.04s. Loss: 2.7873. :  36%|███▌      | 9/25 [00:02<00:02,  7.33it/s]Finetune Epoch:  1/ 5. Data: 2.02s. Batch: 2.06s. Loss: 2.7771. :  36%|███▌      | 9/25 [00:02<00:02,  7.33it/s]Finetune Epoch:  1/ 5. Data: 2.02s. Batch: 2.06s. Loss: 2.7771. :  48%|████▊     | 12/25 [00:02<00:01,  9.88it/s]Finetune Epoch:  1/ 5. Data: 2.05s. Batch: 2.09s. Loss: 2.7730. :  48%|████▊     | 12/25 [00:02<00:01,  9.88it/s]Finetune Epoch:  1/ 5. Data: 2.07s. Batch: 2.11s. Loss: 2.7584. :  48%|████▊     | 12/25 [00:02<00:01,  9.88it/s]Finetune Epoch:  1/ 5. Data: 2.09s. Batch: 2.13s. Loss: 2.7663. :  48%|████▊     | 12/25 [00:02<00:01,  9.88it/s]Finetune Epoch:  1/ 5. Data: 2.09s. Batch: 2.13s. Loss: 2.7663. :  60%|██████    | 15/25 [00:02<00:00, 11.95it/s]Finetune Epoch:  1/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.7590. :  60%|██████    | 15/25 [00:02<00:00, 11.95it/s]Finetune Epoch:  1/ 5. Data: 2.14s. Batch: 2.18s. Loss: 2.7612. :  60%|██████    | 15/25 [00:02<00:00, 11.95it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.7576. :  60%|██████    | 15/25 [00:02<00:00, 11.95it/s]Finetune Epoch:  1/ 5. Data: 2.16s. Batch: 2.21s. Loss: 2.7576. :  72%|███████▏  | 18/25 [00:02<00:00, 13.74it/s]Finetune Epoch:  1/ 5. Data: 2.19s. Batch: 2.23s. Loss: 2.7595. :  72%|███████▏  | 18/25 [00:02<00:00, 13.74it/s]Finetune Epoch:  1/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.7549. :  72%|███████▏  | 18/25 [00:02<00:00, 13.74it/s]Finetune Epoch:  1/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.7504. :  72%|███████▏  | 18/25 [00:02<00:00, 13.74it/s]Finetune Epoch:  1/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.7504. :  84%|████████▍ | 21/25 [00:02<00:00, 15.37it/s]Finetune Epoch:  1/ 5. Data: 2.26s. Batch: 2.30s. Loss: 2.7484. :  84%|████████▍ | 21/25 [00:02<00:00, 15.37it/s]Finetune Epoch:  1/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.7438. :  84%|████████▍ | 21/25 [00:02<00:00, 15.37it/s]Finetune Epoch:  1/ 5. Data: 2.31s. Batch: 2.35s. Loss: 2.7461. :  84%|████████▍ | 21/25 [00:02<00:00, 15.37it/s]Finetune Epoch:  1/ 5. Data: 2.31s. Batch: 2.35s. Loss: 2.7461. :  96%|█████████▌| 24/25 [00:02<00:00, 16.84it/s]Finetune Epoch:  1/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.7432. :  96%|█████████▌| 24/25 [00:02<00:00, 16.84it/s]Finetune Epoch:  1/ 5. Data: 2.33s. Batch: 2.38s. Loss: 2.7432. : 100%|██████████| 25/25 [00:03<00:00,  7.83it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 6.7035. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.72s. Loss: 6.7035. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.87s. Loss: 6.2750. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.58s. Loss: 6.5185. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.44s. Loss: 6.4641. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.36s. Loss: 6.5051. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.30s. Loss: 6.4751. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.26s. Loss: 6.4954. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.23s. Loss: 6.5606. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 6.7024. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<01:46,  1.72s/it]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.20s. Loss: 6.7024. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.18s. Loss: 6.6702. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.17s. Loss: 6.6250. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.15s. Loss: 6.6717. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.14s. Loss: 6.6967. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.13s. Loss: 6.6551. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.13s. Loss: 6.6469. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.12s. Loss: 6.6629. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.11s. Loss: 6.6772. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 6.6472. top1: 0.00. top5: 0.00. :  14%|█▍        | 9/63 [00:01<00:08,  6.64it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.11s. Loss: 6.6472. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.10s. Loss: 6.6478. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.10s. Loss: 6.6526. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.6526. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.6597. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.09s. Loss: 6.6615. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6640. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6483. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.08s. Loss: 6.6330. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:01<00:03, 14.75it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6467. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.75it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6336. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.75it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6201. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.75it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6383. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.75it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6334. top1: 0.00. top5: 0.00. :  29%|██▊       | 18/63 [00:02<00:03, 14.75it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 6.6334. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.5875. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.5273. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.4687. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.4075. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.3696. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.3138. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 6.2772. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.2225. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.1879. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.1541. top1: 0.00. top5: 0.00. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.1127. top1: 0.00. top5: 0.07. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.0708. top1: 0.00. top5: 0.07. :  49%|████▉     | 31/63 [00:02<00:01, 28.62it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.0708. top1: 0.00. top5: 0.07. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.05s. Loss: 6.0247. top1: 0.00. top5: 0.14. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.9861. top1: 0.00. top5: 0.14. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.9547. top1: 0.00. top5: 0.20. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.9217. top1: 0.00. top5: 0.20. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.8951. top1: 0.00. top5: 0.20. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.8673. top1: 0.00. top5: 0.19. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.8357. top1: 0.00. top5: 0.19. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.8063. top1: 0.00. top5: 0.18. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.7775. top1: 0.00. top5: 0.24. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.7487. top1: 0.00. top5: 0.29. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.7298. top1: 0.00. top5: 0.29. :  68%|██████▊   | 43/63 [00:02<00:00, 42.05it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.7298. top1: 0.00. top5: 0.29. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6992. top1: 0.00. top5: 0.28. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6740. top1: 0.00. top5: 0.33. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6561. top1: 0.00. top5: 0.33. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6369. top1: 0.00. top5: 0.32. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.6113. top1: 0.00. top5: 0.32. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5897. top1: 0.00. top5: 0.36. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5718. top1: 0.00. top5: 0.36. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5505. top1: 0.00. top5: 0.35. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5439. top1: 0.00. top5: 0.35. :  86%|████████▌ | 54/63 [00:02<00:00, 52.52it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 5.5439. top1: 0.00. top5: 0.35. : 100%|██████████| 63/63 [00:02<00:00, 24.60it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.72s. Batch: 1.78s. Loss: 2.7256. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  2/ 5. Data: 1.72s. Batch: 1.78s. Loss: 2.7256. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch:  2/ 5. Data: 1.75s. Batch: 1.81s. Loss: 2.7347. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch:  2/ 5. Data: 1.78s. Batch: 1.83s. Loss: 2.7368. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch:  2/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.7633. :   4%|▍         | 1/25 [00:01<00:42,  1.78s/it]Finetune Epoch:  2/ 5. Data: 1.80s. Batch: 1.85s. Loss: 2.7633. :  16%|█▌        | 4/25 [00:01<00:07,  2.65it/s]Finetune Epoch:  2/ 5. Data: 1.83s. Batch: 1.88s. Loss: 2.7466. :  16%|█▌        | 4/25 [00:01<00:07,  2.65it/s]Finetune Epoch:  2/ 5. Data: 1.86s. Batch: 1.90s. Loss: 2.7457. :  16%|█▌        | 4/25 [00:02<00:07,  2.65it/s]Finetune Epoch:  2/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.7531. :  16%|█▌        | 4/25 [00:02<00:07,  2.65it/s]Finetune Epoch:  2/ 5. Data: 1.88s. Batch: 1.93s. Loss: 2.7531. :  28%|██▊       | 7/25 [00:02<00:03,  4.94it/s]Finetune Epoch:  2/ 5. Data: 1.91s. Batch: 1.96s. Loss: 2.7420. :  28%|██▊       | 7/25 [00:02<00:03,  4.94it/s]Finetune Epoch:  2/ 5. Data: 1.93s. Batch: 1.98s. Loss: 2.7569. :  28%|██▊       | 7/25 [00:02<00:03,  4.94it/s]Finetune Epoch:  2/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.7416. :  28%|██▊       | 7/25 [00:02<00:03,  4.94it/s]Finetune Epoch:  2/ 5. Data: 1.96s. Batch: 2.00s. Loss: 2.7416. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch:  2/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.7350. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch:  2/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.7202. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.7167. :  40%|████      | 10/25 [00:02<00:02,  7.43it/s]Finetune Epoch:  2/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.7167. :  52%|█████▏    | 13/25 [00:02<00:01,  9.97it/s]Finetune Epoch:  2/ 5. Data: 2.05s. Batch: 2.10s. Loss: 2.7098. :  52%|█████▏    | 13/25 [00:02<00:01,  9.97it/s]Finetune Epoch:  2/ 5. Data: 2.08s. Batch: 2.12s. Loss: 2.7057. :  52%|█████▏    | 13/25 [00:02<00:01,  9.97it/s]Finetune Epoch:  2/ 5. Data: 2.08s. Batch: 2.12s. Loss: 2.7057. :  60%|██████    | 15/25 [00:02<00:00, 11.48it/s]Finetune Epoch:  2/ 5. Data: 2.10s. Batch: 2.15s. Loss: 2.7117. :  60%|██████    | 15/25 [00:02<00:00, 11.48it/s]Finetune Epoch:  2/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.7128. :  60%|██████    | 15/25 [00:02<00:00, 11.48it/s]Finetune Epoch:  2/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.7128. :  68%|██████▊   | 17/25 [00:02<00:00, 12.30it/s]Finetune Epoch:  2/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.7107. :  68%|██████▊   | 17/25 [00:02<00:00, 12.30it/s]Finetune Epoch:  2/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.7051. :  68%|██████▊   | 17/25 [00:02<00:00, 12.30it/s]Finetune Epoch:  2/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.7051. :  76%|███████▌  | 19/25 [00:02<00:00, 13.55it/s]Finetune Epoch:  2/ 5. Data: 2.21s. Batch: 2.25s. Loss: 2.7015. :  76%|███████▌  | 19/25 [00:02<00:00, 13.55it/s]Finetune Epoch:  2/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.7020. :  76%|███████▌  | 19/25 [00:02<00:00, 13.55it/s]Finetune Epoch:  2/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.7020. :  84%|████████▍ | 21/25 [00:02<00:00, 14.62it/s]Finetune Epoch:  2/ 5. Data: 2.26s. Batch: 2.31s. Loss: 2.6989. :  84%|████████▍ | 21/25 [00:02<00:00, 14.62it/s]Finetune Epoch:  2/ 5. Data: 2.28s. Batch: 2.33s. Loss: 2.6923. :  84%|████████▍ | 21/25 [00:02<00:00, 14.62it/s]Finetune Epoch:  2/ 5. Data: 2.31s. Batch: 2.36s. Loss: 2.6799. :  84%|████████▍ | 21/25 [00:02<00:00, 14.62it/s]Finetune Epoch:  2/ 5. Data: 2.31s. Batch: 2.36s. Loss: 2.6799. :  96%|█████████▌| 24/25 [00:02<00:00, 16.49it/s]Finetune Epoch:  2/ 5. Data: 2.34s. Batch: 2.39s. Loss: 2.6786. :  96%|█████████▌| 24/25 [00:03<00:00, 16.49it/s]Finetune Epoch:  2/ 5. Data: 2.34s. Batch: 2.39s. Loss: 2.6786. : 100%|██████████| 25/25 [00:03<00:00,  7.75it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 5.7486. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 1.93s. Loss: 5.7486. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:00,  1.94s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 0.99s. Loss: 5.4064. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:00,  1.94s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.66s. Loss: 5.6130. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:00,  1.94s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.50s. Loss: 5.5703. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:00,  1.94s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.40s. Loss: 5.6009. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:00,  1.94s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.33s. Loss: 5.5785. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:00,  1.94s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.29s. Loss: 5.5965. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:00,  1.94s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 5.6483. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:00,  1.94s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.25s. Loss: 5.6483. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 5.7631. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 5.7375. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.19s. Loss: 5.7003. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.17s. Loss: 5.7371. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.16s. Loss: 5.7567. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.15s. Loss: 5.7226. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.7153. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.29it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.7153. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.7292. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.7399. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.7161. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.7158. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.7206. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.7204. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.7251. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.7267. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.7295. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.7177. top1: 0.00. top5: 0.00. :  24%|██▍       | 15/63 [00:02<00:04, 11.02it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.7177. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.7054. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.7157. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.7048. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.6942. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 5.7095. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.7059. top1: 0.00. top5: 0.00. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.6665. top1: 0.00. top5: 0.10. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.6166. top1: 0.00. top5: 0.28. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.5678. top1: 0.00. top5: 0.28. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.5170. top1: 0.00. top5: 0.36. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.4846. top1: 0.00. top5: 0.35. :  40%|███▉      | 25/63 [00:02<00:01, 20.95it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 5.4846. top1: 0.00. top5: 0.35. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.4383. top1: 0.00. top5: 0.34. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.4077. top1: 0.00. top5: 0.41. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.3628. top1: 0.00. top5: 0.48. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.3335. top1: 0.00. top5: 0.47. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.3048. top1: 0.00. top5: 0.53. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.2701. top1: 0.00. top5: 0.67. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.2354. top1: 0.00. top5: 0.87. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 5.1978. top1: 0.00. top5: 0.92. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.1661. top1: 0.00. top5: 0.97. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.1398. top1: 0.00. top5: 1.02. :  57%|█████▋    | 36/63 [00:02<00:00, 33.15it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.1398. top1: 0.00. top5: 1.02. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.1126. top1: 0.00. top5: 1.00. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.0904. top1: 0.00. top5: 0.98. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.0673. top1: 0.00. top5: 0.96. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.0409. top1: 0.00. top5: 1.06. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 5.0166. top1: 0.00. top5: 1.10. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9928. top1: 0.00. top5: 1.14. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9691. top1: 0.00. top5: 1.18. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9528. top1: 0.00. top5: 1.22. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9278. top1: 0.00. top5: 1.25. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9072. top1: 0.00. top5: 1.28. :  73%|███████▎  | 46/63 [00:02<00:00, 43.59it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.9072. top1: 0.00. top5: 1.28. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.8922. top1: 0.00. top5: 1.26. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.8758. top1: 0.00. top5: 1.29. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.8546. top1: 0.00. top5: 1.43. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.8368. top1: 0.00. top5: 1.46. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.8219. top1: 0.00. top5: 1.49. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.8042. top1: 0.00. top5: 1.66. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.7986. top1: 0.00. top5: 1.65. :  89%|████████▉ | 56/63 [00:02<00:00, 53.50it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.7986. top1: 0.00. top5: 1.65. : 100%|██████████| 63/63 [00:02<00:00, 22.19it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.95s. Batch: 2.01s. Loss: 2.6406. :   0%|          | 0/25 [00:02<?, ?it/s]Finetune Epoch:  3/ 5. Data: 1.95s. Batch: 2.01s. Loss: 2.6406. :   4%|▍         | 1/25 [00:02<00:48,  2.01s/it]Finetune Epoch:  3/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.5506. :   4%|▍         | 1/25 [00:02<00:48,  2.01s/it]Finetune Epoch:  3/ 5. Data: 2.00s. Batch: 2.05s. Loss: 2.5991. :   4%|▍         | 1/25 [00:02<00:48,  2.01s/it]Finetune Epoch:  3/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.5916. :   4%|▍         | 1/25 [00:02<00:48,  2.01s/it]Finetune Epoch:  3/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.5916. :  16%|█▌        | 4/25 [00:02<00:08,  2.37it/s]Finetune Epoch:  3/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.5799. :  16%|█▌        | 4/25 [00:02<00:08,  2.37it/s]Finetune Epoch:  3/ 5. Data: 2.09s. Batch: 2.14s. Loss: 2.5564. :  16%|█▌        | 4/25 [00:02<00:08,  2.37it/s]Finetune Epoch:  3/ 5. Data: 2.09s. Batch: 2.14s. Loss: 2.5564. :  24%|██▍       | 6/25 [00:02<00:04,  3.80it/s]Finetune Epoch:  3/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.5972. :  24%|██▍       | 6/25 [00:02<00:04,  3.80it/s]Finetune Epoch:  3/ 5. Data: 2.14s. Batch: 2.19s. Loss: 2.6166. :  24%|██▍       | 6/25 [00:02<00:04,  3.80it/s]Finetune Epoch:  3/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.6214. :  24%|██▍       | 6/25 [00:02<00:04,  3.80it/s]Finetune Epoch:  3/ 5. Data: 2.17s. Batch: 2.22s. Loss: 2.6214. :  36%|███▌      | 9/25 [00:02<00:02,  6.24it/s]Finetune Epoch:  3/ 5. Data: 2.19s. Batch: 2.24s. Loss: 2.6068. :  36%|███▌      | 9/25 [00:02<00:02,  6.24it/s]Finetune Epoch:  3/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.6166. :  36%|███▌      | 9/25 [00:02<00:02,  6.24it/s]Finetune Epoch:  3/ 5. Data: 2.22s. Batch: 2.27s. Loss: 2.6166. :  44%|████▍     | 11/25 [00:02<00:01,  7.96it/s]Finetune Epoch:  3/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.6174. :  44%|████▍     | 11/25 [00:02<00:01,  7.96it/s]Finetune Epoch:  3/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.6273. :  44%|████▍     | 11/25 [00:02<00:01,  7.96it/s]Finetune Epoch:  3/ 5. Data: 2.27s. Batch: 2.32s. Loss: 2.6273. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  3/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.6366. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  3/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.6304. :  52%|█████▏    | 13/25 [00:02<00:01,  9.77it/s]Finetune Epoch:  3/ 5. Data: 2.32s. Batch: 2.37s. Loss: 2.6304. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  3/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.6231. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  3/ 5. Data: 2.37s. Batch: 2.43s. Loss: 2.6324. :  60%|██████    | 15/25 [00:02<00:00, 11.50it/s]Finetune Epoch:  3/ 5. Data: 2.37s. Batch: 2.43s. Loss: 2.6324. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch:  3/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.6303. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch:  3/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.6261. :  68%|██████▊   | 17/25 [00:02<00:00, 12.89it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.6226. :  68%|██████▊   | 17/25 [00:03<00:00, 12.89it/s]Finetune Epoch:  3/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.6226. :  80%|████████  | 20/25 [00:03<00:00, 14.68it/s]Finetune Epoch:  3/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.6198. :  80%|████████  | 20/25 [00:03<00:00, 14.68it/s]Finetune Epoch:  3/ 5. Data: 2.51s. Batch: 2.56s. Loss: 2.6156. :  80%|████████  | 20/25 [00:03<00:00, 14.68it/s]Finetune Epoch:  3/ 5. Data: 2.51s. Batch: 2.56s. Loss: 2.6156. :  88%|████████▊ | 22/25 [00:03<00:00, 15.81it/s]Finetune Epoch:  3/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.6188. :  88%|████████▊ | 22/25 [00:03<00:00, 15.81it/s]Finetune Epoch:  3/ 5. Data: 2.56s. Batch: 2.61s. Loss: 2.6170. :  88%|████████▊ | 22/25 [00:03<00:00, 15.81it/s]Finetune Epoch:  3/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.6161. :  88%|████████▊ | 22/25 [00:03<00:00, 15.81it/s]Finetune Epoch:  3/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.6161. : 100%|██████████| 25/25 [00:03<00:00, 17.01it/s]Finetune Epoch:  3/ 5. Data: 2.58s. Batch: 2.63s. Loss: 2.6161. : 100%|██████████| 25/25 [00:03<00:00,  7.21it/s]
  0%|          | 0/63 [00:00<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.00s. Loss: 5.0201. top1: 0.00. top5: 0.00. :   0%|          | 0/63 [00:01<?, ?it/s]Test Iter:   1/ 63. Data: 0.00s. Batch: 2.00s. Loss: 5.0201. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:01<02:03,  2.00s/it]Test Iter:   2/ 63. Data: 0.00s. Batch: 1.01s. Loss: 4.7454. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   3/ 63. Data: 0.00s. Batch: 0.68s. Loss: 4.9212. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   4/ 63. Data: 0.00s. Batch: 0.51s. Loss: 4.8869. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   5/ 63. Data: 0.00s. Batch: 0.41s. Loss: 4.9101. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   6/ 63. Data: 0.00s. Batch: 0.35s. Loss: 4.8929. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   7/ 63. Data: 0.00s. Batch: 0.30s. Loss: 4.9078. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 4.9495. top1: 0.00. top5: 0.00. :   2%|▏         | 1/63 [00:02<02:03,  2.00s/it]Test Iter:   8/ 63. Data: 0.00s. Batch: 0.26s. Loss: 4.9495. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:   9/ 63. Data: 0.00s. Batch: 0.23s. Loss: 5.0433. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  10/ 63. Data: 0.00s. Batch: 0.21s. Loss: 5.0232. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  11/ 63. Data: 0.00s. Batch: 0.20s. Loss: 4.9922. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  12/ 63. Data: 0.00s. Batch: 0.18s. Loss: 5.0212. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  13/ 63. Data: 0.00s. Batch: 0.17s. Loss: 5.0370. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 5.0087. top1: 0.00. top5: 0.00. :  13%|█▎        | 8/63 [00:02<00:10,  5.13it/s]Test Iter:  14/ 63. Data: 0.00s. Batch: 0.16s. Loss: 5.0087. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  15/ 63. Data: 0.00s. Batch: 0.15s. Loss: 5.0021. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  16/ 63. Data: 0.00s. Batch: 0.14s. Loss: 5.0146. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  17/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.0229. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  18/ 63. Data: 0.00s. Batch: 0.13s. Loss: 5.0038. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  19/ 63. Data: 0.00s. Batch: 0.12s. Loss: 5.0031. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  20/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.0076. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.0075. top1: 0.00. top5: 0.00. :  22%|██▏       | 14/63 [00:02<00:04,  9.87it/s]Test Iter:  21/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.0075. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  22/ 63. Data: 0.00s. Batch: 0.11s. Loss: 5.0106. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  23/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.0121. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  24/ 63. Data: 0.00s. Batch: 0.10s. Loss: 5.0152. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  25/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.0060. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  26/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.9957. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  27/ 63. Data: 0.00s. Batch: 0.09s. Loss: 5.0035. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  28/ 63. Data: 0.00s. Batch: 0.09s. Loss: 4.9943. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  29/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.9861. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.9988. top1: 0.00. top5: 0.00. :  33%|███▎      | 21/63 [00:02<00:02, 16.43it/s]Test Iter:  30/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.9988. top1: 0.00. top5: 0.00. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  31/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.9962. top1: 0.00. top5: 0.00. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  32/ 63. Data: 0.00s. Batch: 0.08s. Loss: 4.9623. top1: 0.00. top5: 0.20. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  33/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.9207. top1: 0.00. top5: 0.38. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  34/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.8798. top1: 0.00. top5: 0.64. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  35/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.8376. top1: 0.00. top5: 0.98. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  36/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.8098. top1: 0.00. top5: 0.95. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  37/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.7713. top1: 0.00. top5: 1.01. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  38/ 63. Data: 0.00s. Batch: 0.07s. Loss: 4.7455. top1: 0.00. top5: 1.23. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  39/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.7085. top1: 0.00. top5: 1.44. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6836. top1: 0.00. top5: 1.56. :  48%|████▊     | 30/63 [00:02<00:01, 26.09it/s]Test Iter:  40/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6836. top1: 0.00. top5: 1.56. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  41/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6592. top1: 0.00. top5: 1.68. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  42/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6298. top1: 0.00. top5: 1.86. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  43/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.6010. top1: 0.00. top5: 2.11. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  44/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5702. top1: 0.00. top5: 2.20. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  45/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5439. top1: 0.00. top5: 2.36. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  46/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.5218. top1: 0.00. top5: 2.45. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  47/ 63. Data: 0.00s. Batch: 0.06s. Loss: 4.4992. top1: 0.00. top5: 2.46. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  48/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4806. top1: 0.00. top5: 2.60. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  49/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4614. top1: 0.00. top5: 2.61. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4395. top1: 0.00. top5: 2.69. :  63%|██████▎   | 40/63 [00:02<00:00, 37.86it/s]Test Iter:  50/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4395. top1: 0.00. top5: 2.69. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  51/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.4192. top1: 0.00. top5: 2.76. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  52/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3995. top1: 0.00. top5: 2.76. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  53/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3800. top1: 0.00. top5: 2.83. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  54/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3658. top1: 0.00. top5: 2.95. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  55/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3453. top1: 0.00. top5: 3.07. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  56/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3283. top1: 0.00. top5: 3.12. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  57/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3157. top1: 0.00. top5: 3.29. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  58/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.3017. top1: 0.00. top5: 3.50. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  59/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.2840. top1: 0.00. top5: 3.76. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.2694. top1: 0.00. top5: 3.75. :  79%|███████▉  | 50/63 [00:02<00:00, 48.47it/s]Test Iter:  60/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.2694. top1: 0.00. top5: 3.75. :  95%|█████████▌| 60/63 [00:02<00:00, 57.97it/s]Test Iter:  61/ 63. Data: 0.00s. Batch: 0.05s. Loss: 4.2568. top1: 0.00. top5: 3.79. :  95%|█████████▌| 60/63 [00:02<00:00, 57.97it/s]Test Iter:  62/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.2421. top1: 0.00. top5: 3.93. :  95%|█████████▌| 60/63 [00:02<00:00, 57.97it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.2373. top1: 0.00. top5: 3.95. :  95%|█████████▌| 60/63 [00:02<00:00, 57.97it/s]Test Iter:  63/ 63. Data: 0.00s. Batch: 0.04s. Loss: 4.2373. top1: 0.00. top5: 3.95. : 100%|██████████| 63/63 [00:02<00:00, 21.03it/s]
  0%|          | 0/25 [00:00<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.92s. Batch: 1.99s. Loss: 2.6433. :   0%|          | 0/25 [00:01<?, ?it/s]Finetune Epoch:  4/ 5. Data: 1.92s. Batch: 1.99s. Loss: 2.6433. :   4%|▍         | 1/25 [00:01<00:47,  1.99s/it]Finetune Epoch:  4/ 5. Data: 1.95s. Batch: 2.01s. Loss: 2.6280. :   4%|▍         | 1/25 [00:02<00:47,  1.99s/it]Finetune Epoch:  4/ 5. Data: 1.98s. Batch: 2.03s. Loss: 2.6162. :   4%|▍         | 1/25 [00:02<00:47,  1.99s/it]Finetune Epoch:  4/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.6465. :   4%|▍         | 1/25 [00:02<00:47,  1.99s/it]Finetune Epoch:  4/ 5. Data: 2.01s. Batch: 2.06s. Loss: 2.6465. :  16%|█▌        | 4/25 [00:02<00:08,  2.42it/s]Finetune Epoch:  4/ 5. Data: 2.03s. Batch: 2.08s. Loss: 2.6589. :  16%|█▌        | 4/25 [00:02<00:08,  2.42it/s]Finetune Epoch:  4/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.6374. :  16%|█▌        | 4/25 [00:02<00:08,  2.42it/s]Finetune Epoch:  4/ 5. Data: 2.06s. Batch: 2.11s. Loss: 2.6374. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  4/ 5. Data: 2.08s. Batch: 2.13s. Loss: 2.6142. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  4/ 5. Data: 2.11s. Batch: 2.16s. Loss: 2.6216. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  4/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.6191. :  24%|██▍       | 6/25 [00:02<00:04,  3.91it/s]Finetune Epoch:  4/ 5. Data: 2.13s. Batch: 2.18s. Loss: 2.6191. :  36%|███▌      | 9/25 [00:02<00:02,  6.44it/s]Finetune Epoch:  4/ 5. Data: 2.15s. Batch: 2.20s. Loss: 2.6065. :  36%|███▌      | 9/25 [00:02<00:02,  6.44it/s]Finetune Epoch:  4/ 5. Data: 2.18s. Batch: 2.23s. Loss: 2.6078. :  36%|███▌      | 9/25 [00:02<00:02,  6.44it/s]Finetune Epoch:  4/ 5. Data: 2.20s. Batch: 2.25s. Loss: 2.6131. :  36%|███▌      | 9/25 [00:02<00:02,  6.44it/s]Finetune Epoch:  4/ 5. Data: 2.20s. Batch: 2.25s. Loss: 2.6131. :  48%|████▊     | 12/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/ 5. Data: 2.23s. Batch: 2.28s. Loss: 2.6187. :  48%|████▊     | 12/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.6128. :  48%|████▊     | 12/25 [00:02<00:01,  9.00it/s]Finetune Epoch:  4/ 5. Data: 2.25s. Batch: 2.30s. Loss: 2.6128. :  56%|█████▌    | 14/25 [00:02<00:01, 10.63it/s]Finetune Epoch:  4/ 5. Data: 2.28s. Batch: 2.32s. Loss: 2.5980. :  56%|█████▌    | 14/25 [00:02<00:01, 10.63it/s]Finetune Epoch:  4/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.5943. :  56%|█████▌    | 14/25 [00:02<00:01, 10.63it/s]Finetune Epoch:  4/ 5. Data: 2.30s. Batch: 2.35s. Loss: 2.5943. :  64%|██████▍   | 16/25 [00:02<00:00, 12.13it/s]Finetune Epoch:  4/ 5. Data: 2.33s. Batch: 2.37s. Loss: 2.5888. :  64%|██████▍   | 16/25 [00:02<00:00, 12.13it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.5820. :  64%|██████▍   | 16/25 [00:02<00:00, 12.13it/s]Finetune Epoch:  4/ 5. Data: 2.35s. Batch: 2.40s. Loss: 2.5820. :  72%|███████▏  | 18/25 [00:02<00:00, 13.49it/s]Finetune Epoch:  4/ 5. Data: 2.38s. Batch: 2.43s. Loss: 2.5841. :  72%|███████▏  | 18/25 [00:02<00:00, 13.49it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.5766. :  72%|███████▏  | 18/25 [00:02<00:00, 13.49it/s]Finetune Epoch:  4/ 5. Data: 2.40s. Batch: 2.45s. Loss: 2.5766. :  80%|████████  | 20/25 [00:02<00:00, 14.86it/s]Finetune Epoch:  4/ 5. Data: 2.43s. Batch: 2.48s. Loss: 2.5733. :  80%|████████  | 20/25 [00:02<00:00, 14.86it/s]Finetune Epoch:  4/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.5691. :  80%|████████  | 20/25 [00:03<00:00, 14.86it/s]Finetune Epoch:  4/ 5. Data: 2.45s. Batch: 2.50s. Loss: 2.5691. :  88%|████████▊ | 22/25 [00:03<00:00, 15.99it/s]Finetune Epoch:  4/ 5. Data: 2.48s. Batch: 2.53s. Loss: 2.5676. :  88%|████████▊ | 22/25 [00:03<00:00, 15.99it/s]Finetune Epoch:  4/ 5. Data: 2.50s. Batch: 2.55s. Loss: 2.5664. :  88%|████████▊ | 22/25 [00:03<00:00, 15.99it/s]Finetune Epoch:  4/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.5577. :  88%|████████▊ | 22/25 [00:03<00:00, 15.99it/s]Finetune Epoch:  4/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.5577. : 100%|██████████| 25/25 [00:03<00:00, 17.38it/s]Finetune Epoch:  4/ 5. Data: 2.53s. Batch: 2.58s. Loss: 2.5577. : 100%|██████████| 25/25 [00:03<00:00,  7.38it/s]
  0%|          | 0/63 [00:00<?, ?it/s]  0%|          | 0/63 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 438, in <module>
    main()
  File "main.py", line 334, in main
    pseudo_images, pseudo_targets = metapseudo.train_loop()
  File "/home/vision/minhyuk/smh_real_origin/pseudo_main.py", line 420, in train_loop
    self.finetune(self.labeled_loader, self.student_model)
  File "/home/vision/minhyuk/smh_real_origin/pseudo_main.py", line 552, in finetune
    test_loss, top1, top5 = self.evaluate(model)
  File "/home/vision/minhyuk/smh_real_origin/pseudo_main.py", line 479, in evaluate
    for step, tuples in enumerate(test_iter):
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/site-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 368, in __iter__
    return self._get_iterator()
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 314, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 927, in __init__
    w.start()
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/multiprocessing/process.py", line 112, in start
    self._popen = self._Popen(self)
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/multiprocessing/context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/multiprocessing/context.py", line 277, in _Popen
    return Popen(process_obj)
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/multiprocessing/popen_fork.py", line 20, in __init__
    self._launch(process_obj)
  File "/home/vision/anaconda3/envs/minhyuk/lib/python3.7/multiprocessing/popen_fork.py", line 70, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
